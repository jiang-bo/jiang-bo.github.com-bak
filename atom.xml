<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[非纯种程序猿]]></title>
  <link href="http://jiangbo.me/atom.xml" rel="self"/>
  <link href="http://jiangbo.me/"/>
  <updated>2012-10-18T21:48:31+08:00</updated>
  <id>http://jiangbo.me/</id>
  <author>
    <name><![CDATA[jiang-bo]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[HDFS源码学习（7）——Block管理]]></title>
    <link href="http://jiangbo.me/blog/2012/10/18/hdfs-namenode-block-management/"/>
    <updated>2012-10-18T21:46:00+08:00</updated>
    <id>http://jiangbo.me/blog/2012/10/18/hdfs-namenode-block-management</id>
    <content type="html"><![CDATA[<p>HDFS通过一个BlockManager管理集群中所有的block信息</p>

<h2>主要数据结构</h2>

<h3>Block</h3>

<p>Block是HDFS读写的基本单元，集群中每个block通过一个long id来唯一标示。</p>

<h3>BlockInfo</h3>

<p>维护一个block的元信息，主要通过</p>

<h3>BlockMap</h3>

<p>通过一个GSet&lt;Block, BlockInfo>维护一个block与其元数据信息的映射关系，元信息包括其所属的BlockCollection和存储该block的datanode节点，每个BlockMap有个初始容量capacity</p>

<h3>BlockCollection</h3>

<h2>Block和副本管理</h2>

<h3>Block和副本状态</h3>

<p>Block有如下状态：</p>

<ol>
<li>committed：所有的副本已经被创建且更新至最新</li>
<li>Under construction: 需要创建一个或多个副本</li>
<li>To be deleted: 所有副本需要被删除。发生在文件被删除或者block被重写</li>
<li>Over-replicated: 过多的副本存在。此时副本中的一个需要设置为无效并删除。</li>
</ol>


<p>副本有如下状态：</p>

<ol>
<li>Current: 正常状态，该副本正确反应block内容</li>
<li>Conrrupt: 某个副本损坏。副本损坏是由client报告给namenode的。client通过checksum检查副本是否损坏，如果损坏了，通过BlockManager.invalidateBlock()处理</li>
<li>On a faild DataNode: DataNode Heartbeat发现有DataNode失效时，即将在改datanode上创建的副本将被删除</li>
<li>Out of Date: 当Datanode失效，且副本所属的block发生更新后，Datanode恢复正常。过期的block将通过blockreport报告给namenode，并将其删除</li>
<li>Under construction: 副本尚未被写入并在Datanode上被验证。在NameNode看来，只有当收到blockReport并且报告中timestamp正确时，猜人物副本写入正常。</li>
</ol>


<h2>Block分配</h2>

<h2>Block查询</h2>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HDFS源码学习（6）——租约管理（lease management)]]></title>
    <link href="http://jiangbo.me/blog/2012/10/18/hdfs-namenode-lease-management/"/>
    <updated>2012-10-18T21:44:00+08:00</updated>
    <id>http://jiangbo.me/blog/2012/10/18/hdfs-namenode-lease-management</id>
    <content type="html"><![CDATA[<p>LeaseManagement是HDFS中的一个同步机制，用于保证同一时刻只有一个client对一个文件进行写或创建操作。如当新建一个文件f时，client向NameNode发起一个create请求，那么leaseManager会想该client分配一个f文件的lease。client凭借该lease完成文件的创建操作。此时其他client无法获得f的当client长时间（默认为超过1min）不进行操作时，发放的lease将被收回。</p>

<p>LeaseManager主要完成两部分工作：</p>

<ol>
<li>文件create，write，complete操作时，创建lease、更新时间戳、回收lease</li>
<li>一个后台线程定期检查是否有过期的lease</li>
</ol>


<p>LeaseManager的代码结构如下</p>

<p><img src="http://jiangbo.me/images/hdfs/LeaseManager.png" alt="LeaseManager" /></p>

<p>其中Lease表示一个租约，包括一个client(holder)所拥有的所有文件锁(paths)。</p>

<p>Monitor是检查是否有过期租约的线程。</p>

<p>LeaseManager中有几个主要数据结构：</p>

<ol>
<li>leases（TreeMap&lt;String, Lease>）：维护holder -> leased的映射集合</li>
<li>sortedLeases (TreeSet<Lease>): lease集合</li>
<li>sortedLeaseByPath(TreeMap&lt;String, Lease>): 维护paths->lease的映射集合</li>
</ol>


<h2>一、创建lease</h2>

<p>当client向NameNode发起create操作时，NameNode.create()调用FSNameSystem.startFile()->FSNameSystem.startFileInternal()，该方法最终会调用leaseManager.addLease(cons.clientName, src)来创建lease。</p>

<p>LeaseManager.addLease()方法如下：</p>

<pre><code>  synchronized Lease addLease(String holder, String src
      ) throws IOException {
    Lease lease = getLease(holder);
    if (lease == null) {
      lease = new Lease(holder);
      leases.put(holder, lease);
      sortedLeases.add(lease);
    } else {
      renewLease(lease);
    }
    sortedLeasesByPath.put(src, lease);
    lease.paths.add(src);
    return lease;
  }
</code></pre>

<p>代码结构简单：判断该client是否有lease，没有则新建一个lease，并将起加到leases集合中。否则更新lease。更新sortedLeasesByPath，将filepath加入到该lease的paths集合中</p>

<h2>二、更新时间戳</h2>

<p>针对已经存在的lease，通过LeasemManager.renewLease()来更新该lease的时间戳。代码如下：</p>

<pre><code>  synchronized void renewLease(Lease lease) {
    if (lease != null) {
      sortedLeases.remove(lease);
      lease.renew();
      sortedLeases.add(lease);
    }
  }
</code></pre>

<p>lease.renew()代码如下：</p>

<pre><code>/** Only LeaseManager object can renew a lease */
private void renew() {
  this.lastUpdate = FSNamesystem.now();
}
</code></pre>

<h2>三、compelete时回收lease</h2>

<p>当client调用NameNode.complete()方法时，最终会调用FSNameSystem.completeFileInternal()方法。其中执行finalizeINodeFileUnderConstruction()是调用leaseManager.removeLease()释放lease。</p>

<p>代码结构如下：</p>

<pre><code>  synchronized void removeLease(String holder, String src) {
    Lease lease = getLease(holder);
    if (lease != null) {
      removeLease(lease, src);
    }
  }
</code></pre>

<p> removeLease(lease, src);代码如下：</p>

<pre><code>  /**
   * Remove the specified lease and src.
   */
  synchronized void removeLease(Lease lease, String src) {
    sortedLeasesByPath.remove(src);
    if (!lease.removePath(src)) {
      LOG.error(src + " not found in lease.paths (=" + lease.paths + ")");
    }

    if (!lease.hasPath()) {
      leases.remove(lease.holder);
      if (!sortedLeases.remove(lease)) {
        LOG.error(lease + " not found in sortedLeases");
      }
    }
  }
</code></pre>

<h2>四、后台线程回收过期lease</h2>

<p>Monitor回收lease线程代码结构如下：</p>

<pre><code> class Monitor implements Runnable {
    final String name = getClass().getSimpleName();

    /** Check leases periodically. */
    public void run() {
      for(; fsnamesystem.isRunning(); ) {
        fsnamesystem.writeLock();
        try {
          checkLeases();
        } finally {
          fsnamesystem.writeUnlock();
        }

        try {
          Thread.sleep(2000);
        } catch(InterruptedException ie) {
          if (LOG.isDebugEnabled()) {
            LOG.debug(name + " is interrupted", ie);
          }
        }
      }
    }
  }
</code></pre>

<p>代码结构简单，每个2s周期性执行checkLeases()。</p>

<h3>4.1 checkLeases()</h3>

<pre><code>  /** Check the leases beginning from the oldest. */
  synchronized void checkLeases() {
    for(; sortedLeases.size() &gt; 0; ) {
      final Lease oldest = sortedLeases.first();
      if (!oldest.expiredHardLimit()) {
        return;
      }

      LOG.info("Lease " + oldest + " has expired hard limit");

      final List&lt;String&gt; removing = new ArrayList&lt;String&gt;();
      // need to create a copy of the oldest lease paths, becuase 
      // internalReleaseLease() removes paths corresponding to empty files,
      // i.e. it needs to modify the collection being iterated over
      // causing ConcurrentModificationException
      String[] leasePaths = new String[oldest.getPaths().size()];
      oldest.getPaths().toArray(leasePaths);
      for(String p : leasePaths) {
        try {
          fsnamesystem.internalReleaseLeaseOne(oldest, p);
        } catch (IOException e) {
          LOG.error("Cannot release the path "+p+" in the lease "+oldest, e);
          removing.add(p);
        }
      }

      for(String p : removing) {
        removeLease(oldest, p);
      }
    }
  }
</code></pre>

<h2>Lease Recovery ——租约回收</h2>

<h3>lease recovery时机</h3>

<p>lease发放之后，在不用时会被回收，回收的产经除上述Monitor线程检测lease过期是回收外，还有：</p>

<ol>
<li>NameNode收到DataNode的Sync block command时</li>
<li>DFSClient主动关闭一个流时</li>
<li>创建文件时，如果该DFSClient的lease超过soft limit时</li>
</ol>


<h3>lease recovery 算法</h3>

<p>1) NameNode查找lease信息</p>

<p>2) 对于lease中的每个文件f，令b为f的最后一个block，作如下操作：</p>

<p>2.1) 获取b所在的datanode列表</p>

<p>2.2) 令其中一个datanode作为primary datanode p</p>

<p>2.3) p 从NameNode获取最新的时间戳</p>

<p>2.4) p 从每个DataNode获取block信息</p>

<p>2.5) p 计算最小的block长度</p>

<p>2.6) p 用最小的block长度和最新的时间戳来更新具有有效时间戳的datanode</p>

<p>2.7) p 通知NameNode更新结果</p>

<p>2.8) NameNode更新BlockInfo</p>

<p>2.9) NameNode从lease中删除f，如果此时该lease中所有文件都已被删除，将删除该lease</p>

<p>2.10) Name提交修改的EditLog</p>

<h2>Client续约 —— DFSClient.LeaseChecker</h2>

<p>在NameNode上的LeaseManager.Monitor线程负责检查过期的lease，那么client为了防止尚在使用的lease过期，需要定期想NameNode发起续约请求。该任务有DFSClient中的LeaseChecker完成。</p>

<p>LeaseChecker结构如下：</p>

<p><img src="http://jiangbo.me/images/hdfs/LeaseChecker.png" alt="LeaseChecker" /></p>

<p>其中pendingCreates是一个TreeMap&lt;String, OutputStream>用来维护src->当前正在写入的文件的DFSOutputStream的映射。</p>

<p>其核心是周期性（每个1s）调用run()方法来对租约过半的lease进行续约</p>

<pre><code>public void run() {
  long lastRenewed = 0;
  while (clientRunning &amp;&amp; !Thread.interrupted()) {
    //当租约周期过半时需要进行续约
    if (System.currentTimeMillis() - lastRenewed &gt; (LEASE_SOFTLIMIT_PERIOD / 2)) {
      try {
        renew();
        lastRenewed = System.currentTimeMillis();
      } catch (IOException ie) {
        LOG.warn("Problem renewing lease for " + clientName, ie);
      }
    }

    try {
      Thread.sleep(1000);
    } catch (InterruptedException ie) {
      if (LOG.isDebugEnabled()) {
        LOG.debug(this + " is interrupted.", ie);
      }
      return;
    }
  }
}
</code></pre>

<p>其中renew()方法如下：</p>

<pre><code>    private void renew() throws IOException {
      synchronized(this) {
        //如果当前创建中的文件列表为空，则不需要续约
        if (pendingCreates.isEmpty()) {
          return;
        }
      }
      //向NameNode发起续约请求
      namenode.renewLease(clientName);
    }
</code></pre>

<p>NameNode接收到renewLease请求后，调用FSNameSystem.renewLease()并最终调用LeaseManager.renewLease()完成续约。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HDFS源码学习（5）——副本管理（Replica Management)]]></title>
    <link href="http://jiangbo.me/blog/2012/10/18/hdfs-namenode-replica-management/"/>
    <updated>2012-10-18T21:43:00+08:00</updated>
    <id>http://jiangbo.me/blog/2012/10/18/hdfs-namenode-replica-management</id>
    <content type="html"><![CDATA[<p>HDFS中的副本管理通过FSNameSystem.java中的ReplicationMonitor线程来完成。该线程代码结构较为简单。</p>

<pre><code>  class ReplicationMonitor implements Runnable {
    static final int INVALIDATE_WORK_PCT_PER_ITERATION = 32;
    static final float REPLICATION_WORK_MULTIPLIER_PER_ITERATION = 2;
    public void run() {
      while (fsRunning) {
        try {
          computeDatanodeWork();
          processPendingReplications();
          Thread.sleep(replicationRecheckInterval);
        } catch (InterruptedException ie) {
          LOG.warn("ReplicationMonitor thread received InterruptedException.", ie);
          break;
        } catch (IOException ie) {
          LOG.warn("ReplicationMonitor thread received exception. " + ie +  " " +
              StringUtils.stringifyException(ie));
        } catch (Throwable t) {
          LOG.fatal("ReplicationMonitor thread received Runtime exception. " + t + " " +
              StringUtils.stringifyException(t));
          Runtime.getRuntime().exit(-1);
        }
      }
    }
  }
</code></pre>

<p>该线程只是周期性调用computeDatanodeWork()和processPendingReplications()。</p>

<h2>一、computeDatanodeWork()</h2>

<pre><code>  public int computeDatanodeWork() throws IOException {
    int workFound = 0;
    int blocksToProcess = 0;
    int nodesToProcess = 0;
    // blocks should not be replicated or removed if safe mode is on
    if (isInSafeMode())
      return workFound;
    //计算需要备份的block数和节点数
    synchronized(heartbeats) {
      blocksToProcess = (int)(heartbeats.size() 
          * ReplicationMonitor.REPLICATION_WORK_MULTIPLIER_PER_ITERATION);
      nodesToProcess = (int)Math.ceil((double)heartbeats.size() 
          * ReplicationMonitor.INVALIDATE_WORK_PCT_PER_ITERATION / 100);
    }
    //执行备份
    workFound = computeReplicationWork(blocksToProcess); 

    // Update FSNamesystemMetrics counters
    pendingReplicationBlocksCount = pendingReplications.size();
    underReplicatedBlocksCount = neededReplications.size();
    scheduledReplicationBlocksCount = workFound;
    corruptReplicaBlocksCount = corruptReplicas.size();

    //HADOOP-5549 : Fix bug of schedule both replication and deletion work in one iteration
    workFound += computeInvalidateWork(nodesToProcess);
    return workFound;
  }
</code></pre>

<h3>1.1. computeReplicationWork()</h3>

<pre><code>  private int computeReplicationWork(
                                  int blocksToProcess) throws IOException {
    // stall only useful for unit tests (see TestFileAppend4.java)
    if (stallReplicationWork)  {
      return 0;
    }

    // 选取需要备份的block
    List&lt;List&lt;Block&gt;&gt; blocksToReplicate =
      chooseUnderReplicatedBlocks(blocksToProcess);

    // 执行备份
    return computeReplicationWorkForBlocks(blocksToReplicate);
  }
</code></pre>

<h3>1.1.1 选取需要备份的block —— chooseUnderReplicatedBlocks()</h3>

<pre><code>  List&lt;List&lt;Block&gt;&gt; chooseUnderReplicatedBlocks(int blocksToProcess) {
    // 初始化返回值数据结构，返回值是一个二维优先级列表
    List&lt;List&lt;Block&gt;&gt; blocksToReplicate =
      new ArrayList&lt;List&lt;Block&gt;&gt;(UnderReplicatedBlocks.LEVEL);
    for (int i = 0; i &lt; UnderReplicatedBlocks.LEVEL; i++) {
      blocksToReplicate.add(new ArrayList&lt;Block&gt;());
    }

    writeLock();
    try {
      synchronized (neededReplications) {
        if (neededReplications.size() == 0) {
          return blocksToReplicate;
        }

        for (int priority = 0; priority&lt;UnderReplicatedBlocks.LEVEL; priority++) {
        //遍历所有需要备份的block列表（UnderReplicatedBlocks结构）
        BlockIterator neededReplicationsIterator = neededReplications.iterator(priority);
        int numBlocks = neededReplications.size(priority);
        //检查该优先级列表中是否已经开始备份（relIndex数组中保存的是当前每个优先级列表中已备份的block索引）
        if (replIndex[priority] &gt; numBlocks) {
          replIndex[priority] = 0;
        }
        // skip to the first unprocessed block, which is at replIndex
        for (int i = 0; i &lt; replIndex[priority] &amp;&amp; neededReplicationsIterator.hasNext(); i++) {
          neededReplicationsIterator.next();
        }
        // 计算该优先级下需要备份的block数，低优先级的block备份数不超过总配额的20%
        int blocksToProcessIter = getQuotaForThisPriority(blocksToProcess,
            numBlocks, neededReplications.getSize(priority+1));
        blocksToProcess -= blocksToProcessIter;

        //便利改优先级列表将该优先级下的block添加到返回值中
        for (int blkCnt = 0; blkCnt &lt; blocksToProcessIter; blkCnt++, replIndex[priority]++) {
          if (!neededReplicationsIterator.hasNext()) {
            // start from the beginning
            replIndex[priority] = 0;
            neededReplicationsIterator = neededReplications.iterator(priority);
            assert neededReplicationsIterator.hasNext() :
              "neededReplications should not be empty.";
          }

          Block block = neededReplicationsIterator.next();
          blocksToReplicate.get(priority).add(block);
        } // end for
        }
      } // end try
      return blocksToReplicate;
    } finally {
      writeUnlock();
    }
  }
</code></pre>

<h3>1.1.2. 备份blocks —— computeReplicationWorkForBlocks（）</h3>

<pre><code>  int computeReplicationWorkForBlocks(List&lt;List&lt;Block&gt;&gt; blocksToReplicate) {
    int requiredReplication, numEffectiveReplicas, priority;
    List&lt;DatanodeDescriptor&gt; containingNodes;
    DatanodeDescriptor srcNode;
    INodeFile fileINode = null;

    int scheduledWork = 0;
    List&lt;ReplicationWork&gt; work = new LinkedList&lt;ReplicationWork&gt;();

    writeLock();
    try {
      synchronized (neededReplications) {
        for (priority = 0; priority &lt; blocksToReplicate.size(); priority++) {
          for (Block block : blocksToReplicate.get(priority)) {
            // block should belong to a file
            //获取该block所属的INode
            fileINode = blocksMap.getINode(block);
            // abandoned block not belong to a file
            if (fileINode == null ) {
              neededReplications.remove(block, priority); // remove from neededReplications
              replIndex[priority]--;
              continue;
            }
            //获取该文件需要的副本数
            requiredReplication = fileINode.getReplication();

            // 获取一个源datanode节点
            containingNodes = new ArrayList&lt;DatanodeDescriptor&gt;();
            NumberReplicas numReplicas = new NumberReplicas();
            srcNode = chooseSourceDatanode(block, containingNodes, numReplicas);
            if (srcNode == null) // block can not be replicated from any node
            {
              continue;
            }

          // 检查正在备份中的副本数是否满足备份需要，满足则不需要再备份
            numEffectiveReplicas = numReplicas.liveReplicas() +
              pendingReplications.getNumReplicas(block);
            if (numEffectiveReplicas &gt;= requiredReplication) {
              neededReplications.remove(block, priority); // remove from neededReplications
              replIndex[priority]--;
              continue;
            }
            //添加到待备份列表中
            work.add(new ReplicationWork(block, fileINode, requiredReplication
                - numEffectiveReplicas, srcNode, containingNodes, priority));
          }
        }
      }
    } finally {
      writeUnlock();
    }

    // 选取一个备份目标datanode
    for(ReplicationWork rw : work){
      DatanodeDescriptor targets[] = chooseTarget(rw);
      rw.targets = targets;
    }

    writeLock();
    try {
      for(ReplicationWork rw : work){
        DatanodeDescriptor[] targets = rw.targets;
        if(targets == null || targets.length == 0){
          rw.targets = null;
          continue;
        }
        synchronized (neededReplications) {
          Block block = rw.block;
          priority = rw.priority;
          // 重新检查INode和备份数，因为全局锁已经释放
          // block should belong to a file
          fileINode = blocksMap.getINode(block);
          // abandoned block not belong to a file
          if (fileINode == null ) {
            neededReplications.remove(block, priority); // remove from neededReplications
            rw.targets = null;
            replIndex[priority]--;
            continue;
          }
          requiredReplication = fileINode.getReplication();


          NumberReplicas numReplicas = countNodes(block);
          numEffectiveReplicas = numReplicas.liveReplicas() +
            pendingReplications.getNumReplicas(block);
          if (numEffectiveReplicas &gt;= requiredReplication) {
            neededReplications.remove(block, priority); // remove from neededReplications
            replIndex[priority]--;
            rw.targets = null;
            continue;
          }

          // 将block添加到datanode的需要备份的block列表中
          rw.srcNode.addBlockToBeReplicated(block, targets);

          scheduledWork++;

          //设置namenode的block调度计数器
          for (DatanodeDescriptor dn : targets) {
            dn.incBlocksScheduled();
          }

          // Move the block-replication into a "pending" state.
          // The reason we use 'pending' is so we can retry
          // replications that fail after an appropriate amount of time.
          //将该block移至pendingReplications（PendingReplicationBlocks）中，表示该block的状态为'pending'(正在备份中)。'pending'表示如果失败了还可以重试
          pendingReplications.add(block, targets.length);
          NameNode.stateChangeLog.debug(
            "BLOCK* block " + block
              + " is moved from neededReplications to pendingReplications");

          // remove from neededReplications
          //从 neededReplication列表中移除该block
          if (numEffectiveReplicas + targets.length &gt;= requiredReplication) {
            neededReplications.remove(block, priority); // remove from neededReplications
            replIndex[priority]--;
          }
        }
      }
    } finally {
      writeUnlock();
    }

    // 更新 metrics
    updateReplicationMetrics(work);

    // 打印debug信息
    if(NameNode.stateChangeLog.isInfoEnabled()){
      // log which blocks have been scheduled for replication
      for(ReplicationWork rw : work){
        // report scheduled blocks
        DatanodeDescriptor[] targets = rw.targets;
        if (targets != null &amp;&amp; targets.length != 0) {
          StringBuffer targetList = new StringBuffer("datanode(s)");
          for (int k = 0; k &lt; targets.length; k++) {
            targetList.append(' ');
            targetList.append(targets[k].getName());
          }
          NameNode.stateChangeLog.info(
            "BLOCK* ask "
              + rw.srcNode.getName() + " to replicate "
              + rw.block + " to " + targetList);
        }
      }
    }

    // 记录一次备份操作
    if (NameNode.stateChangeLog.isDebugEnabled()) {
      NameNode.stateChangeLog.debug("BLOCK* neededReplications = "
          + neededReplications.size() + " pendingReplications = "
          + pendingReplications.size());
    }
    return scheduledWork;
  }
</code></pre>

<h4>1.1.2.1. 选取源datanode —— chooseSourceDatanode（）</h4>

<p>获取一个源datanode节点</p>

<pre><code>  private DatanodeDescriptor chooseSourceDatanode(
                                    Block block,
                                    List&lt;DatanodeDescriptor&gt; containingNodes,
                                    NumberReplicas numReplicas) {
    containingNodes.clear();
    DatanodeDescriptor srcNode = null;
    int live = 0;
    int decommissioned = 0;
    int corrupt = 0;
    int excess = 0;
    Iterator&lt;DatanodeDescriptor&gt; it = blocksMap.nodeIterator(block);
    Collection&lt;DatanodeDescriptor&gt; nodesCorrupt = corruptReplicas.getNodes(block);
    while(it.hasNext()) {
      DatanodeDescriptor node = it.next();
      Collection&lt;Block&gt; excessBlocks = 
        excessReplicateMap.get(node.getStorageID());
      if ((nodesCorrupt != null) &amp;&amp; (nodesCorrupt.contains(node)))
        corrupt++;
      else if (node.isDecommissionInProgress() || node.isDecommissioned())
        decommissioned++;
      else if (excessBlocks != null &amp;&amp; excessBlocks.contains(block)) {
        excess++;
      } else {
        live++;
      }
      containingNodes.add(node);
      // Check if this replica is corrupt
      // If so, do not select the node as src node
      if ((nodesCorrupt != null) &amp;&amp; nodesCorrupt.contains(node))
        continue;
      if(node.getNumberOfBlocksToBeReplicated() &gt;= maxReplicationStreams)
        continue; // already reached replication limit
      // the block must not be scheduled for removal on srcNode
      if(excessBlocks != null &amp;&amp; excessBlocks.contains(block))
        continue;
      // never use already decommissioned nodes
      if(node.isDecommissioned())
        continue;
      // we prefer nodes that are in DECOMMISSION_INPROGRESS state
      if(node.isDecommissionInProgress() || srcNode == null) {
        srcNode = node;
        continue;
      }
      if(srcNode.isDecommissionInProgress())
        continue;
      // switch to a different node randomly
      // this to prevent from deterministically selecting the same node even
      // if the node failed to replicate the block on previous iterations
      if(r.nextBoolean())
        srcNode = node;
    }
    if(numReplicas != null)
      numReplicas.initialize(live, decommissioned, corrupt, excess);
    return srcNode;
  }
</code></pre>

<h4>1.1.2.2. 选取目标datanode —— chooseTarget(rw);</h4>

<pre><code>  private DatanodeDescriptor[] chooseTarget(ReplicationWork work) {
    if (!neededReplications.contains(work.block)) {
      return null;
    }
    if (work.blockSize == BlockCommand.NO_ACK) {
      LOG.warn("Block " + work.block.getBlockId() + 
          " of the file " + work.fileINode.getFullPathName() + 
          " is invalidated and cannot be replicated.");
      return null;
    }
    if (work.blockSize == DFSUtil.DELETED) {
      LOG.warn("Block " + work.block.getBlockId() + 
          " of the file " + work.fileINode.getFullPathName() + 
          " is a deleted block and cannot be replicated.");
      return null;
    }
    //实际调用replicator(BlockPlacementPolicy)的chooseTarget方法选取target
    return replicator.chooseTarget(work.fileINode,
        work.numOfReplicas, work.srcNode,
        work.containingNodes, null, work.blockSize);
  }
</code></pre>

<h2>副本存放策略</h2>

<p><img src="img/BlockAllocation.png" alt="BlockAllocation" /></p>

<p>如图所示，HDFS默认的副本存放策略为：</p>

<ol>
<li>第一个副本存放在当前datanode的本地</li>
<li>第二个副本存放在与第一个副本所在datanode不在同一机架上的一个datanode上</li>
<li>第三个副本存放在与第二个副本同一机架但不同datanode上</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HDFS源码学习(4)——DataNode心跳检测（HeartBeat）]]></title>
    <link href="http://jiangbo.me/blog/2012/10/18/hdfs-heartbeat/"/>
    <updated>2012-10-18T21:38:00+08:00</updated>
    <id>http://jiangbo.me/blog/2012/10/18/hdfs-heartbeat</id>
    <content type="html"><![CDATA[<p>HDFS中DataNode的心跳检测通过FSNameSystem中的HeartbeatMonitor完成。代码结构如下：</p>

<pre><code>  class HeartbeatMonitor implements Runnable {
    /**
     */
    public void run() {
      while (fsRunning) {
        try {
          heartbeatCheck();
        } catch (Exception e) {
          FSNamesystem.LOG.error(StringUtils.stringifyException(e));
        }
        try {
          Thread.sleep(heartbeatRecheckInterval);
        } catch (InterruptedException ie) {
        }
      }
    }
  }
</code></pre>

<p>代码很简单，心跳检测线程周期性调用heartbeatCheck()。</p>

<h2>一、心跳检查——heartbeatCheck()</h2>

<p>该方法主要用于检测是否有过期的心跳检测，如有，检测其上的block是否已经进行过重新备份。该线程每次只处理一个datanode。</p>

<pre><code>  void heartbeatCheck() {
    if (isInSafeMode()) {
      // 安全模式下不做心跳检测
      return;
    }
    boolean allAlive = false;
    while (!allAlive) {
      boolean foundDead = false;
      DatanodeID nodeID = null;

      // 获取第一个dead datanode
      synchronized(heartbeats) {
        for (Iterator&lt;DatanodeDescriptor&gt; it = heartbeats.iterator();
             it.hasNext();) {
          DatanodeDescriptor nodeInfo = it.next();
          if (isDatanodeDead(nodeInfo)) {
            foundDead = true;
            nodeID = nodeInfo;
            break;
          }
        }
      }

      // 申请fsnamesystem锁，删除dead datanode
      if (foundDead) {
        writeLock();
        try {
          synchronized(heartbeats) {
            synchronized (datanodeMap) {
              DatanodeDescriptor nodeInfo = null;
              try {
                nodeInfo = getDatanode(nodeID);
              } catch (IOException e) {
                nodeInfo = null;
              }
              if (nodeInfo != null &amp;&amp; isDatanodeDead(nodeInfo)) {
                NameNode.stateChangeLog.info("BLOCK* NameSystem.heartbeatCheck: "
                                             + "lost heartbeat from " + nodeInfo.getName());
                removeDatanode(nodeInfo);
              }
            }
          }
        } finally {
          writeUnlock();
        }
      }
      allAlive = !foundDead;
    }
  }
</code></pre>

<h3>1.1 判断是否已死 —— isDatanodeDead（）</h3>

<p>判断一个datanode是否已经dead的标准很简单，当前距该节点最后的更新时间差是否已经超过心跳检测的过期时间限制</p>

<pre><code>private boolean isDatanodeDead(DatanodeDescriptor node) {
    return (node.getLastUpdate() &lt;
            (now() - heartbeatExpireInterval));
  }
</code></pre>

<h3>1.2 删除datanode —— removeDatanode（）</h3>

<pre><code>  private void removeDatanode(DatanodeDescriptor nodeInfo) {
    synchronized (heartbeats) {
      if (nodeInfo.isAlive) {
        updateStats(nodeInfo, false);
        //从heartbeats中移除
        heartbeats.remove(nodeInfo);
        //更新datanode状态
        nodeInfo.isAlive = false;
      }
    }

    nodeInfo.hasInitialBlockReport = false;
    for (Iterator&lt;Block&gt; it = nodeInfo.getBlockIterator(); it.hasNext();) {
      //移除该节点上的block
      removeStoredBlock(it.next(), nodeInfo);
    }
    unprotectedRemoveDatanode(nodeInfo);
    clusterMap.remove(nodeInfo);
  }
</code></pre>

<h4>1.2.1 removeStoredBlock（）</h4>

<p>该方法更新block->datanode的映射(blocksMap)，如果block还有效，有可能导致block备份发生</p>

<pre><code>  void removeStoredBlock(Block block, DatanodeDescriptor node) {
    if (NameNode.stateChangeLog.isDebugEnabled()) {
      NameNode.stateChangeLog.debug("BLOCK* NameSystem.removeStoredBlock: "
                                    +block + " from "+node.getName());
    }
    assert (hasWriteLock());
    if (!blocksMap.removeNode(block, node)) {
      if (NameNode.stateChangeLog.isDebugEnabled()) {
        NameNode.stateChangeLog.debug("BLOCK* NameSystem.removeStoredBlock: "
                                      +block+" has already been removed from node "+node);
      }
      return;
    }

    //
    //检查是否需要备份删除的block
    INode fileINode = blocksMap.getINode(block);
    if (fileINode != null) {
      //减小当前系统中安全block（备份数满足最小值的block）数量
      decrementSafeBlockCount(block);
      //更新需要备份的block数量
      updateNeededReplications(block, -1, 0);
    }

    //
    // 从excessblocks中删除改block，并从excessReplicateMap删除改datanode
    Collection&lt;Block&gt; excessBlocks = excessReplicateMap.get(node.getStorageID());
    if (excessBlocks != null) {
      if (excessBlocks.remove(block)) {
        excessBlocksCount--;
        if (NameNode.stateChangeLog.isDebugEnabled()) {
          NameNode.stateChangeLog.debug("BLOCK* NameSystem.removeStoredBlock: "
              +block+" is removed from excessBlocks");
        }
        if (excessBlocks.size() == 0) {
          excessReplicateMap.remove(node.getStorageID());
        }
      }
    }

    // 从corruptReplicas中移除该block
    corruptReplicas.removeFromCorruptReplicasMap(block, node);
  }
</code></pre>

<h5>1.2.1.1  BlocksMap.removeNode（）</h5>

<p>其中BlocksMap.removeNode()方法如下：</p>

<pre><code>  boolean removeNode(Block b, DatanodeDescriptor node) {
    BlockInfo info = blocks.get(b);
    if (info == null)
      return false;

    // 从datanode 的blocklist中移除block，并从block的datalist中移除datanode
    boolean removed = node.removeBlock(info);

    if (info.getDatanode(0) == null     // no datanodes left
              &amp;&amp; info.inode == null) {  // does not belong to a file
      //从blocksmap中移除该block
      blocks.remove(b);  // remove block from the map
    }
    return removed;
  }
</code></pre>

<h5>1.2.1.2 减小当前安全的block数 —— decrementSafeBlockCount()</h5>

<p>减小当前副本数安全的的block数，此举有可能触发系统进入安全模式（safemode）</p>

<pre><code>  void decrementSafeBlockCount(Block b) {
    if (safeMode == null) // mostly true
      return;

    safeMode.decrementSafeBlockCount((short)countNodes(b).liveReplicas());
  }
</code></pre>

<p>其中safeMode.decrementSafeBlockCount()代码如下：</p>

<pre><code>synchronized void decrementSafeBlockCount(short replication) {

  if (replication == safeReplication-1) {
    //安全的block数减一
    this.blockSafe--;
    //检查是否需要进入到safemode
    checkMode();
  }
}
</code></pre>

<p>SafeModeInfo.checkMode()代码如下：</p>

<pre><code>    private void checkMode() {
      //当安全的block数比例降至安全值以下，进入安全模式
      if (needEnter()) {
        enter();
        // check if we are ready to initialize replication queues
        if (canInitializeReplQueues() &amp;&amp; !isPopulatingReplQueues()) {
          //初始化副本队列
          initializeReplQueues();
        }
        reportStatus("STATE* Safe mode ON.", false);
        return;
      }
      // 如果安全模式已经关闭或者门槛小于0，则跳出安全模式
      if (!isOn() ||                           // safe mode is off
          extension &lt;= 0 || threshold &lt;= 0) {  // don't need to wait
        this.leave(true); // leave safe mode
        return;
      }

      //之前已经进入安全模式，直接返回
      if (reached &gt; 0) {  // threshold has already been reached before
        reportStatus("STATE* Safe mode ON.", false);
        return;
      }
      // 启动SafeModeMonitor线程
      reached = now();
      smmthread = new Daemon(new SafeModeMonitor());
      smmthread.start();
      reportStatus("STATE* Safe mode extension entered.", true);
    }
</code></pre>

<h5>1.2.1.3 更新需要备份的列表 —— updateNeededReplications（）</h5>

<pre><code>  /* updates a block in under replication queue */
  void updateNeededReplications(Block block,
                        int curReplicasDelta, int expectedReplicasDelta) {
    writeLock();
    try {
    //计算当前副本数
    NumberReplicas repl = countNodes(block);
    //期望的副本数
    int curExpectedReplicas = getReplication(block);
    //将该block更新到需要备份的列表中（neededReplications）
    neededReplications.update(block, 
                              repl.liveReplicas(), 
                              repl.decommissionedReplicas(),
                              curExpectedReplicas,
                              curReplicasDelta, expectedReplicasDelta);
    } finally {
      writeUnlock();
    }
  }
</code></pre>

<h4>1.2.2 移除datanode —— unprotectedRemoveDatanode</h4>

<pre><code>  void unprotectedRemoveDatanode(DatanodeDescriptor nodeDescr) {
    //重置清空datanode中block信息
    nodeDescr.resetBlocks();
    //从invlidateSet中移除datanode
    removeFromInvalidates(nodeDescr.getStorageID());
    if (NameNode.stateChangeLog.isDebugEnabled()) {
      NameNode.stateChangeLog.debug(
                                    "BLOCK* NameSystem.unprotectedRemoveDatanode: "
                                    + nodeDescr.getName() + " is out of service now.");
    }
  }
</code></pre>

<h5>1.2.2.1 removeFromInvalidates()</h5>

<pre><code>  private void removeFromInvalidates(String storageID) {
    //从recentInvalidateSet中移除该datanode
    Collection&lt;Block&gt; blocks = recentInvalidateSets.remove(storageID);
    if (blocks != null) {
      //从正在删除的block总数中减去当前节点上的block总数
      pendingDeletionBlocksCount -= blocks.size();
    }
  }
</code></pre>

<h2>二、 处理心跳检测请求 —— handleHeartbeat()</h2>

<p>NameNode只负责创建一个HeartbeatMonitor来通过每个datanode的最新更新时间周期性检查是否有过期的datanode，而每个datanode是否的最新更新时间是由datanode主动向namenode报告的，namenode通过handleHeartbeat()处理心跳请求。</p>

<pre><code>  DatanodeCommand[] handleHeartbeat(DatanodeRegistration nodeReg,
      long capacity, long dfsUsed, long remaining,
      int xceiverCount, int xmitsInProgress) throws IOException {
    DatanodeCommand cmd = null;
    synchronized (heartbeats) {
      synchronized (datanodeMap) {
        DatanodeDescriptor nodeinfo = null;
        try {
          nodeinfo = getDatanode(nodeReg);
        } catch(UnregisteredDatanodeException e) {
          return new DatanodeCommand[]{DatanodeCommand.REGISTER};
        }

        // 检查该datanode是否需要被关闭，可以通过设置datanode的adminState为DECOMMISSIONED来关闭一个datanode
        if (nodeinfo != null &amp;&amp; shouldNodeShutdown(nodeinfo)) {
          setDatanodeDead(nodeinfo);
          throw new DisallowedDatanodeException(nodeinfo);
        }

        if (nodeinfo == null || !nodeinfo.isAlive) {
          return new DatanodeCommand[]{DatanodeCommand.REGISTER};
        }

        updateStats(nodeinfo, false);
        nodeinfo.updateHeartbeat(capacity, dfsUsed, remaining, xceiverCount);
        updateStats(nodeinfo, true);

        //检查租约恢复状态
        cmd = nodeinfo.getLeaseRecoveryCommand(Integer.MAX_VALUE);
        if (cmd != null) {
          return new DatanodeCommand[] {cmd};
        }

        ArrayList&lt;DatanodeCommand&gt; cmds = new ArrayList&lt;DatanodeCommand&gt;(2);
        //检查正在备份中的副本
        cmd = nodeinfo.getReplicationCommand(
              maxReplicationStreams - xmitsInProgress);
        if (cmd != null) {
          cmds.add(cmd);
        }
        //检查无效的block
        cmd = nodeinfo.getInvalidateBlocks(blockInvalidateLimit);
        if (cmd != null) {
          cmds.add(cmd);
        }
        if (!cmds.isEmpty()) {
          return cmds.toArray(new DatanodeCommand[cmds.size()]);
        }
      }
    }

    //检查是否需要升级系统
    cmd = getDistributedUpgradeCommand();
    if (cmd != null) {
      return new DatanodeCommand[] {cmd};
    }
    return null;
  }
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HDFS源码学习（3）——NameNode中的线程]]></title>
    <link href="http://jiangbo.me/blog/2012/10/18/hdfs-namenode-thread/"/>
    <updated>2012-10-18T21:37:00+08:00</updated>
    <id>http://jiangbo.me/blog/2012/10/18/hdfs-namenode-thread</id>
    <content type="html"><![CDATA[<p>NameNode存在三种运行模式：</p>

<ol>
<li>Normal： NameNode正常服务的状态</li>
<li>Safe mode：NameNode重启时进入Safe mode，该模式下整个系统是只读的，以便于NameNode手机DataNode信息</li>
<li>Backup mode：备份NameNode处于Backup mode，被动的接收主NameNode的检查点信息</li>
</ol>


<p>在NameNode中存在如下几种线程：</p>

<ol>
<li>DataNode 健康检查管理线程</li>
<li>副本管理线程</li>
<li>租约管理（lease Management）</li>
<li>IPC Handler 线程</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HDFS源码学习(2)——NameNode初始化]]></title>
    <link href="http://jiangbo.me/blog/2012/10/18/hdfs-namenode-startup/"/>
    <updated>2012-10-18T21:35:00+08:00</updated>
    <id>http://jiangbo.me/blog/2012/10/18/hdfs-namenode-startup</id>
    <content type="html"><![CDATA[<h2>main()</h2>

<pre><code>  public static void main(String argv[]) throws Exception {
    try {
      StringUtils.startupShutdownMessage(NameNode.class, argv, LOG);
      //创建nameNode
      NameNode namenode = createNameNode(argv, null);
      if (namenode != null)
        namenode.join();
    } catch (Throwable e) {
      LOG.error(StringUtils.stringifyException(e));
      System.exit(-1);
    }
  }
</code></pre>

<h3>createNameNode()</h3>

<pre><code>  public static NameNode createNameNode(String argv[], 
                                 Configuration conf) throws IOException {
    if (conf == null)
      conf = new Configuration();
      //从命令行参数中提取启动配置项数据
    StartupOption startOpt = parseArguments(argv);
    if (startOpt == null) {
      printUsage();
      return null;
    }
    //设置启动参数
    setStartupOption(conf, startOpt);

    switch (startOpt) {
      case FORMAT:
        boolean aborted = format(conf, true);
        System.exit(aborted ? 1 : 0);
      case FINALIZE:
        aborted = finalize(conf, true);
        System.exit(aborted ? 1 : 0);
      default:
    }

    //新建NameNode
    NameNode namenode = new NameNode(conf);
    return namenode;
  }
</code></pre>

<h3>NameNode()</h3>

<pre><code>  public NameNode(Configuration conf) throws IOException {
    super(conf);
    try {
    //初始化
      initialize(getConf());
    } catch (IOException e) {
      this.stop();
      throw e;
    }
  }
</code></pre>

<h3>initialize()</h3>

<pre><code>  private void initialize(Configuration conf) throws IOException {
    InetSocketAddress socAddr = NameNode.getAddress(conf);
    int handlerCount = conf.getInt("dfs.namenode.handler.count", 10);
    // 关键-&gt;创建一个RPC Server
    this.server = RPC.getServer(this, socAddr.getHostName(), socAddr.getPort(),
                                handlerCount, false, conf);

    // The rpc-server port can be ephemeral... ensure we have the correct info
    this.serverAddress = this.server.getListenerAddress(); 
    FileSystem.setDefaultUri(conf, getUri(serverAddress));
    LOG.info("Namenode up at: " + this.serverAddress);

    myMetrics = new NameNodeMetrics(conf, this);

    //关键-&gt;创建一个FSNameSystem
    this.namesystem = new FSNamesystem(this, conf);
    //启动HTTP Server
    startHttpServer(conf);
    //启动RPC Server
    this.server.start();  //start RPC server   

    startTrashEmptier(conf);
  }
</code></pre>

<h2>FSNameSystem()</h2>

<pre><code>  FSNamesystem(NameNode nn, Configuration conf) throws IOException {
    try {
      //初始化FSNameSystem
      initialize(nn, conf);
      userPasswordInformation = new UserPasswordInformation(conf);
      extendAccessControlList = new ExtendAccessControlList(conf);
    } catch(IOException e) {
      LOG.error(getClass().getSimpleName() + " initialization failed.", e);
      close();
      throw e;
    }
  }
</code></pre>

<h3>FSNameSystem.initialize()</h3>

<pre><code>  private void initialize(NameNode nn, Configuration conf) throws IOException {
    this.systemStart = now();
    this.fsLock = new ReentrantReadWriteLock(); // non-fair locking
    setConfigurationParameters(conf);

    this.nameNodeAddress = nn.getNameNodeAddress();
    this.registerMBean(conf); // register the MBean for the FSNamesystemStutus

    //创建FSDirectory
    this.dir = new FSDirectory(this, conf);
    StartupOption startOpt = NameNode.getStartupOption(conf);

    //加载FSImage
    this.dir.loadFSImage(getNamespaceDirs(conf),
                         getNamespaceEditsDirs(conf), startOpt);
    long timeTakenToLoadFSImage = now() - systemStart;
    LOG.info("Finished loading FSImage in " + timeTakenToLoadFSImage + " msecs");
    NameNode.getNameNodeMetrics().fsImageLoadTime.set(
                              (int) timeTakenToLoadFSImage);
    this.safeMode = new SafeModeInfo(conf);
    setBlockTotal();
    //创建PendingReplicationBlocks
    pendingReplications = new PendingReplicationBlocks(
                            conf.getInt("dfs.replication.pending.timeout.sec", 
                                        -1) * 1000L);
    //创建心跳检查线程                                          
    this.hbthread = new Daemon(new HeartbeatMonitor());
    //创建租约管理线程
    this.lmthread = new Daemon(leaseManager.new Monitor());
    //创建副本管理线程
    this.replthread = new Daemon(new ReplicationMonitor());
    hbthread.start();
    lmthread.start();
    replthread.start();

    // 副本超额block管理线程
    this.overreplthread = new Daemon(new OverReplicationMonitor());
    overreplthread.start();

    this.hostsReader = new HostsFileReader(conf.get("dfs.hosts",""),
                                           conf.get("dfs.hosts.exclude",""));
    //创建退役节点管理线程
    this.dnthread = new Daemon(new DecommissionManager(this).new Monitor(
        conf.getInt("dfs.namenode.decommission.interval", 30),
        conf.getInt("dfs.namenode.decommission.nodes.per.interval", 5)));
    dnthread.start();

    this.dnsToSwitchMapping = ReflectionUtils.newInstance(
        conf.getClass("topology.node.switch.mapping.impl", ScriptBasedMapping.class,
            DNSToSwitchMapping.class), conf);

    /* If the dns to swith mapping supports cache, resolve network 
     * locations of those hosts in the include list, 
     * and store the mapping in the cache; so future calls to resolve
     * will be fast.
     */
    if (dnsToSwitchMapping instanceof CachedDNSToSwitchMapping) {
      dnsToSwitchMapping.resolve(new ArrayList&lt;String&gt;(hostsReader.getHosts()));
    }
    //创建副本定位器用于定位副本存放位置
    this.replicator = BlockPlacementPolicy.getInstance(
        conf,
        this,
        this.clusterMap,
        this.hostsReader,
        this.dnsToSwitchMapping,
        this);
  }
</code></pre>

<h2>FSDirectory(this, conf)</h2>

<p>新建FSDirecotry</p>

<pre><code> FSDirectory(FSNamesystem ns, Configuration conf) {
    //创建一个FSImage，并实例化构建FSDirectory
    this(new FSImage(), ns, conf);
    fsImage.setCheckpointDirectories(FSImage.getCheckpointDirs(conf, null),
                                FSImage.getCheckpointEditsDirs(conf, null));
  }
</code></pre>

<h3>this(new FSImage(), ns, conf);</h3>

<pre><code>FSDirectory(FSImage fsImage, FSNamesystem ns, Configuration conf) {
    this.bLock = new ReentrantReadWriteLock(); // non-fair
    this.cond = bLock.writeLock().newCondition();
    //创建根目录
    rootDir = new INodeDirectoryWithQuota(INodeDirectory.ROOT_NAME,
        ns.createFsOwnerPermissions(new FsPermission((short)0755)),
        Integer.MAX_VALUE, -1);
    this.fsImage = fsImage;
    namesystem = ns;
    initialize(conf);
  }
</code></pre>

<h3>FSDirectory.initialize()</h3>

<pre><code>  private void initialize(Configuration conf) {
    MetricsContext metricsContext = MetricsUtil.getContext("dfs");
    directoryMetrics = MetricsUtil.createRecord(metricsContext, "FSDirectory");
    directoryMetrics.setTag("sessionId", conf.get("session.id"));
  }
</code></pre>

<h3>FSDirectory.loadFSImage()</h3>

<pre><code>  void loadFSImage(Collection&lt;File&gt; dataDirs,
                   Collection&lt;File&gt; editsDirs,
                   StartupOption startOpt) throws IOException {
    // format before starting up if requested
    if (startOpt == StartupOption.FORMAT) {
      fsImage.setStorageDirectories(dataDirs, editsDirs);
      fsImage.format();
      startOpt = StartupOption.REGULAR;
    }
    try {
      //从datadir和editdirs加载FSImage
      if (fsImage.recoverTransitionRead(dataDirs, editsDirs, startOpt)) {
        fsImage.saveNamespace(true);
      }
      //初始化Editlog
      FSEditLog editLog = fsImage.getEditLog();
      assert editLog != null : "editLog must be initialized";
      if (!editLog.isOpen())
        editLog.open();
      fsImage.setCheckpointDirectories(null, null);
    } catch(IOException e) {
      fsImage.close();
      throw e;
    }
    writeLock();
    try {
      this.ready = true;
      cond.signalAll();
    } finally {
      writeUnlock();
    }
  }
</code></pre>

<h3>FSImage.recoverTransitionRead（）</h3>

<pre><code>  boolean recoverTransitionRead(Collection&lt;File&gt; dataDirs,
                             Collection&lt;File&gt; editsDirs,
                                StartupOption startOpt
                                ) throws IOException {
    assert startOpt != StartupOption.FORMAT : 
      "NameNode formatting should be performed before reading the image";

    // none of the data dirs exist
    if (dataDirs.size() == 0 || editsDirs.size() == 0)  
      throw new IOException(
        "All specified directories are not accessible or do not exist.");

    if(startOpt == StartupOption.IMPORT 
        &amp;&amp; (checkpointDirs == null || checkpointDirs.isEmpty()))
      throw new IOException("Cannot import image from a checkpoint. "
                          + "\"fs.checkpoint.dir\" is not set." );

    if(startOpt == StartupOption.IMPORT 
        &amp;&amp; (checkpointEditsDirs == null || checkpointEditsDirs.isEmpty()))
      throw new IOException("Cannot import image from a checkpoint. "
                          + "\"fs.checkpoint.edits.dir\" is not set." );

    setStorageDirectories(dataDirs, editsDirs);
    // 1.检查所有目录的状态和一致性
    Map&lt;StorageDirectory, StorageState&gt; dataDirStates = 
             new HashMap&lt;StorageDirectory, StorageState&gt;();
    boolean isFormatted = false;
    for (Iterator&lt;StorageDirectory&gt; it = 
                      dirIterator(); it.hasNext();) {
      StorageDirectory sd = it.next();
      StorageState curState;
      try {
        curState = sd.analyzeStorage(startOpt);
        // sd is locked but not opened
        switch(curState) {
        case NON_EXISTENT:
          // name-node fails if any of the configured storage dirs are missing
          throw new InconsistentFSStateException(sd.getRoot(),
                                                 "storage directory does not exist or is not accessible.");
        case NOT_FORMATTED:
          break;
        case NORMAL:
          break;
        default:  // recovery is possible
          sd.doRecover(curState);      
        }
        if (curState != StorageState.NOT_FORMATTED 
            &amp;&amp; startOpt != StartupOption.ROLLBACK) {
          sd.read(); // read and verify consistency with other directories
          isFormatted = true;
        }
        if (startOpt == StartupOption.IMPORT &amp;&amp; isFormatted)
          // import of a checkpoint is allowed only into empty image directories
          throw new IOException("Cannot import image from a checkpoint. " 
              + " NameNode already contains an image in " + sd.getRoot());
      } catch (IOException ioe) {
        sd.unlock();
        throw ioe;
      }
      dataDirStates.put(sd,curState);
    }

    if (!isFormatted &amp;&amp; startOpt != StartupOption.ROLLBACK 
                     &amp;&amp; startOpt != StartupOption.IMPORT)
      throw new IOException("NameNode is not formatted.");
    if (layoutVersion &lt; LAST_PRE_UPGRADE_LAYOUT_VERSION) {
      checkVersionUpgradable(layoutVersion);
    }
    if (startOpt != StartupOption.UPGRADE
          &amp;&amp; layoutVersion &lt; LAST_PRE_UPGRADE_LAYOUT_VERSION
          &amp;&amp; layoutVersion != FSConstants.LAYOUT_VERSION)
        throw new IOException(
                          "\nFile system image contains an old layout version " + layoutVersion
                          + ".\nAn upgrade to version " + FSConstants.LAYOUT_VERSION
                          + " is required.\nPlease restart NameNode with -upgrade option.");
    // check whether distributed upgrade is reguired and/or should be continued
    verifyDistributedUpgradeProgress(startOpt);

    // 2. Format unformatted dirs.
    this.checkpointTime = 0L;
    for (Iterator&lt;StorageDirectory&gt; it = 
                     dirIterator(); it.hasNext();) {
      StorageDirectory sd = it.next();
      StorageState curState = dataDirStates.get(sd);
      switch(curState) {
      case NON_EXISTENT:
        assert false : StorageState.NON_EXISTENT + " state cannot be here";
      case NOT_FORMATTED:
        LOG.info("Storage directory " + sd.getRoot() + " is not formatted.");
        LOG.info("Formatting ...");
        sd.clearDirectory(); // create empty currrent dir
        break;
      default:
        break;
      }
    }
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HDFS源码学习（1）——NameNode主要数据结构]]></title>
    <link href="http://jiangbo.me/blog/2012/10/18/hdfs-namenode-datastructure/"/>
    <updated>2012-10-18T11:04:00+08:00</updated>
    <id>http://jiangbo.me/blog/2012/10/18/hdfs-namenode-datastructure</id>
    <content type="html"><![CDATA[<h2>FSNameSystem</h2>

<p>FSNameSystem是HDFS文件系统实际执行的核心，提供各种增删改查文件操作接口。其内部维护多个数据结构之间的关系：</p>

<ol>
<li>fsname->block列表的映射</li>
<li>所有有效blocks集合</li>
<li>block与其所属的datanodes之间的映射（该映射是通过block reports动态构建的，维护在namenode的内存中。每个datanode在启动时向namenode报告其自身node上的block）</li>
<li>每个datanode与其上的blocklist的映射</li>
<li>采用心跳检测根据LRU算法更新的机器（datanode）列表</li>
</ol>


<h3>FSDirectory</h3>

<p>FSDirectory用于维护当前系统中的文件树。</p>

<p>其内部主要组成结构包括一个INodeDirectoryWithQuota作为根目录(rootDir)和一个FSImage来持久化文件树的修改操作。</p>

<h4>INode</h4>

<p>HDFS中文件树用类似VFS中INode的方式构建，整个HDFS中文件被表示为INodeFile，目录被表示为INodeDirectory。INodeDiretoryWithQuota是INodeDirectory的扩展类，即带配额的文件目录</p>

<p><img src="http://jiangbo.me/images/hdfs/INode.png" alt="INode" /></p>

<p>INodeFile表示INode书中的一个文件，扩展自INode，除了名字(name)，父节点(parent)等之外，一个主要元素是blocks，一个BlockInfo数组，表示该文件对应的block信息。</p>

<h3>BlocksMap</h3>

<p>BlocksMap用于维护Block -> { INode, datanodes, self ref } 的映射
<img src="http://jiangbo.me/images/hdfs/BlocksMap.png" alt="BlocksMap" />
BlocksMap结构比较简单，实际上就是一个Block到BlockInfo的映射。</p>

<h4>Block</h4>

<p>Block是HDFS中的基本读写单元，主要包括：</p>

<ol>
<li>blockId: 一个long类型的块id</li>
<li>numBytes: 块大小</li>
<li>generationStamp: 块更新的时间戳</li>
</ol>


<h4>BlockInfo</h4>

<p>BlockInfo扩展自Block，除基本信息外还包括一个inode引用，表示该block所属的文件；以及一个神奇的三元组数组Object[] triplets，用来表示保存该block的datanode信息，假设系统中的备份数量为3。那么这个数组结构如下：</p>

<p><img src="http://jiangbo.me/images/hdfs/triplets.png" alt="triplets" /></p>

<ol>
<li>DN1，DN2，DN3分别表示存有改block的三个datanode的引用(DataNodeDescriptor）</li>
<li>DN1-prev-blk表示在DN1上block列表中当前block的前置block引用</li>
<li>DN1-next-blk表示在DN1上block列表中当前block的后置block引用</li>
</ol>


<p>DN2,DN3的prev-blk和next-blk类似。
HDFS采用这种结构存放block->datanode list的信息主要是为了节省内存空间，block->datanodelist之间的映射关系需要占用大量内存，如果同样还要将datanode->blockslist的信息保存在内存中，同样要占用大量内存。采用三元组这种方式能够从其中一个block获得到改block所属的datanode上的所有block列表。</p>

<h4>FSImage</h4>

<p>FSImage用于持久化文件树的变更以及系统启动时加载持久化数据。
HDFS启动时通过FSImage来加载磁盘中原有的文件树，系统Standby之后，通过FSEditlog来保存在文件树上的修改，FSEditLog定期将保存的修改信息刷到FSImage中进行持久化存储。
FSImage中文件元信息的存储结构如下（参见FImage.saveFSImage()方法）</p>

<p><img src="http://jiangbo.me/images/hdfs/FSImage.png" alt="FSImage" /></p>

<h5>FSImage头部信息</h5>

<ol>
<li>layoutVersion(int):image layout版本号，0.19版本的hdfs中为-18</li>
<li>namespaceId(int): 命名空间ID，系统初始化时生成，在一个namenode生命周期内保持不变，datanode想namenode注册是返回改id作为registerId，以后每次datanode与namenode通信时都携带该id，不认识的id的请求将被拒绝。</li>
<li>numberItemOfTree(long): 系统中的文件总数</li>
<li>generationTimeStamp: 生成image的时间戳</li>
</ol>


<h5>INode信息</h5>

<p>FSImage头之后是numberItemOfTree个INode信息，INode信息分为文件(INodeFile)和文件目录(INodeDirectory)两类，两者大体一致，分为INode头，Blocks区（目录没有blocks）和文件权限。</p>

<p><strong>INode头</strong></p>

<ol>
<li>nameLen(short): 文件名长度</li>
<li>filename(String): 文件名</li>
<li>replication(short): 备份数量</li>
<li>modificationTime(long): 最近修改时间</li>
<li>accessTime(long): 最近访问时间</li>
<li>preferedBlockSize(long): 块大小（目录为0）</li>
<li>block num(int): 块数量（目录为-1）</li>
</ol>


<p><strong>Blocks区</strong></p>

<ol>
<li>blockId(long)</li>
<li>numBytes(long,block大小)</li>
<li>generationTimeStamp(long, 更新时间戳）</li>
</ol>


<p><strong>文件权限</strong></p>

<ol>
<li>username(String): 文件用户名</li>
<li>group(String): 所属组</li>
<li>fileperm(short): 文件权限</li>
</ol>


<h5>underconstructionFile区</h5>

<p>layoutverion&lt;-18版本的fsimage还包括正在构建的文件区。与普通Inode信息类似，均有inode头和blocks区以及文件权限，除此之外，underConstructionFile还包括：</p>

<p><strong>client信息</strong></p>

<ol>
<li>clientName：client明</li>
<li>clientMachine： client机器名</li>
</ol>


<p><strong>已分配的datanode信息</strong></p>

<ol>
<li>ipcport： 服务端口</li>
<li>capacity: 容量</li>
<li>dfsuse： 已使用的空间</li>
<li>remaining： 剩余空间</li>
<li>lastupdate： 最新更新时间</li>
<li>xceiverCount</li>
<li>location： datanode位置</li>
<li>hostName：主机名</li>
<li>state： admin管理状态</li>
</ol>


<h2>其他结构</h2>

<h3>CorruptReplicasMap</h3>

<p>CorruptReplicasMap通过一个TreeMap维护corrupt状态block的blocks&#8211;>datanodedescriptor(s)映射。一个block备份在多个datanode中，当其中的一个或多个datanode上的block损坏时，会将该datanode加到treeMap中该block对应的datanodeDescriptor集合中。FSNameSystem通过该Map来维护所有损坏的block与其对应datanode的关系。</p>

<h3>Map&lt;String, LightWeightHashSet<Block>> recentInvalidateSets</h3>

<p>维护最近失效的block集合，map中为storageId->ArrayList<Block>，当某个block的一个datanode上副本失效时会将改block和对应的datanode的storeageId添加到recentInvalidateSet中，当datanode想namenode进行heartbeat时，namenode会检查该datanode中是否有损坏的block，如有，则通知datanode删除改block。</p>

<h3>NavigableMap&lt;String, DatanodeDescriptor>  datanodeMap</h3>

<p>datanodeMap用于维护datanode->block的映射</p>

<h3>ArrayList<DatanodeDescriptor> heartbeats</h3>

<p>维护多有当前活着的节点</p>

<h3>UnderReplicatedBlocks neededReplications</h3>

<p>通过一个优先级队列来维护当前需要备份的block集合，副本数越少的block优先级越高，0为最高级，表示当前只有一个副本。</p>

<h3>PendingReplicationBlocks pendingReplications;</h3>

<p>维护当前正在备份的block集合，并且进行备份请求的时间统计，并通过一个后台线程（PendingReplicationMonitor）来周期性（默认为5分钟）的统计超时的备份请求，当发生超时时，会将这个block重新添加到neededReplications列表中。
<img src="http://jiangbo.me/images/hdfs/PendingReplicationBlocks.png" alt="PendingReplicationBlocks" /></p>

<h3>LightWeightLinkedSet<Block> overReplicatedBlocks</h3>

<p>当前需要检查是否备份过多的block集合</p>

<h3>Map&lt;String, Collection<Block>> excessReplicateMap</h3>

<p>维护系统中datanode与其上的超额备份block的集合，这些超额的备份将被删除。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[本地编译Hadoop小记]]></title>
    <link href="http://jiangbo.me/blog/2012/09/24/compile-hadoop/"/>
    <updated>2012-09-24T15:28:00+08:00</updated>
    <id>http://jiangbo.me/blog/2012/09/24/compile-hadoop</id>
    <content type="html"><![CDATA[<h2>Git源码</h2>

<pre><code>git clone git://git.apache.org/hadoop-common.git
</code></pre>

<p>视网速不通，略慢</p>

<h2>编译</h2>

<pre><code>cd hadoop-common
mvn install -DskipTests
</code></pre>

<p>抛异常：</p>

<pre><code>[ERROR] Failed to execute goal org.apache.maven.plugins:maven-antrun-plugin:1.6:run (compile-proto) on project hadoop-common: An Ant BuildException has occured: exec returned: 127 -&gt; [Help 1]
org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-antrun-plugin:1.6:run (compile-proto) on project hadoop-common: An Ant BuildException has occured: exec returned: 127
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:217)
    at... 
    Caused by: /Users/Shared/Workspace/hadoop/hadoop-common/hadoop-common-project/hadoop-common/target/antrun/build-main.xml:23: exec returned: 127
    at org.apache.tools.ant.taskdefs.ExecTask.runExecute(ExecTask.java:650)
    at org.apache.tools.ant.taskdefs.ExecTask.runExec(ExecTask.java:676)
    at org.apache.tools.ant.taskdefs.ExecTask.execute(ExecTask.java:502)
    at org.apache.tools.ant.UnknownElement.execute(UnknownElement.java:291)
    at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)
    ... 21 more
</code></pre>

<p>原因是缺少protocol buffer， 找不到protoc命令。</p>

<h3>安装protocol buffer</h3>

<pre><code>wget https://protobuf.googlecode.com/files/protobuf-2.4.1.tar.bz2
tar -xvf protobuf-2.4.1.tar.bz2
cd protobuf-2.4.1
./configure &amp;&amp; make
make install
</code></pre>

<h3>导入Eclipse</h3>

<pre><code>mvn eclipse:eclipse -DdownloadSources=true -DdownloadJavadocs=true
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[关于Memcache内存管理模型的理解]]></title>
    <link href="http://jiangbo.me/blog/2012/08/31/something-about-memcache-internal/"/>
    <updated>2012-08-31T07:52:00+08:00</updated>
    <id>http://jiangbo.me/blog/2012/08/31/something-about-memcache-internal</id>
    <content type="html"><![CDATA[<script async class="speakerdeck-embed" data-id="504049be5ec53c000202daa6" data-ratio="1.299492385786802" src="http://jiangbo.me//speakerdeck.com/assets/embed.js"></script>


<h2>说在前面</h2>

<p>本文不包含为什么使用memcache，以及如何使用memcache等基础知识。相关知识请查阅各类手册。
另，为便于理解，最好手头准备一份memcache的源码，本文使用的是目前最新的1.4.4版本源码，可自行到github上clone。</p>

<h2>Item、Chunk、Page、Slab</h2>

<h3>Data Item</h3>

<pre><code>+---------------------------------------+
|  key-value | cas | suffix | item head |  
+---------------------------------------+
</code></pre>

<p>Item指实际存放到memcache中的数据对象结构，除key-value数据外，还包括memcache自身对数据对象的描述信息（Item=key+value+后缀长+32byte结构体）</p>

<h3>Chunk</h3>

<p>Chunk指Memcache用来存放Data Item的最小单元，同一个Slab中的chunk大小是固定的。</p>

<pre><code>+------------------------------+
|   data item    | empty space |
+------------------------------+
</code></pre>

<h2>Page</h2>

<pre><code>+-------------------------------------+
|  chunk1 | chunk2 | chunk3 | chunk4  |
+-------------------------------------+
</code></pre>

<p>每个Slab中按照Page来申请内存，Page的大小默认为1M，可以通过-l参数调整，最小1k，最大128m.</p>

<h3>Slab</h3>

<pre><code>+--------------------------------+
|  Page1 | Page2 | Page3 | Page4 |
+--------------------------------+
</code></pre>

<p>Memcache将分配给它的内存（-m 参数指定，默认64m）按照Chunk大小不同，划分为多个slab。</p>

<p>他们三者的关系如下图所示:</p>

<pre><code>                 Chunk
                   ^                                                         
+------------------|------------------------------------------------------------+
|   Memory         |                                                            | 
|  +---------------|---------------------------------------------------------+  |
|  |      +--------|---------------------+  +------------------------------+ |  |
|  |      |Page1 +-|---+ +-----+ +-----+ |  |Page2 +-----+ +-----+ +-----+ | |  |
|  | Slab |(1M)  | 96B | | 68B | | 72B | |  |(1M)  | 92B | | 76B | | 84B | | |  | 
|  |  1   |      +-----+ +-----+ +-----+ |  |      +-----+ +-----+ +-----+ | |  |
|  |      +------------------------------+  +------------------------------+ |  |
|  +-------------------------------------------------------------------------+  |
|                                                                               |
|  +-------------------------------------------------------------------------+  |
|  |      +------------------------------+  +------------------------------+ |  |
|  |      |Page1 +------+    +------+    |  |Page2 +------+    +-------+   | |  |
|  | Slab | (1M) | 128B |    | 120B |    |  |(1M)  | 128B |    | 97B   |   | |  |
|  |   2  |      +------+    +------+    |  |      +------+    +-------+   | |  |
|  |      +------------------------------+  +------------------------------+ |  |
|  +-------------------------------------------------------------------------+  |
+-------------------------------------------------------------------------------+
</code></pre>

<h2>Slab内存分配</h2>

<h3>slab初始化</h3>

<p>Memcache启动时会进行slab初始化（参见slabs.c中slabs_init()函数），默认最小的chunksize为80（查看源码会发现settings中chunk_size默认为48，但是实际还需要加上一个32bytes的item结构体），可以通过-n参数调整，按照然后按照factor（默认为1.25，可以通过-f参数调整）(<em>关于参数更多的memcache默认参数可以参考memcache.c中settings的设置</em>)比例递增，划分出多个不同chunk大小的slab空间，即slab1的chunk大小=80，slab2的chunk大小为80*1.25=100，slab3的chunk大小为80*1.25*1.25=125，但最大一个一个chunk不会大于一个Page的大小（默认1M）。</p>

<pre><code>一下代码节选自 slabs.c
 95 void slabs_init(const size_t limit, const double factor, const bool prealloc) {
 96     int i = POWER_SMALLEST - 1;
 97     unsigned int size = sizeof(item) + settings.chunk_size;
 98  
 99     mem_limit = limit;
100  
101     if (prealloc) {
102         /* Allocate everything in a big chunk with malloc */
103         mem_base = malloc(mem_limit);
104         if (mem_base != NULL) {
105             mem_current = mem_base;
106             mem_avail = mem_limit;
107         } else {
108             fprintf(stderr, "Warning: Failed to allocate requested memory in"
109                     " one large chunk.\nWill allocate in smaller chunks\n");
110         }
111     }
112  
113     memset(slabclass, 0, sizeof(slabclass));
114  
115     while (++i &lt; POWER_LARGEST &amp;&amp; size &lt;= settings.item_size_max / factor) {
116         /* Make sure items are always n-byte aligned */
117         if (size % CHUNK_ALIGN_BYTES)
118             size += CHUNK_ALIGN_BYTES - (size % CHUNK_ALIGN_BYTES);
119  
120         slabclass[i].size = size;
121         slabclass[i].perslab = settings.item_size_max / slabclass[i].size;
122         size *= factor;
123         if (settings.verbose &gt; 1) {
124             fprintf(stderr, "slab class %3d: chunk size %9u perslab %7u\n",
125                     i, slabclass[i].size, slabclass[i].perslab);
126         }
127     }
128  
129     power_largest = i;
130     slabclass[power_largest].size = settings.item_size_max;
131     slabclass[power_largest].perslab = 1;
132     if (settings.verbose &gt; 1) {
133         fprintf(stderr, "slab class %3d: chunk size %9u perslab %7u\n",
134                 i, slabclass[i].size, slabclass[i].perslab);
135     }
136  
137     /* for the test suite:  faking of how much we've already malloc'd */
138     {
139         char *t_initial_malloc = getenv("T_MEMD_INITIAL_MALLOC");
140         if (t_initial_malloc) {
141             mem_malloced = (size_t)atol(t_initial_malloc);
142         }
143  
144     }
145  
146     if (prealloc) {
147         slabs_preallocate(power_largest);
148     }
149 }                             
</code></pre>

<p>PS：prealloc指的是直接申请一个大的chunk存放所有数据，默认是不采用这种方式的。</p>

<h3>数据存储过程</h3>

<p>一个数据项的大致存储量过程可以理解为（完整代码较长，不在粘贴，具体可参见items.c中do_item_alloc()方法）：</p>

<ol>
<li>构造一个数据项结构体，计算数据项的大小，（假设默认配置下，数据项大小为102B）</li>
<li>根据数据项的大小，找到最合适的slab，（100&lt;102&lt;125，所以存储在slab3中）</li>
<li>检查该slab中是否有过期的数据，如有清理掉</li>
<li>如果没有过期的数据项，则从当前slab中申请空间，参见slabs.c中slab_alloc()方法。</li>
<li>如果当前slab中申请失败，则尝试根据LRU算法逐出一个数据项，默认memcache是允许逐出的，如果被设置为禁止逐出，那么这是会反生悲剧的oom了</li>
<li>获取到item空间后将数据存储到改空间中，并追加到该slab的item列表中</li>
</ol>


<p>一个slab的申请一个chunk空间的过程大致如下（以下代码节选自slabs.c）：</p>

<pre><code>195 static int do_slabs_newslab(const unsigned int id) { 
196     slabclass_t *p = &amp;slabclass[id];
197     int len = settings.slab_reassign ? settings.item_size_max
198         : p-&gt;size * p-&gt;perslab;
199     char *ptr;             
200            
201     if ((mem_limit &amp;&amp; mem_malloced + len &gt; mem_limit &amp;&amp; p-&gt;slabs &gt; 0) ||
202         (grow_slab_list(id) == 0) ||    
203         ((ptr = memory_allocate((size_t)len)) == 0)) {
204            
205         MEMCACHED_SLABS_SLABCLASS_ALLOCATE_FAILED(id);
206         return 0;          
207     }      
208            
209     memset(ptr, 0, (size_t)len);    
210     split_slab_page_into_freelist(ptr, id);
211            
212     p-&gt;slab_list[p-&gt;slabs++] = ptr; 
213     mem_malloced += len;   
214     MEMCACHED_SLABS_SLABCLASS_ALLOCATE(id);
215            
216     return 1;              
217 }
218  
219 /*@null@*/ 
220 static void *do_slabs_alloc(const size_t size, unsigned int id) {
221     slabclass_t *p;        
222     void *ret = NULL;      
223     item *it = NULL;       
224  
225     if (id &lt; POWER_SMALLEST || id &gt; power_largest) {
226         MEMCACHED_SLABS_ALLOCATE_FAILED(size, 0);
227         return NULL;
228     }
229  
230     p = &amp;slabclass[id];
231     assert(p-&gt;sl_curr == 0 || ((item *)p-&gt;slots)-&gt;slabs_clsid == 0);
232  
233     /* fail unless we have space at the end of a recently allocated page,
234        we have something on our freelist, or we could allocate a new page */
235     if (! (p-&gt;sl_curr != 0 || do_slabs_newslab(id) != 0)) {
236         /* We don't have more memory available */
237         ret = NULL;
238     } else if (p-&gt;sl_curr != 0) {
239         /* return off our freelist */
240         it = (item *)p-&gt;slots;
241         p-&gt;slots = it-&gt;next;
242         if (it-&gt;next) it-&gt;next-&gt;prev = 0;
243         p-&gt;sl_curr--;
244         ret = (void *)it;
245     }
246  
247     if (ret) {
248         p-&gt;requested += size;
249         MEMCACHED_SLABS_ALLOCATE(size, id, p-&gt;size, ret);
250     } else {
251         MEMCACHED_SLABS_ALLOCATE_FAILED(size, id);
252     }
253  
254     return ret;
255 }
</code></pre>

<p>slab优先从slots（空闲chunk空间列表）中申请空间，如果没有则尝试申请一个Page的新空间（do_slab_newslab()），申请新slab是会先判断是否进行slab_reasgin（重新分配slab空间，默认不开启）。</p>

<h2>内存浪费</h2>

<p>根据上述描述，Memcache使用Slab预分配的方式进行内存管理提升了性能（减少分配内存的消耗），但是带来了内存浪费，主要体现在：</p>

<ol>
<li><p>Data Item Size &lt;= Chunk Size，Chunk是存储数据项的最小单元，数据项的大小必须不大于其所在的Chunk大小。也就是说76B的数据对象存入96B的Chunk中，将带来96B-76B=20B的空间浪费。</p></li>
<li><p>Memcache是按照Page申请和使用内存的，当Page大小不是Chunk的整数倍时，余下的空间将被浪费。即如果PageSize=1M，ChunkSize=1000B,那么将有1024*1024%1000=576B的空间浪费。</p></li>
<li><p>Memcache默认是不开启slab reasign的，也就是说分配已经分配给一个slab的内存空间，即使该slab不用，默认也不会分配给其他slab的</p></li>
</ol>


<h2>案例分析：定长问题导致逐出</h2>

<p>memcache的chunk分布是均匀的，这是为了通用性考虑，但是现实中一些场景chunk的分布是不均运的，例如为了减小对数据库的压力，对数据进行了全量缓存，为标识数据库中不存在的记录，向缓存中放置了一个stupidObject。这个对象大小是固定的，且该数据的量很大，导致该数据类型所在的slab占用了大量缓存空间。再一次调整对象结构时，修改了这个StupidObject大小，使其分布在另一个slab中，但是这个原分配的slab空间不会回收，空闲空间不足，导致大量逐出。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用方法链和静态工厂构造流畅接口]]></title>
    <link href="http://jiangbo.me/blog/2012/04/08/build-fluent-interface-with-method-chain-and-static-factory/"/>
    <updated>2012-04-08T11:23:00+08:00</updated>
    <id>http://jiangbo.me/blog/2012/04/08/build-fluent-interface-with-method-chain-and-static-factory</id>
    <content type="html"><![CDATA[<h3>问题现象</h3>

<p>现有的VO，DO，Model等模型类中，均遵循JavaBean规范，为对属性的访问提供了getter和setter方法，并且在实际使用时通常为构造一个模型实例，需要调用大段的setter方法。下面以VasViewVO为例：</p>

<pre><code>public class VasViewVO {

    private String description;

    private Date gmtOpen;

    private Date gmtClose;

    private CreditVasType serviceType;

    private CreditVasMemberStatus creditVasMemberStatus;
    ...//此处省略getter和setter方法
}
</code></pre>

<p>通常按照如下方式构造一个VasViewVO实例：</p>

<pre><code>    VasViewVO vasViewVO = new VasViewVO();
    vasViewVO.setCreditVasMemberStatus(CreditVasMemberStatus.OPEN);
    vasViewVO.setGmtOpen(new Date());
    vasViewVO.setServiceType(CreditVasType.fastpay);
    vasViewVO.setDescription("open fastpay");
    //do something with vasViewVO
</code></pre>

<p>如此构造VasViewVO的实例并非有严重的逻辑错误或者其他的问题，只是不够简洁易懂（贴近自然语言）。
最近学习过jQuery的都知道，jQuery中可以按如下方式连续调用api</p>

<pre><code>    $("p").hide().fadeIn("slow").slideUp("slow").slideDown("slow");
</code></pre>

<p>如果Java程序中也可以使用类似的方式将会简洁许多。</p>

<h3>解决方法</h3>

<h4>使用方法链</h4>

<p>jQuery中之所以能够连续调用api，主要是因为每个方法返回的都是一个jQuery对象。Java本身也可这样做，即返回一个this(自身引用)，也就是常说的<a href="http://en.wikipedia.org/wiki/Method_chaining">方法链</a>。
方法链的实现非常简单，通常的setter方法返回void，方法链返回的是this引用，如下：</p>

<pre><code>    public VasViewVO description(String description) {
        this.description = description;
        return this;
    }

    public VasViewVO gmtOpen(Date gmtOpen) {
        this.gmtOpen = gmtOpen;
        return this;
    }

    public VasViewVO gmtClose(Date gmtClose) {
        this.gmtClose = gmtClose;
        return this;
    }

    public VasViewVO serviceType(CreditVasType serviceType) {
        this.serviceType = serviceType;
        return this;
    }
</code></pre>

<p>如此一来在调用时只需要新建一个对象，连续调用赋值方法即可：</p>

<pre><code>    VasViewVO vasView = new VasViewVO();
    vasView.creditVasMemberStatus(CreditVasMemberStatus.CLOSE)
            .description("Commoent cxxx").gmtClose(new Date())
            .gmtOpen(new Date()).serviceType(CreditVasType.fastpay);
</code></pre>

<p>如此相比连续调用5次setter方法简洁的多。</p>

<h4>使用静态工厂和static import优化</h4>

<p>使用方法链之后简化了setter调用，但是每次还必须要先new一个实例，略显繁琐。这个问题可以通过Effectvie Java的第一条静态工厂来解决，即在VasViewVO内部实现一个静态工厂方法。</p>

<pre><code>    public static VasViewVO with() {
        return new VasViewVO();
    }
</code></pre>

<p>这个with的方法名与一般的静态工厂所用的getInstance，newInstance不同，主要时为了更加贴近自然语言。
如此，构造一个VasViewVO实例就可简化为</p>

<pre><code>    VasViewVO vasViewVO = VasViewVO.with()
                .creditVasMemberStatus(CreditVasMemberStatus.CLOSE)
                .description("Commoent cxxx").gmtClose(new Date())
                .gmtOpen(new Date()).serviceType(CreditVasType.fastpay);
</code></pre>

<p>代码已经很简洁，不过每次都是用枚举类长长的类名，感觉很是不雅，可以通过static import解决，最终的到的简化后构造一个VasViewVO实例的代码如下：</p>

<pre><code>import static  com.alibaba.china.credit.common.constants.CreditVasType.*;
import static com.alibaba.china.credit.vas.dal.constant.CreditVasMemberStatus.*;
public class Test{
    public static void main(String[] args) {
        . . .

        VasViewVO vasViewVO = VasViewVO.with()
            .creditVasMemberStatus(CLOSE)
            .description("Commoent cxxx").gmtClose(new Date())
            .gmtOpen(new Date()).serviceType(fastpay);
        . . .
    }
}
</code></pre>

<h3>进阶总结</h3>

<p>程序设计要解决的是讲现实世界中的问题描述转化为计算机可识别的计算机语言（二进制码），因此编程语言必须为这一转化过程提供有效的抽像机制。现有编程语言提供的抽象机制侧重各有不同，在C，C++，JAVA等通用语言中更关注语言的基本语义，离实际的问题域描述较远；SQL，CSS等特定领域语言更关注特定问题域问题的抽象，更贴近实际的问题描述。</p>

<p>站在人的角度，语言越是贴近实际问题的描述越是容易理解，对问题的描述也更加准确。但现有的特定领域语言又不具备通用变成语言解决问题的的通用性，因此我们更希望能够在通用语言上进行更高层次的抽象，使其更加贴近具体的问题域。某种程度上讲语言提供的API或者方法库就是对基本问题的更高层次抽象，但离具体的问题域还是太远，有时我们更渴望更加贴近具体问题的语言来解决问题并兼具通用语言的通用性，因此诞生了通用语言的内部DSL。
<a href="http://www.martinfowler.com/bliki/FluentInterface.html">流畅接口（Fluent Interface）</a>是实现内部DSL的重要手段，<a href="http://en.wikipedia.org/wiki/Fluent_interface">wikipedia上如此描述</a>Fluent Interface：</p>

<pre><code>A fluent interface (as first coined by Eric Evans and Martin Fowler) is an implementation of an object oriented API that aims to provide for more readable code. A fluent interface is normally implemented by using method chaining to relay the instruction context of a subsequent call (but a fluent interface entails more than just method chaining)。
</code></pre>

<p>方法链（method chain）是实现Fluent Interface的重要手段（注意，method chain!= Fluent Interface!=DSL）。但仅仅有方法链是不足够构建有效的DSL的，除此之外还需要一些且他编程技巧，比如static factory和static import等，具体请参见<a href="http://www.infoq.com/articles/internal-dsls-java">《An Approach to Internal Domain－Specific Languages in Java》</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[java.lang.instrument笔记]]></title>
    <link href="http://jiangbo.me/blog/2012/02/21/java-lang-instrument/"/>
    <updated>2012-02-21T17:13:00+08:00</updated>
    <id>http://jiangbo.me/blog/2012/02/21/java-lang-instrument</id>
    <content type="html"><![CDATA[<h2>什么是Instrumentation？</h2>

<p>java Instrumentation指的是可以用独立于应用程序之外的代理（agent）程序来监测和协助运行在JVM上的应用程序。这种监测和协助包括但不限于获取JVM运行时状态，替换和修改类定义等。
Java SE5中使用JVM TI替代了JVM PI和JVM DI。提供一套代理机制，支持独立于JVM应用程序之外的程序以代理的方式连接和访问JVM。java.lang.instrument是在JVM TI的基础上提供的Java版本的实现。
Instrumentation提供的主要功能是修改jvm中类的行为。
Java SE6中由两种应用Instrumentation的方式，premain（命令行）和agentmain（运行时）</p>

<h2>premain方式</h2>

<p>在Java SE5时代，Instrument只提供了premain一种方式，即在真正的应用程序（包含main方法的程序）main方法启动前启动一个代理程序。例如使用如下命令：</p>

<pre><code>java -javaagent:agent_jar_path[=options] java_app_name
</code></pre>

<p>可以在启动名为java_app_name的应用之前启动一个agent_jar_path指定位置的agent jar。
实现这样一个agent jar包，必须满足两个条件：</p>

<ol>
<li>在这个jar包的manifest文件中包含Premain-Class属性，并且改属性的值为代理类全路径名。</li>
<li>代理类必须提供一个public static void premain(String args, Instrumentation inst)或 public static void premain(String args) 方法。</li>
</ol>


<p>当在命令行启动该代理jar时，VM会根据manifest中指定的代理类，使用于main类相同的系统类加载器（即ClassLoader.getSystemClassLoader()获得的加载器）加载代理类。在执行main方法前执行premain()方法。如果premain(String args, Instrumentation inst)和premain(String args)同时存在时，优先使用前者。其中方法参数args即命令中的options，类型为String（注意不是String[]），因此如果需要多个参数，需要在方法中自己处理（比如用&#8221;;&#8221;分割多个参数之类）；inst是运行时由VM自动传入的Instrumentation实例，可以用于获取VM信息。</p>

<h2>premain实例-打印所有的方法调用</h2>

<p>下面实现一个打印程序执行过程中所有方法调用的功能，这个功能可以通过AOP其他方式实现，这里只是尝试使用Instrumentation进行ClassFile的字节码转换实现：</p>

<h3>构造agent类</h3>

<p>premain方式的agent类必须提供premain方法，代码如下：</p>

<pre><code>package test;

import java.lang.instrument.Instrumentation;

public class Agent {

    public static void premain(String args, Instrumentation inst){
        System.out.println("Hi, I'm agent!");
        inst.addTransformer(new TestTransformer());
    }
}
</code></pre>

<p>premain有两个参数，args为自定义传入的代理类参数，inst为VM自动传入的Instrumentation实例。 premain方法的内容很简单，除了标准输出外，只有</p>

<pre><code>inst.addTransformer(new TestTransformer());
</code></pre>

<p>这行代码的意思是向inst中添加一个类的转换器。用于转换类的行为。</p>

<h3>构造Transformer</h3>

<p>下面来实现上述过程中的TestTransformer来完成打印调用方法的类定义转换。</p>

<pre><code>package test;

import java.lang.instrument.ClassFileTransformer;
import java.lang.instrument.IllegalClassFormatException;
import java.security.ProtectionDomain;

import org.objectweb.asm.ClassReader;
import org.objectweb.asm.ClassWriter;
import org.objectweb.asm.Opcodes;
import org.objectweb.asm.tree.ClassNode;
import org.objectweb.asm.tree.FieldInsnNode;
import org.objectweb.asm.tree.InsnList;
import org.objectweb.asm.tree.LdcInsnNode;
import org.objectweb.asm.tree.MethodInsnNode;
import org.objectweb.asm.tree.MethodNode;

public class TestTransformer implements ClassFileTransformer {

    @Override
    public byte[] transform(ClassLoader arg0, String arg1, Class&lt;?&gt; arg2,
            ProtectionDomain arg3, byte[] arg4)
            throws IllegalClassFormatException {
        ClassReader cr = new ClassReader(arg4);
        ClassNode cn = new ClassNode();
        cr.accept(cn, 0);
        for (Object obj : cn.methods) {
            MethodNode md = (MethodNode) obj;
            if ("&lt;init&gt;".endsWith(md.name) || "&lt;clinit&gt;".equals(md.name)) {
                continue;
            }
            InsnList insns = md.instructions;
            InsnList il = new InsnList();
            il.add(new FieldInsnNode(Opcodes.GETSTATIC, "java/lang/System",
                    "out", "Ljava/io/PrintStream;"));
            il.add(new LdcInsnNode("Enter method-&gt; " + cn.name+"."+md.name));
            il.add(new MethodInsnNode(Opcodes.INVOKEVIRTUAL,
                    "java/io/PrintStream", "println", "(Ljava/lang/String;)V"));
            insns.insert(il);
            md.maxStack += 3;

        }
        ClassWriter cw = new ClassWriter(0);
        cn.accept(cw);
        return cw.toByteArray();
    }

}
</code></pre>

<p>TestTransformer实现了ClassFileTransformer接口，该接口只有一个transform方法，参数传入包括该类的类加载器，类名，原字节码字节流等，返回被转换后的字节码字节流。
TestTransformer主要使用ASM实现在所有的类定义的方法中，在方法开始出添加了一段打印该类名和方法名的字节码。在转换完成后返回新的字节码字节流。详细的ASM使用请参考ASM手册。</p>

<h3>设置MANIFEST.MF</h3>

<p>设置MANIFEST.MF文件中的属性，文件内容如下：</p>

<pre><code>Manifest-Version: 1.0
Premain-Class: test.Agent
Created-By: 1.6.0_29
</code></pre>

<h3>测试</h3>

<p>代码编写完成后将代码编译打成agent.jar。
编写测试代码：</p>

<pre><code>public class TestAgent {

    public static void main(String[] args) {
        TestAgent ta = new TestAgent();
        ta.test();
    }

    public void test() {
        System.out.println("I'm TestAgent");
    }

}
</code></pre>

<p>从命令行执行该类，并设置agent.jar</p>

<pre><code>java -javaagent:agent.jar TestAgent
</code></pre>

<p>将打印出程序运行过程中实际执行过的所有方法名：</p>

<pre><code>Hi, I'm agent!
Enter method-&gt; test/TestAgent.main
Enter method-&gt; test/TestAgent.test
I'm TestAgent
Enter method-&gt; java/util/IdentityHashMap$KeySet.iterator
Enter method-&gt; java/util/IdentityHashMap$IdentityHashMapIterator.hasNext
Enter method-&gt; java/util/IdentityHashMap$KeyIterator.next
Enter method-&gt; java/util/IdentityHashMap$IdentityHashMapIterator.nextIndex
Enter method-&gt; java/util/IdentityHashMap$IdentityHashMapIterator.hasNext
Enter method-&gt; java/util/IdentityHashMap$KeySet.iterator
Enter method-&gt; java/util/IdentityHashMap$IdentityHashMapIterator.hasNext
Enter method-&gt; java/util/IdentityHashMap$KeyIterator.next
Enter method-&gt; java/util/IdentityHashMap$IdentityHashMapIterator.nextIndex
Enter method-&gt; com/apple/java/Usage$3.run
。。。
</code></pre>

<p>从输出中可以看出，程序首先执行的是代理类中的premain方法（不过代理类自身不会被自己转换，所以不能打印出代理类的方法名），然后是应用程序中的main方法。</p>

<h2>agentmain方式</h2>

<p>premain时Java SE5开始就提供的代理方式，给了开发者诸多惊喜，不过也有些须不变，由于其必须在命令行指定代理jar，并且代理类必须在main方法前启动。因此，要求开发者在应用前就必须确认代理的处理逻辑和参数内容等等，在有些场合下，这是比较苦难的。比如正常的生产环境下，一般不会开启代理功能，但是在发生问题时，我们不希望停止应用就能够动态的去修改一些类的行为，以帮助排查问题，这在应用启动前是无法确定的。
为解决运行时启动代理类的问题，Java SE6开始，提供了在应用程序的VM启动后在动态添加代理的方式，即agentmain方式。
与Permain类似，agent方式同样需要提供一个agent jar，并且这个jar需要满足：</p>

<ol>
<li>在manifest中指定Agent-Class属性，值为代理类全路径</li>
<li>代理类需要提供public static void agentmain(String args, Instrumentation inst)或public static void agentmain(String args)方法。并且再二者同时存在时以前者优先。args和inst和premain中的一致。</li>
</ol>


<p>不过如此设计的再运行时进行代理有个问题——如何在应用程序启动之后再开启代理程序呢？
JDK6中提供了Java Tools API，其中Attach API可以满足这个需求。</p>

<p>Attach API中的VirtualMachine代表一个运行中的VM。其提供了loadAgent()方法，可以在运行时动态加载一个代理jar。具体需要参考<a href="">《Attach API》</a></p>

<h2>agentmain实例-打印当前已加载的类</h2>

<h3>构造agent类</h3>

<p>agentmain方式的代理类必须提供agentmain方法：</p>

<pre><code>package loaded;

import java.lang.instrument.Instrumentation;

public class LoadedAgent {
    @SuppressWarnings("rawtypes")
    public static void agentmain(String args, Instrumentation inst){
        Class[] classes = inst.getAllLoadedClasses();
        for(Class cls :classes){
            System.out.println(cls.getName());
        }
    }
}
</code></pre>

<p>agentmain方法通过传入的Instrumentation实例获取当前系统中已加载的类。</p>

<h3>设置MANNIFEST.MF</h3>

<p>设置MANIFEST.MF文件，指定Agent-Class:</p>

<pre><code>Manifest-Version: 1.0
Agent-Class: loaded.LoadedAgent
Created-By: 1.6.0_29
</code></pre>

<h3>绑定到目标VM</h3>

<p>将agent类和MANIFEST.MF文件编译打成loadagent.jar后，由于agent main方式无法向pre main方式那样在命令行指定代理jar，因此需要借助Attach Tools API。</p>

<pre><code>package attach;

import java.io.IOException;

import com.sun.tools.attach.AgentInitializationException;
import com.sun.tools.attach.AgentLoadException;
import com.sun.tools.attach.AttachNotSupportedException;
import com.sun.tools.attach.VirtualMachine;

public class Test {
    public static void main(String[] args) throws AttachNotSupportedException,
            IOException, AgentLoadException, AgentInitializationException {
        VirtualMachine vm = VirtualMachine.attach(args[0]);
        vm.loadAgent("/Users/jiangbo/Workspace/code/java/javaagent/loadagent.jar");

    }

}
</code></pre>

<p>该程序接受一个参数为目标应用程序的进程id，通过Attach Tools API的VirtualMachine.attach方法绑定到目标VM，并向其中加载代理jar。</p>

<h3>构造目标测试程序</h3>

<p>构造一个测试用的目标应用程序：</p>

<pre><code>package attach;

public class TargetVM {
    public static void main(String[] args) throws InterruptedException{
        while(true){
            Thread.sleep(1000);
        }
    }
}
</code></pre>

<p>这个测试程序什么都不做，只是不停的sleep。:)
运行该程序，获得进程ID=33902。
运行上面绑定到VM的Test程序，将进程id作为参数传入：</p>

<pre><code>java attach.Test 33902
</code></pre>

<p>观察输出，会打印出系统当前所有已经加载类名</p>

<pre><code>java.lang.NoClassDefFoundError
java.lang.StrictMath
java.security.SignatureSpi
java.lang.Runtime
java.util.Hashtable$EmptyEnumerator
sun.security.pkcs.PKCS7
java.lang.InterruptedException
java.io.FileDescriptor$1
java.nio.HeapByteBuffer
java.lang.ThreadGroup
[Ljava.lang.ThreadGroup;
java.io.FileSystem
。。。
</code></pre>

<h2>参考文档</h2>

<ul>
<li><a href="http://docs.oracle.com/javase/6/docs/api/java/lang/instrument/package-summary.html">java.lang.instrument API docs</a></li>
<li><a href="https://blogs.oracle.com/CoreJavaTechTips/entry/the_attach_api">The Attach API</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/java/j-lo-jse61/index.html">Java SE6新特性：Instrumentation新功能</a></li>
</ul>


<h2>附：agent jar中manifest的属性</h2>

<ul>
<li>Premain-Class: 当在VM启动时，在命令行中指定代理jar时，必须在manifest中设置Premain-Class属性，值为代理类全类名，并且该代理类必须提供premain方法。否则JVM会异常终止。</li>
<li>Agent-Class: 当在VM启动之后，动态添加代理jar包时，代理jar包中manifest必须设置Agent-Class属性，值为代理类全类名，并且该代理类必须提供agentmain方法，否则无法启动该代理。</li>
<li>Boot-Class-Path: Bootstrap class loader加载类时的搜索路径，可选。</li>
<li>Can-Redefine-Classes: true/false；标示代理类是否能够重定义类。可选。</li>
<li>Can-Retransform-Classes: true/false；标示代理类是否能够转换类定义。可选。</li>
<li>Can-Set-Native-Prefix::true/false；标示代理类是否需要本地方法前缀，可选。</li>
</ul>


<p><strong> 当一个代理jar包中的manifest文件中既有Premain-Class又有Agent-Class时，如果以命令行方式在VM启动前指定代理jar，则使用Premain-Class；反之如果在VM启动后，动态添加代理jar，则使用Agent-Class </strong></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Jetty ClassLoader解析]]></title>
    <link href="http://jiangbo.me/blog/2012/02/14/jetty-classloader/"/>
    <updated>2012-02-14T00:26:00+08:00</updated>
    <id>http://jiangbo.me/blog/2012/02/14/jetty-classloader</id>
    <content type="html"><![CDATA[<h2>什么是类加载器？</h2>

<p>类加载器（ClassLoader）指将类加载到虚拟机中的代码模块，所有的类必须通过加载器被加载到JVM中。JVM规范将累加在的过程外置于JVM实现，让应用程序自己决定如何获取所需类，这种机制位类层次划分，热加载，模块化奠定了基础。</p>

<h2>类加载器分类</h2>

<p>类加载器主要分为：</p>

<ul>
<li>启动类加载器(Bootstrap ClassLoader)：主要负责加载<JAVA_HOME>\lib目录中或者-Xbootclasspath中指定的，并且被虚拟机识别的类库加载到VM中。这个加载器是JVM自身的一部分，用本地代码实现的(openjdk中源码位于hotspot/src/share/vm/classfile/classLoader.cpp中)，无法直接被java代码引用。</li>
<li>扩展类加载器(Extension ClassLoader)：主要负责加载jdk扩展类库<JAVA_HOME>\lib\ext或者java.ext.dirs系统属性指定的目录中jar文件，由sun.misc.Launcher$ExtClassLoader实现</li>
<li>系统类加载器(System ClassLoader)：用于加载CLASSPATH中指定的类，由sun.misc.Launcher$AppClassLoader实现。该类即ClassLoader.getSystemLoader()的返回值，是应用程序默认的类加载器。</li>
<li>自定义加载器(User ClassLoader)：用户可以自定义自己的类加载器</li>
</ul>


<h2>双亲委托模型</h2>

<p>JDK中要求所有的自定义ClassLoader 必须扩展自抽象类java.lang.ClassLoader。该类的文档说名中有一个段关于delegate model的描述：</p>

<blockquote><p>The ClassLoader class uses a <code>delegation model</code> to search for classes and resources. Each instance of ClassLoader has an associated parent class loader. When requested to find a class or resource, a ClassLoader instance will delegate the search for the class or resource to its parent class loader before attempting to find the class or resource itself. The virtual machine&#8217;s built-in class loader, called the &#8220;bootstrap class loader&#8221;, does not itself have a parent but may serve as the parent of a ClassLoader instance.</p></blockquote>

<p>简单来说这个delegate model要求除了Bootstrap ClassLoader之外，其余ClassLoader都需要关联一个parent ClassLoader（这种关联方式采用的时组合而非继承），在执行加载class时，首先委托给parent ClassLoader加载，只有当parent ClassLoader无法加载时，再由自身加载。各加载器的关联关系如下：</p>

<pre><code>        Bootstrap ClassLoader
                 |
        Extension ClassLoader
                 |
        System ClassLoader
            /           \
    User1 ClassLoader   User2 ClassLoader
</code></pre>

<p>Bootstrap ClassLoader是最根层的加载器，用户自定义加载器建议使用系统类加载器作为parent。
这种委托模型的好处显而易见，它维护了类加载器之间的层次优先级关系。使所有的类加载优先由parent加载，这保证了java基础类库中的加载只会有一份。以java.lang.Object为例，委托模式保证了这个类最终只会由BootstrapClassLoader来加载，以此来保证所有环境中只有同一个类。否则由各加载器自由发挥，当用户自己定义各同名的java.lang.Object类时，系统会出现多分Objec类，最根基的行为出现混乱。（当然，你还是可以自定义出一个同名的java.lang.Object，并且顺利通过编译，但是它正常情况下永远不会被加载）。</p>

<p><strong><em>这个委托模型并非jvm的强制规范，只是jdk中建议的一种模式，有时会发现不遵守这种模式的行为却能产生奇妙的效果，如热部署，OSGI等。</em></strong></p>

<h2>Jetty中的ClassLoader</h2>

<p>jetty，tomcat等web容器通常都会对classloader做扩展，因为一个正常的容器至少要保证其内部运行的多个webapp之间：私有的类库不受影响，并且公有的类库可以共享。这正好发挥classloader的层级划分优势。
jetty中有一个org.mortbay.jetty.webapp.WebAppClassLoader，负责加载一个webapp context中的应用类，WebAppClassLoader以系统类加载器作为parent，用于加载系统类。不过servlet规范使得web容器的classloader比正常的classloader委托模型稍稍复杂，servlet规范要求：</p>

<ol>
<li>WEB-INF/lib 和 WEB-INF/classes优先于父容器中的类加载，比如WEB-INF/classes下有个XYZ类，CLASSPATH下也有个XYZ类，jetty中优先加载的是WEB-INF/classes下的，这与正常的父加载器优先相反。</li>
<li>系统类比如java.lang.String不遵循第一条， WEB-INF/classes或WEB-INF/lib下的类不能替换系统类。不过规范中没有明确规定哪些是系统类，jetty中的实现是按照类的全路径名判断。</li>
<li>Server的实现类不被应用中的类引用，即Server的实现类不能被人和应用类加载器加载。不过，同样的，规范里没有明确规定哪些是Server的实现类，jetty中同样是按照类的全路径名判断。</li>
</ol>


<p>为了处理上述三个问题，jetty的应用类加载器(org.mortbay.jetty.webapp.WebAppClassLoader)做了些特殊处理。</p>

<h3>WebAppClassLoader的实现</h3>

<p>首先看WebAppClassLoader的实现，WebAppClassLoader的构造器中有如下代码：</p>

<pre><code>super(new URL[]{},parent!=null?parent
            :(Thread.currentThread().getContextClassLoader()!=null?Thread.currentThread().getContextClassLoader()
                    :(WebAppClassLoader.class.getClassLoader()!=null?WebAppClassLoader.class.getClassLoader()
                            :ClassLoader.getSystemClassLoader())));
</code></pre>

<p>表明WebAppClassLoader还是按照正常的范式设置parent classloader
然后看重要的loadclass方法实现：</p>

<pre><code>@Override
protected synchronized Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException
{
    Class&lt;?&gt; c= findLoadedClass(name);
    ClassNotFoundException ex= null;
    boolean tried_parent= false;

    boolean system_class=_context.isSystemClass(name);
    boolean server_class=_context.isServerClass(name);

    if (system_class &amp;&amp; server_class)
    {
        return null;
    }

    if (c == null &amp;&amp; _parent!=null &amp;&amp; (_context.isParentLoaderPriority() || system_class) &amp;&amp; !server_class)
    {
        tried_parent= true;
        try
        {
            c= _parent.loadClass(name);
            if (LOG.isDebugEnabled())
                LOG.debug("loaded " + c);
        }
        catch (ClassNotFoundException e)
        {
            ex= e;
        }
    }

    if (c == null)
    {
        try
        {
            c= this.findClass(name);
        }
        catch (ClassNotFoundException e)
        {
            ex= e;
        }
    }

    if (c == null &amp;&amp; _parent!=null &amp;&amp; !tried_parent &amp;&amp; !server_class )
        c= _parent.loadClass(name);

    if (c == null)
        throw ex;

    if (resolve)
        resolveClass(c);

    if (LOG.isDebugEnabled())
        LOG.debug("loaded " + c+ " from "+c.getClassLoader());

    return c;
}
</code></pre>

<p>loadclass按照：</p>

<ol>
<li>findLoadedClass(name)-检查类是否已经加载</li>
<li>判断该类是否为系统类或server类</li>
<li>如果该类未加载且父加载器不为空且设置了父加载器优先或类类为系统类，且该类不是server类，则尝试使用父加载器加载该类</li>
<li>如果不是父加载器优先或者父加载器未加载到该类，使用WebAppClassLoader加载该类</li>
<li>如果是不是父加载器优先，并且WebAppClassLoader未加载到该类，尝试使用父加载器加载该类</li>
<li>找到则返回，否则抛出ClassNotFoundException</li>
</ol>


<h3>ClassLoader Priority</h3>

<p>上述过程涉及一个加载器优先级的概念，这也是针对前述第一条规范中WEB-INF/lib和WEB-INF/classes类优先的处理。jetty中父加载器优先的配置项可以通过环境变量</p>

<pre><code>org.eclipse.jetty.server.webapp.parentLoaderPriority=false(默认)/true来设置
</code></pre>

<p>也可以通过</p>

<pre><code>org.eclipse.jetty.webapp.WebAppContext.setParentLoaderPriority(boolean)方法来设置
</code></pre>

<p>优于该配置默认是false，因此在load class过程中优先使用WebAppClassLoader加载WEB-INF/lib和WEB-INF/classes中的类。
当将该配置项设为true时需要确认类加载顺序没有问题。</p>

<h3>设置系统类</h3>

<p>规范2中约定系统类不能被应用类覆盖，但是没有明确规定哪些时系统类，jetty中以类的package路径名来区分，当类的package路径名位包含于</p>

<pre><code>  public final static String[] __dftSystemClasses =
    {
        "java.",                            
        "javax.",                           
        "org.xml.",                         
        "org.w3c.",                         
        "org.apache.commons.logging.",      
        "org.eclipse.jetty.continuation.",  
        "org.eclipse.jetty.jndi.",          
        "org.eclipse.jetty.plus.jaas.",     
        "org.eclipse.jetty.websocket.WebSocket", 
        "org.eclipse.jetty.websocket.WebSocketFactory", 
        "org.eclipse.jetty.servlet.DefaultServlet" 
    } ;
</code></pre>

<p>时，会被认为是系统类。（该定义位于<a href="https://github.com/eclipse/jetty.project/blob/master/jetty-webapp/src/main/java/org/eclipse/jetty/webapp/WebAppContext.java">WebAppContext@github</a>中）</p>

<p>因此，我们可以通过 org.eclipse.jetty.webapp.WebAppContext.setSystemClasses(String Array)或者org.eclipse.jetty.webapp.WebAppContext.addSystemClass(String)来设置系统类。
再次提醒，系统类是对多有应用都可见。</p>

<h3>设置Server类</h3>

<p>规范3中约定Server类不对任何应用可见。jetty同样是用package路径名来区分哪些是Server类。Server类包括：</p>

<pre><code>public final static String[] __dftServerClasses =
{
    "-org.eclipse.jetty.continuation.", 
    "-org.eclipse.jetty.jndi.",         
    "-org.eclipse.jetty.plus.jaas.",    
    "-org.eclipse.jetty.websocket.WebSocket", 
    "-org.eclipse.jetty.websocket.WebSocketFactory", 
    "-org.eclipse.jetty.servlet.DefaultServlet", 
    "-org.eclipse.jetty.servlet.listener.", 
    "org.eclipse.jetty."                
} ;
</code></pre>

<p>我们可以通过， org.eclipse.jetty.webapp.WebAppContext.setServerClasses(String Array) 或org.eclipse.jetty.webapp.WebAppContext.addServerClass(String)方法设置Server类。
注意，Server类是对所有应用都不可见的，但是WEB-INF/lib下的类可以替换Server类。</p>

<h3>自定义WebApp ClassLoader</h3>

<p>当默认的WebAppClassLoader不能满足需求时，可以自定义WebApp ClassLoader，不过jetty建议自定义的classloader要扩展于默认的WebAppClassLoader实现。具体请参考<a href="http://wiki.eclipse.org/Jetty/Reference">jetty手册</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[解决Mac上解压Windows压缩包乱码问题]]></title>
    <link href="http://jiangbo.me/blog/2012/02/13/unzip-file-from-win-to-mac/"/>
    <updated>2012-02-13T16:53:00+08:00</updated>
    <id>http://jiangbo.me/blog/2012/02/13/unzip-file-from-win-to-mac</id>
    <content type="html"><![CDATA[<p>Windows上默认使用的GBK编码，Mac上默认使用的unicode编码，因此Win上的压缩包再Mac上解压会出现文件名乱码:(
下面是用ruby写的一个解决方法：</p>

<p><a href="https://github.com/jiang-bo/codingforfun/blob/master/ruby/utils/unzipFromWinToMac.rb">source@github</a></p>

<pre><code>require 'zip/zip'
require 'iconv'

# To unzip zipfile which zip in GBK to UTF-8.
#
# When you zip a file on Windows, it will encode in GBK default.
# Then you unzip it on Mac OSX which use unicode default, it will be wrong.
# This code is used to fix this problem:)
#
# @Author: jiang-bo
Zip::ZipInputStream::open(zipFile){
  |io|
  while(entry = io.get_next_entry)
    name=Iconv.iconv("UTF-8","GBK", entry.name)[0]

    puts "Extracting #{name}"
    if name.end_with?('/')
      Dir.mkdir(name.to_s)
    else
      entry.extract(name.to_s)
    end
  end
}
</code></pre>

<p>主要依赖rubyzip和iconv两个包：</p>

<pre><code>gem install rubyzip
gem install iconv
</code></pre>

<p>使用ruby zip中ZipInputStream打开压缩包，然后使用Iconv.iconv将其中的文件名由&#8217;GBK&#8217;转码为&#8217;UTF-8&#8217;。
然后解压压缩包。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JVM Luncher Lifecycle]]></title>
    <link href="http://jiangbo.me/blog/2012/02/10/jvm-luncher-lifecycle/"/>
    <updated>2012-02-10T23:51:00+08:00</updated>
    <id>http://jiangbo.me/blog/2012/02/10/jvm-luncher-lifecycle</id>
    <content type="html"><![CDATA[<h1>JVM运行时环境</h1>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CentOS6编译OpenJDK7]]></title>
    <link href="http://jiangbo.me/blog/2012/02/10/compile-openjdk7-on-centos6/"/>
    <updated>2012-02-10T14:39:00+08:00</updated>
    <id>http://jiangbo.me/blog/2012/02/10/compile-openjdk7-on-centos6</id>
    <content type="html"><![CDATA[<h2>一.环境准备</h2>

<h3>1.jdk</h3>

<p>在编译JDK7之前，需要有个JDK6版本，这个貌似有个鸡生蛋，还是蛋生鸡的问题，不过，这个确实需要:)</p>

<h3>2.alsa包</h3>

<p>linux版本的jdk编译需要ALSA（Advanced Linux Sound Architecture）包，大部分linux发行版都没有预装，CentOS可以通过如下命令检查：</p>

<pre><code> rpm -qa |grep alsa
</code></pre>

<p>alsa-lib和alsa-lib-devel均需要。CentOS缺少alsa-lib-devel，通过如下命令安装：</p>

<pre><code> yum install alsa-lib-devel
</code></pre>

<h3>3.cups-devel</h3>

<pre><code>yum install cups-devel
</code></pre>

<h3>4.libXi-devel</h3>

<pre><code>yum install libXi-devel
</code></pre>

<h3>5.freetype2.3</h3>

<pre><code>wget http://download.savannah.gnu.org/releases/freetype/freetype-2.3.12.tar.gz
tar -xvf freetype-2.3.12.tar.gz
cd freetype-2.3.12
./configure &amp;&amp; make &amp;&amp; make install
</code></pre>

<h3>6. ant</h3>

<pre><code>wget http://mirror.bit.edu.cn/apache//ant/binaries/apache-ant-1.8.2-bin.zip
unzip apache-ant-1.8.2-bin.zip
</code></pre>

<h3>7.g++</h3>

<pre><code>yum install gcc gcc-c++
</code></pre>

<h2>二、设置环境变量</h2>

<p>jdk编译过程中有一些环境变量需要设置，详细的请参考README-builds.html，下面写的只是一些必须设置的环境变量：</p>

<pre><code>export ALT_BOOTDIR=/usr/opt/jdk # 预装的jdk7目录
export ANT_HOME=ant安装目录
export ALT_FREETYPE_HEADERS_PATH=/usr/local/include/freetype2 #freetype2头文件安装目录
export ALT_FREETYPE_LIB_PATH=/usr/local/lib #freetype2 lib目录
</code></pre>

<h2>三、编译</h2>

<h3>1.健全检查</h3>

<p>可以通过如下命令检查环境配置是否准备好：</p>

<pre><code>make sanity ARCH_DATA_MODEL=64
</code></pre>

<p>如果最终输出：</p>

<pre><code>Sanity check passed.
</code></pre>

<p>则表示环境检查通过，否则需要根据提示信息排查问题。</p>

<h3>2.执行编译</h3>

<p>通过如下命令开始编译：</p>

<pre><code>make ARCH_DATA_MODEL=64
</code></pre>

<h3>3.问题排查：</h3>

<p>编译过程中出现一些问题：</p>

<h3>1)缺少jaxp和jaxws</h3>

<p>错误信息</p>

<pre><code>ERROR: Cannot find source for project jaxp
</code></pre>

<p>原因是现在jaxp源码分支和jdk源码分支分开了，但是jaxws是jdk中的一部分，所以完全编译需要jaxp源码，针对该问题的描述可以查看README-build.html中TroubleShooting部分。
解决方式有两种：
一种是先下载好源码包，以drops的方式安装，具体参考README-build.html
另外一种是使用在线安装，在编译时加入允许下载源码的配置:</p>

<pre><code>make ARCH_DATA_MODEL=64 ALLOW_DOWNLOADS=true
</code></pre>

<h3>2)缺少X＊库</h3>

<p>编译过程中多次出现如下缺少X*, awt之类的错误，基本上都是因为缺乏图形相关的库</p>

<pre><code>../../../src/solaris/native/sun/awt/img_util_md.h:32: ??:expected specifier-qualifier-list before 'XID'
make[5]: *** [/home/jiangbo/Workspace/jdk/openjdk/build/linux-amd64/tmp/sun/sun.awt/awt/obj64/BufImgSurfaceData.o] Error 1
make[5]: *** Waiting for unfinished jobs....
make[5]: Leaving directory `/home/jiangbo/Workspace/jdk/openjdk/jdk/make/sun/awt'
make[4]: *** [library_parallel_compile] Error 2
make[4]: Leaving directory `/home/jiangbo/Workspace/jdk/openjdk/jdk/make/sun/awt'
make[3]: *** [all] Error 1
make[3]: Leaving directory `/home/jiangbo/Workspace/jdk/openjdk/jdk/make/sun'
make[2]: *** [all] Error 1
make[2]: Leaving directory `/home/jiangbo/Workspace/jdk/openjdk/jdk/make'
make[1]: *** [jdk-build] Error 2
make[1]: Leaving directory `/home/jiangbo/Workspace/jdk/openjdk'
make: *** [build_product_image] Error 2
</code></pre>

<p>解决方式时安装X相关的库</p>

<pre><code>yum install libX*
</code></pre>

<p>这个有些暴力，不过比较有效:)</p>

<h2>四、测试编译结果</h2>

<p>漫长的编译之后直至出现如下类似内容时，表示编译完成了：</p>

<pre><code>-- Build times ----------
Target all_product_build
Start 2012-02-09 10:38:39
End   2012-02-09 11:14:37
00:01:41 corba
00:06:19 hotspot
00:15:49 jaxp
00:01:30 jaxws
00:10:03 jdk
00:00:36 langtools
00:35:58 TOTAL
</code></pre>

<p>编译完成后，编译结果维语build/linux-amd64目录下，可以写个简单的Java程序测试编译结果</p>

<p>Test.java</p>

<pre><code>public class Test{
        public static void main(String[] args){
                System.out.println("Hello");
        }
}
</code></pre>

<p>编译</p>

<pre><code>[root@localhost openjdk]# ./build/linux-amd64/bin/java Test.java
</code></pre>

<p>执行</p>

<pre><code>[root@localhost openjdk]# ./build/linux-amd64/bin/java Test
Hello
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何用ruby获取本机IP&发送給Gtalk]]></title>
    <link href="http://jiangbo.me/blog/2012/01/04/how-to-get-ip-and-send-to-gtalk-by-ruby/"/>
    <updated>2012-01-04T17:35:00+08:00</updated>
    <id>http://jiangbo.me/blog/2012/01/04/how-to-get-ip-and-send-to-gtalk-by-ruby</id>
    <content type="html"><![CDATA[<h3>问题</h3>

<p>有一台server用的是动态ip，每次重启后ip地址就变了，因此写了一个脚本，每次在server重启后，自动将ip发送到我的gtalk上。</p>

<h3>解决</h3>

<h4>如何获取本机IP</h4>

<p>用ruby获取本机的动态ip，网上很多教程都用</p>

<pre><code>require 'socket'

IPSocket.getaddress(Socket.gethostname)
puts TCPSocket.gethostbyname(Socket.gethostname)
</code></pre>

<p>这个在mac下是正常的，但是在linux下就只能拿到127.0.0.1
在StackOverflow上有另一种解决方案</p>

<pre><code>require 'socket'

def local_ip
  orig, Socket.do_not_reverse_lookup = Socket.do_not_reverse_lookup, true  # turn off reverse DNS resolution temporarily

  UDPSocket.open do |s|
    s.connect '64.233.187.99', 1
    s.addr.last
  end
ensure
  Socket.do_not_reverse_lookup = rig
end
</code></pre>

<p>这段主要是通过开启一个UDP链接来获取本地对外ip，因为UDP是无状态，所以不会实际建立网络链接，但是会获取本机对外ip。</p>

<h4>如何发送消息</h4>

<p>获取ip后需要通过gtalk发送，gtalk使用的是xmpp协议，ruby中协议有多种开源实现，比较简单通用的是xmpp4r，详细教程请看这里
首先需要安装xmpp4r-simple</p>

<pre><code>gem install xmpp4r-simple
</code></pre>

<p>注意，貌似这个gem不支持1.9.*，所以使用之前先将ruby切换到1.8.7版本
然后编写代码，主要两步：</p>

<ul>
<li>建立链接</li>
<li>发送消息</li>
</ul>


<p>代码如下：</p>

<pre><code> require 'rubygems'
 require 'xmpp4r-simple'  

 username = gmailusername
 password = gmailpassword
 to_username = destination_gmailusername  

 puts "Connecting to jabber server.."
 jabber = Jabber::Simple.new(username+'@gmail.com',password)
 puts "Connected."
 jabber.deliver(to_username+"@gmail.com", "Hello..!")
 sleep(1)
</code></pre>

<p>注意，最后那个sleep不能少，尽管我还不知道为啥:(</p>

<p>如此以来整个的获取ip，发送給gtalk的脚本为：</p>

<pre><code>require 'rubygems'
require 'socket'
require 'xmpp4r-simple'

def local_ip
  orig, Socket.do_not_reverse_lookup = Socket.do_not_reverse_lookup, true  # turn off reverse DNS resolution temporarily

  UDPSocket.open do |s|
    s.connect '64.233.187.99', 1
    s.addr.last
  end
ensure
  Socket.do_not_reverse_lookup = orig
end

jabber = Jabber::Simple.new('gmailuseanme@gmail.com','password')
jabber.deliver('destusenam@gmail.com', local_ip)
sleep 1
</code></pre>

<h4>设置自动运行</h4>

<p>linux设置自动运行是老生常谈了，在/etc/rc.local加上一句运行脚本的命令即可：</p>

<pre><code>ruby /home/jiangbo/ruby/getIP.rb
</code></pre>

<h3>结尾</h3>

<p>这样每次机器重启时，就能够通过gtalk获取到ip了，不过还遗留一个问题，就是在机器重启时，必须保证接收消息的gtalk在线，因为这种方式的消息gtalk不会自动重法，目前不知怎么解决。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[我的2011&2012]]></title>
    <link href="http://jiangbo.me/blog/2011/12/31/my2011and2012/"/>
    <updated>2011-12-31T00:00:00+08:00</updated>
    <id>http://jiangbo.me/blog/2011/12/31/my2011and2012</id>
    <content type="html"><![CDATA[<p>一眨眼，一年又过去了，奔三的步伐又向前迈进了一步…</p>

<p><h2>2011流水账</h2></p>

<p>1月～3月，入职来第一次正是参加了大项目，中间夹杂个春节，据说每年年底做大项目是部门的传统，今年也不例外啊:(，项目苦了写，不过学了不少</p>

<p><p>4月～6月，公司进行服务化改造，作为主力开发参与了部门的服务化建设，期间送走了两个同事好友，一个去了厦门，一个回了宁波，各自寻找自己的幸福去了。<br />
附加一句，上半年基本还处在阴霾期，期间养成了去酒吧喝酒的习惯，有钱去酒吧，没钱去地摊，酒量现在还可以。</p></p>

<p>7月～8月，参加了另外一个项目，8月底的时候由于上半年持续表现不错，连续两个3.75，所以被升了一级，薪水也有了不错的涨幅:)。同时部门也组织了一次outing，去了舟山嵊泗岛，很祥和的小渔村，很不错。中间的时候李辉来杭州玩，许久不见的兄弟啊</p>

<p>9月第一次自己带了一个小项目。同时又送走一位同事。</p>

<p>十一期间，休了半个月的假，和同事几人一起去了趟西藏，花光了半年多的积蓄，感觉无法用语言形容，还会再去的，一定</p>

<p>11月～12月，需求不断，每日都投入在工作中，有些疲惫哈</p>

<p><h2>2011总结</h2></p>

<p>回顾下11年初定的三个目标：</p>

<p><em>1. 工作顺利挺进，争取升一级</em></p>

<p><em>2. 保养皮肤，争取帅一点</em></p>

<p><em>3. 去西藏，无论如何，我一定会去的</em></p>

<p><p>第一点顺利完成；第二点除了痘少些，人也老些，基本没变；第三点纠结许久也顺利完成，而且收获远超期望。<br />
除了以上三点，还有些额外收获，譬如结束单身生活啥的:)，老家盖新房啥的<br />
总的来说11年过的还算不错，基本算是从阴霾走向光明，逐渐奔向幸福，哈哈</p></p>

<p><h2>2012的三件事</h2></p>

<p>按照惯例，还是列下明年的目标把，不多，还是三个：</p>

<p><ol>
<li>自己做个网站</li>
<li>再一次长途旅行（环青海湖或这挺进新疆，诚征驴友）</li>
<li>还有一个很重要的事，一时想不起来了，暂定“顺利度过2012吧！”</li>
</ol></p>

<p><h2>祝福</h2></p>

<p>还是按照惯例，最后送上祝福：</p>

<p><p>亲们，尽管我这个人平时很少和大家联系，但我内心真的很想念你们，大家都要幸福啊！<br />
2012，幸福快乐！</p>
</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[优化rails new时bundle install速度]]></title>
    <link href="http://jiangbo.me/blog/2011/12/17/rails_new_optimize_bundle_install/"/>
    <updated>2011-12-17T00:00:00+08:00</updated>
    <id>http://jiangbo.me/blog/2011/12/17/rails_new_optimize_bundle_install</id>
    <content type="html"><![CDATA[<p>最近痴迷ruby和ror，但是每次rails new xxx时总会在bundle install 停留很久，学习了下，发现rails new时会进行bundle install，自动到rubygems.org上检查是否有更新。如果确定不需要更新，事实上是可以跳过这个步骤的，方法很简单：
<code>
rails new my_app --skip-bundle
</code>
另外在单独执行bundle install时默认也会自动检查所有更新，解决方法时
<code>
bundle insall --local
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rails中常见的错误]]></title>
    <link href="http://jiangbo.me/blog/2011/12/17/rails-common-error/"/>
    <updated>2011-12-17T00:00:00+08:00</updated>
    <id>http://jiangbo.me/blog/2011/12/17/rails-common-error</id>
    <content type="html"><![CDATA[<p><h1>Rails中常见错误总结</h1>
<h3>NoMothedError</h3>
NoMethodError通常表示引用了错误的方法，比如link_to写成了lunk_to。根据页面上的错误提示很容易能够定位到错误代码位于哪一行。
<h3>NameError</h3>
NameError常见于引用了错误的变量，比如变量不存在等
<h3>SyntaxError: unexpected $end</h3>
SyntaxError加上unexpected $end, expected keyword_end的错误，通常是少了end关键字。def和do必须要有对应的end。不过通常错误提示无法定位具体哪一行缺少了end，需要自己审查代码逻辑。
<h3>invalid multibyte char(US-ASCII)</h3>
如果使用的是Ruby1.9，出现:invalid multibyte char(US-ASCII)的时候，通常表示代码源文件中有UTF-8字符，比如中文，根据Ruby1.9规范，必须在源文件的头部加上编码注解<br />
#encoding: utf-8<br />
并且代码的源文件格式必须时utf-8的。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[chrome中清除dns缓存]]></title>
    <link href="http://jiangbo.me/blog/2011/12/07/clean-dns-cache-on-chrome/"/>
    <updated>2011-12-07T00:00:00+08:00</updated>
    <id>http://jiangbo.me/blog/2011/12/07/clean-dns-cache-on-chrome</id>
    <content type="html"><![CDATA[<p>web开发经常要做各种host绑定的切换，firefox下有个DNS Flusher插件，但没有chrome版本，其实在chrome下清除DNS缓存非常简单：<br />
1、用chrome打开：chrome://net-internals/#dns<br />
2、点击上面的“clean host cache”<br />
为了方便使用，可以加个bookmark:)</p>
]]></content>
  </entry>
  
</feed>
