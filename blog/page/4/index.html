
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>非纯种程序猿</title>
  <meta name="author" content="jiang-bo">

  
  <meta name="description" content="NameNode存在三种运行模式： Normal： NameNode正常服务的状态
Safe mode：NameNode重启时进入Safe mode，该模式下整个系统是只读的，以便于NameNode手机DataNode信息
Backup mode：备份NameNode处于Backup mode， &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://jiangbo.me/blog/page/4/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
   <link href="/stylesheets/data-table.css" media="screen, projection" rel="stylesheet" type="text/css" />
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="非纯种程序猿" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>


  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-34477986-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
</hgroup>

</header>
  <!-- <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:jiangbo.me" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav> -->
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/10/18/hdfs-namenode-thread/">HDFS源码学习（3）——NameNode中的线程</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-10-18T21:37:00+08:00" pubdate data-updated="true">Oct 18<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/10/18/hdfs-namenode-thread/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>NameNode存在三种运行模式：</p>

<ol>
<li>Normal： NameNode正常服务的状态</li>
<li>Safe mode：NameNode重启时进入Safe mode，该模式下整个系统是只读的，以便于NameNode手机DataNode信息</li>
<li>Backup mode：备份NameNode处于Backup mode，被动的接收主NameNode的检查点信息</li>
</ol>


<p>在NameNode中存在如下几种线程：</p>

<ol>
<li>DataNode 健康检查管理线程</li>
<li>副本管理线程</li>
<li>租约管理（lease Management）</li>
<li>IPC Handler 线程</li>
</ol>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/10/18/hdfs-namenode-startup/">HDFS源码学习(2)——NameNode初始化</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-10-18T21:35:00+08:00" pubdate data-updated="true">Oct 18<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/10/18/hdfs-namenode-startup/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>main()</h2>

<pre><code>  public static void main(String argv[]) throws Exception {
    try {
      StringUtils.startupShutdownMessage(NameNode.class, argv, LOG);
      //创建nameNode
      NameNode namenode = createNameNode(argv, null);
      if (namenode != null)
        namenode.join();
    } catch (Throwable e) {
      LOG.error(StringUtils.stringifyException(e));
      System.exit(-1);
    }
  }
</code></pre>

<h3>createNameNode()</h3>

<pre><code>  public static NameNode createNameNode(String argv[], 
                                 Configuration conf) throws IOException {
    if (conf == null)
      conf = new Configuration();
      //从命令行参数中提取启动配置项数据
    StartupOption startOpt = parseArguments(argv);
    if (startOpt == null) {
      printUsage();
      return null;
    }
    //设置启动参数
    setStartupOption(conf, startOpt);

    switch (startOpt) {
      case FORMAT:
        boolean aborted = format(conf, true);
        System.exit(aborted ? 1 : 0);
      case FINALIZE:
        aborted = finalize(conf, true);
        System.exit(aborted ? 1 : 0);
      default:
    }

    //新建NameNode
    NameNode namenode = new NameNode(conf);
    return namenode;
  }
</code></pre>

<h3>NameNode()</h3>

<pre><code>  public NameNode(Configuration conf) throws IOException {
    super(conf);
    try {
    //初始化
      initialize(getConf());
    } catch (IOException e) {
      this.stop();
      throw e;
    }
  }
</code></pre>

<h3>initialize()</h3>

<pre><code>  private void initialize(Configuration conf) throws IOException {
    InetSocketAddress socAddr = NameNode.getAddress(conf);
    int handlerCount = conf.getInt("dfs.namenode.handler.count", 10);
    // 关键-&gt;创建一个RPC Server
    this.server = RPC.getServer(this, socAddr.getHostName(), socAddr.getPort(),
                                handlerCount, false, conf);

    // The rpc-server port can be ephemeral... ensure we have the correct info
    this.serverAddress = this.server.getListenerAddress(); 
    FileSystem.setDefaultUri(conf, getUri(serverAddress));
    LOG.info("Namenode up at: " + this.serverAddress);

    myMetrics = new NameNodeMetrics(conf, this);

    //关键-&gt;创建一个FSNameSystem
    this.namesystem = new FSNamesystem(this, conf);
    //启动HTTP Server
    startHttpServer(conf);
    //启动RPC Server
    this.server.start();  //start RPC server   

    startTrashEmptier(conf);
  }
</code></pre>

<h2>FSNameSystem()</h2>

<pre><code>  FSNamesystem(NameNode nn, Configuration conf) throws IOException {
    try {
      //初始化FSNameSystem
      initialize(nn, conf);
      userPasswordInformation = new UserPasswordInformation(conf);
      extendAccessControlList = new ExtendAccessControlList(conf);
    } catch(IOException e) {
      LOG.error(getClass().getSimpleName() + " initialization failed.", e);
      close();
      throw e;
    }
  }
</code></pre>

<h3>FSNameSystem.initialize()</h3>

<pre><code>  private void initialize(NameNode nn, Configuration conf) throws IOException {
    this.systemStart = now();
    this.fsLock = new ReentrantReadWriteLock(); // non-fair locking
    setConfigurationParameters(conf);

    this.nameNodeAddress = nn.getNameNodeAddress();
    this.registerMBean(conf); // register the MBean for the FSNamesystemStutus

    //创建FSDirectory
    this.dir = new FSDirectory(this, conf);
    StartupOption startOpt = NameNode.getStartupOption(conf);

    //加载FSImage
    this.dir.loadFSImage(getNamespaceDirs(conf),
                         getNamespaceEditsDirs(conf), startOpt);
    long timeTakenToLoadFSImage = now() - systemStart;
    LOG.info("Finished loading FSImage in " + timeTakenToLoadFSImage + " msecs");
    NameNode.getNameNodeMetrics().fsImageLoadTime.set(
                              (int) timeTakenToLoadFSImage);
    this.safeMode = new SafeModeInfo(conf);
    setBlockTotal();
    //创建PendingReplicationBlocks
    pendingReplications = new PendingReplicationBlocks(
                            conf.getInt("dfs.replication.pending.timeout.sec", 
                                        -1) * 1000L);
    //创建心跳检查线程                                          
    this.hbthread = new Daemon(new HeartbeatMonitor());
    //创建租约管理线程
    this.lmthread = new Daemon(leaseManager.new Monitor());
    //创建副本管理线程
    this.replthread = new Daemon(new ReplicationMonitor());
    hbthread.start();
    lmthread.start();
    replthread.start();

    // 副本超额block管理线程
    this.overreplthread = new Daemon(new OverReplicationMonitor());
    overreplthread.start();

    this.hostsReader = new HostsFileReader(conf.get("dfs.hosts",""),
                                           conf.get("dfs.hosts.exclude",""));
    //创建退役节点管理线程
    this.dnthread = new Daemon(new DecommissionManager(this).new Monitor(
        conf.getInt("dfs.namenode.decommission.interval", 30),
        conf.getInt("dfs.namenode.decommission.nodes.per.interval", 5)));
    dnthread.start();

    this.dnsToSwitchMapping = ReflectionUtils.newInstance(
        conf.getClass("topology.node.switch.mapping.impl", ScriptBasedMapping.class,
            DNSToSwitchMapping.class), conf);

    /* If the dns to swith mapping supports cache, resolve network 
     * locations of those hosts in the include list, 
     * and store the mapping in the cache; so future calls to resolve
     * will be fast.
     */
    if (dnsToSwitchMapping instanceof CachedDNSToSwitchMapping) {
      dnsToSwitchMapping.resolve(new ArrayList&lt;String&gt;(hostsReader.getHosts()));
    }
    //创建副本定位器用于定位副本存放位置
    this.replicator = BlockPlacementPolicy.getInstance(
        conf,
        this,
        this.clusterMap,
        this.hostsReader,
        this.dnsToSwitchMapping,
        this);
  }
</code></pre>

<h2>FSDirectory(this, conf)</h2>

<p>新建FSDirecotry</p>

<pre><code> FSDirectory(FSNamesystem ns, Configuration conf) {
    //创建一个FSImage，并实例化构建FSDirectory
    this(new FSImage(), ns, conf);
    fsImage.setCheckpointDirectories(FSImage.getCheckpointDirs(conf, null),
                                FSImage.getCheckpointEditsDirs(conf, null));
  }
</code></pre>

<h3>this(new FSImage(), ns, conf);</h3>

<pre><code>FSDirectory(FSImage fsImage, FSNamesystem ns, Configuration conf) {
    this.bLock = new ReentrantReadWriteLock(); // non-fair
    this.cond = bLock.writeLock().newCondition();
    //创建根目录
    rootDir = new INodeDirectoryWithQuota(INodeDirectory.ROOT_NAME,
        ns.createFsOwnerPermissions(new FsPermission((short)0755)),
        Integer.MAX_VALUE, -1);
    this.fsImage = fsImage;
    namesystem = ns;
    initialize(conf);
  }
</code></pre>

<h3>FSDirectory.initialize()</h3>

<pre><code>  private void initialize(Configuration conf) {
    MetricsContext metricsContext = MetricsUtil.getContext("dfs");
    directoryMetrics = MetricsUtil.createRecord(metricsContext, "FSDirectory");
    directoryMetrics.setTag("sessionId", conf.get("session.id"));
  }
</code></pre>

<h3>FSDirectory.loadFSImage()</h3>

<pre><code>  void loadFSImage(Collection&lt;File&gt; dataDirs,
                   Collection&lt;File&gt; editsDirs,
                   StartupOption startOpt) throws IOException {
    // format before starting up if requested
    if (startOpt == StartupOption.FORMAT) {
      fsImage.setStorageDirectories(dataDirs, editsDirs);
      fsImage.format();
      startOpt = StartupOption.REGULAR;
    }
    try {
      //从datadir和editdirs加载FSImage
      if (fsImage.recoverTransitionRead(dataDirs, editsDirs, startOpt)) {
        fsImage.saveNamespace(true);
      }
      //初始化Editlog
      FSEditLog editLog = fsImage.getEditLog();
      assert editLog != null : "editLog must be initialized";
      if (!editLog.isOpen())
        editLog.open();
      fsImage.setCheckpointDirectories(null, null);
    } catch(IOException e) {
      fsImage.close();
      throw e;
    }
    writeLock();
    try {
      this.ready = true;
      cond.signalAll();
    } finally {
      writeUnlock();
    }
  }
</code></pre>

<h3>FSImage.recoverTransitionRead（）</h3>

<pre><code>  boolean recoverTransitionRead(Collection&lt;File&gt; dataDirs,
                             Collection&lt;File&gt; editsDirs,
                                StartupOption startOpt
                                ) throws IOException {
    assert startOpt != StartupOption.FORMAT : 
      "NameNode formatting should be performed before reading the image";

    // none of the data dirs exist
    if (dataDirs.size() == 0 || editsDirs.size() == 0)  
      throw new IOException(
        "All specified directories are not accessible or do not exist.");

    if(startOpt == StartupOption.IMPORT 
        &amp;&amp; (checkpointDirs == null || checkpointDirs.isEmpty()))
      throw new IOException("Cannot import image from a checkpoint. "
                          + "\"fs.checkpoint.dir\" is not set." );

    if(startOpt == StartupOption.IMPORT 
        &amp;&amp; (checkpointEditsDirs == null || checkpointEditsDirs.isEmpty()))
      throw new IOException("Cannot import image from a checkpoint. "
                          + "\"fs.checkpoint.edits.dir\" is not set." );

    setStorageDirectories(dataDirs, editsDirs);
    // 1.检查所有目录的状态和一致性
    Map&lt;StorageDirectory, StorageState&gt; dataDirStates = 
             new HashMap&lt;StorageDirectory, StorageState&gt;();
    boolean isFormatted = false;
    for (Iterator&lt;StorageDirectory&gt; it = 
                      dirIterator(); it.hasNext();) {
      StorageDirectory sd = it.next();
      StorageState curState;
      try {
        curState = sd.analyzeStorage(startOpt);
        // sd is locked but not opened
        switch(curState) {
        case NON_EXISTENT:
          // name-node fails if any of the configured storage dirs are missing
          throw new InconsistentFSStateException(sd.getRoot(),
                                                 "storage directory does not exist or is not accessible.");
        case NOT_FORMATTED:
          break;
        case NORMAL:
          break;
        default:  // recovery is possible
          sd.doRecover(curState);      
        }
        if (curState != StorageState.NOT_FORMATTED 
            &amp;&amp; startOpt != StartupOption.ROLLBACK) {
          sd.read(); // read and verify consistency with other directories
          isFormatted = true;
        }
        if (startOpt == StartupOption.IMPORT &amp;&amp; isFormatted)
          // import of a checkpoint is allowed only into empty image directories
          throw new IOException("Cannot import image from a checkpoint. " 
              + " NameNode already contains an image in " + sd.getRoot());
      } catch (IOException ioe) {
        sd.unlock();
        throw ioe;
      }
      dataDirStates.put(sd,curState);
    }

    if (!isFormatted &amp;&amp; startOpt != StartupOption.ROLLBACK 
                     &amp;&amp; startOpt != StartupOption.IMPORT)
      throw new IOException("NameNode is not formatted.");
    if (layoutVersion &lt; LAST_PRE_UPGRADE_LAYOUT_VERSION) {
      checkVersionUpgradable(layoutVersion);
    }
    if (startOpt != StartupOption.UPGRADE
          &amp;&amp; layoutVersion &lt; LAST_PRE_UPGRADE_LAYOUT_VERSION
          &amp;&amp; layoutVersion != FSConstants.LAYOUT_VERSION)
        throw new IOException(
                          "\nFile system image contains an old layout version " + layoutVersion
                          + ".\nAn upgrade to version " + FSConstants.LAYOUT_VERSION
                          + " is required.\nPlease restart NameNode with -upgrade option.");
    // check whether distributed upgrade is reguired and/or should be continued
    verifyDistributedUpgradeProgress(startOpt);

    // 2. Format unformatted dirs.
    this.checkpointTime = 0L;
    for (Iterator&lt;StorageDirectory&gt; it = 
                     dirIterator(); it.hasNext();) {
      StorageDirectory sd = it.next();
      StorageState curState = dataDirStates.get(sd);
      switch(curState) {
      case NON_EXISTENT:
        assert false : StorageState.NON_EXISTENT + " state cannot be here";
      case NOT_FORMATTED:
        LOG.info("Storage directory " + sd.getRoot() + " is not formatted.");
        LOG.info("Formatting ...");
        sd.clearDirectory(); // create empty currrent dir
        break;
      default:
        break;
      }
    }
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/10/18/hdfs-namenode-datastructure/">HDFS源码学习（1）——NameNode主要数据结构</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-10-18T11:04:00+08:00" pubdate data-updated="true">Oct 18<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/10/18/hdfs-namenode-datastructure/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>FSNameSystem</h2>

<p>FSNameSystem是HDFS文件系统实际执行的核心，提供各种增删改查文件操作接口。其内部维护多个数据结构之间的关系：</p>

<ol>
<li>fsname->block列表的映射</li>
<li>所有有效blocks集合</li>
<li>block与其所属的datanodes之间的映射（该映射是通过block reports动态构建的，维护在namenode的内存中。每个datanode在启动时向namenode报告其自身node上的block）</li>
<li>每个datanode与其上的blocklist的映射</li>
<li>采用心跳检测根据LRU算法更新的机器（datanode）列表</li>
</ol>


<h3>FSDirectory</h3>

<p>FSDirectory用于维护当前系统中的文件树。</p>

<p>其内部主要组成结构包括一个INodeDirectoryWithQuota作为根目录(rootDir)和一个FSImage来持久化文件树的修改操作。</p>

<h4>INode</h4>

<p>HDFS中文件树用类似VFS中INode的方式构建，整个HDFS中文件被表示为INodeFile，目录被表示为INodeDirectory。INodeDiretoryWithQuota是INodeDirectory的扩展类，即带配额的文件目录</p>

<p><img src="/images/hdfs/INode.png" alt="INode" /></p>

<p>INodeFile表示INode书中的一个文件，扩展自INode，除了名字(name)，父节点(parent)等之外，一个主要元素是blocks，一个BlockInfo数组，表示该文件对应的block信息。</p>

<h3>BlocksMap</h3>

<p>BlocksMap用于维护Block -> { INode, datanodes, self ref } 的映射
<img src="/images/hdfs/BlocksMap.png" alt="BlocksMap" />
BlocksMap结构比较简单，实际上就是一个Block到BlockInfo的映射。</p>

<h4>Block</h4>

<p>Block是HDFS中的基本读写单元，主要包括：</p>

<ol>
<li>blockId: 一个long类型的块id</li>
<li>numBytes: 块大小</li>
<li>generationStamp: 块更新的时间戳</li>
</ol>


<h4>BlockInfo</h4>

<p>BlockInfo扩展自Block，除基本信息外还包括一个inode引用，表示该block所属的文件；以及一个神奇的三元组数组Object[] triplets，用来表示保存该block的datanode信息，假设系统中的备份数量为3。那么这个数组结构如下：</p>

<p><img src="/images/hdfs/triplets.png" alt="triplets" /></p>

<ol>
<li>DN1，DN2，DN3分别表示存有改block的三个datanode的引用(DataNodeDescriptor）</li>
<li>DN1-prev-blk表示在DN1上block列表中当前block的前置block引用</li>
<li>DN1-next-blk表示在DN1上block列表中当前block的后置block引用</li>
</ol>


<p>DN2,DN3的prev-blk和next-blk类似。
HDFS采用这种结构存放block->datanode list的信息主要是为了节省内存空间，block->datanodelist之间的映射关系需要占用大量内存，如果同样还要将datanode->blockslist的信息保存在内存中，同样要占用大量内存。采用三元组这种方式能够从其中一个block获得到改block所属的datanode上的所有block列表。</p>

<h4>FSImage</h4>

<p>FSImage用于持久化文件树的变更以及系统启动时加载持久化数据。
HDFS启动时通过FSImage来加载磁盘中原有的文件树，系统Standby之后，通过FSEditlog来保存在文件树上的修改，FSEditLog定期将保存的修改信息刷到FSImage中进行持久化存储。
FSImage中文件元信息的存储结构如下（参见FImage.saveFSImage()方法）</p>

<p><img src="/images/hdfs/FSImage.png" alt="FSImage" /></p>

<h5>FSImage头部信息</h5>

<ol>
<li>layoutVersion(int):image layout版本号，0.19版本的hdfs中为-18</li>
<li>namespaceId(int): 命名空间ID，系统初始化时生成，在一个namenode生命周期内保持不变，datanode想namenode注册是返回改id作为registerId，以后每次datanode与namenode通信时都携带该id，不认识的id的请求将被拒绝。</li>
<li>numberItemOfTree(long): 系统中的文件总数</li>
<li>generationTimeStamp: 生成image的时间戳</li>
</ol>


<h5>INode信息</h5>

<p>FSImage头之后是numberItemOfTree个INode信息，INode信息分为文件(INodeFile)和文件目录(INodeDirectory)两类，两者大体一致，分为INode头，Blocks区（目录没有blocks）和文件权限。</p>

<p><strong>INode头</strong></p>

<ol>
<li>nameLen(short): 文件名长度</li>
<li>filename(String): 文件名</li>
<li>replication(short): 备份数量</li>
<li>modificationTime(long): 最近修改时间</li>
<li>accessTime(long): 最近访问时间</li>
<li>preferedBlockSize(long): 块大小（目录为0）</li>
<li>block num(int): 块数量（目录为-1）</li>
</ol>


<p><strong>Blocks区</strong></p>

<ol>
<li>blockId(long)</li>
<li>numBytes(long,block大小)</li>
<li>generationTimeStamp(long, 更新时间戳）</li>
</ol>


<p><strong>文件权限</strong></p>

<ol>
<li>username(String): 文件用户名</li>
<li>group(String): 所属组</li>
<li>fileperm(short): 文件权限</li>
</ol>


<h5>underconstructionFile区</h5>

<p>layoutverion&lt;-18版本的fsimage还包括正在构建的文件区。与普通Inode信息类似，均有inode头和blocks区以及文件权限，除此之外，underConstructionFile还包括：</p>

<p><strong>client信息</strong></p>

<ol>
<li>clientName：client明</li>
<li>clientMachine： client机器名</li>
</ol>


<p><strong>已分配的datanode信息</strong></p>

<ol>
<li>ipcport： 服务端口</li>
<li>capacity: 容量</li>
<li>dfsuse： 已使用的空间</li>
<li>remaining： 剩余空间</li>
<li>lastupdate： 最新更新时间</li>
<li>xceiverCount</li>
<li>location： datanode位置</li>
<li>hostName：主机名</li>
<li>state： admin管理状态</li>
</ol>


<h2>其他结构</h2>

<h3>CorruptReplicasMap</h3>

<p>CorruptReplicasMap通过一个TreeMap维护corrupt状态block的blocks&#8211;>datanodedescriptor(s)映射。一个block备份在多个datanode中，当其中的一个或多个datanode上的block损坏时，会将该datanode加到treeMap中该block对应的datanodeDescriptor集合中。FSNameSystem通过该Map来维护所有损坏的block与其对应datanode的关系。</p>

<h3>Map&lt;String, LightWeightHashSet<Block>> recentInvalidateSets</h3>

<p>维护最近失效的block集合，map中为storageId->ArrayList<Block>，当某个block的一个datanode上副本失效时会将改block和对应的datanode的storeageId添加到recentInvalidateSet中，当datanode想namenode进行heartbeat时，namenode会检查该datanode中是否有损坏的block，如有，则通知datanode删除改block。</p>

<h3>NavigableMap&lt;String, DatanodeDescriptor>  datanodeMap</h3>

<p>datanodeMap用于维护datanode->block的映射</p>

<h3>ArrayList<DatanodeDescriptor> heartbeats</h3>

<p>维护多有当前活着的节点</p>

<h3>UnderReplicatedBlocks neededReplications</h3>

<p>通过一个优先级队列来维护当前需要备份的block集合，副本数越少的block优先级越高，0为最高级，表示当前只有一个副本。</p>

<h3>PendingReplicationBlocks pendingReplications;</h3>

<p>维护当前正在备份的block集合，并且进行备份请求的时间统计，并通过一个后台线程（PendingReplicationMonitor）来周期性（默认为5分钟）的统计超时的备份请求，当发生超时时，会将这个block重新添加到neededReplications列表中。
<img src="/images/hdfs/PendingReplicationBlocks.png" alt="PendingReplicationBlocks" /></p>

<h3>LightWeightLinkedSet<Block> overReplicatedBlocks</h3>

<p>当前需要检查是否备份过多的block集合</p>

<h3>Map&lt;String, Collection<Block>> excessReplicateMap</h3>

<p>维护系统中datanode与其上的超额备份block的集合，这些超额的备份将被删除。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/09/24/compile-hadoop/">本地编译Hadoop小记</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-09-24T15:28:00+08:00" pubdate data-updated="true">Sep 24<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/09/24/compile-hadoop/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>Git源码</h2>

<pre><code>git clone git://git.apache.org/hadoop-common.git
</code></pre>

<p>视网速不通，略慢</p>

<h2>编译</h2>

<pre><code>cd hadoop-common
mvn install -DskipTests
</code></pre>

<p>抛异常：</p>

<pre><code>[ERROR] Failed to execute goal org.apache.maven.plugins:maven-antrun-plugin:1.6:run (compile-proto) on project hadoop-common: An Ant BuildException has occured: exec returned: 127 -&gt; [Help 1]
org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-antrun-plugin:1.6:run (compile-proto) on project hadoop-common: An Ant BuildException has occured: exec returned: 127
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:217)
    at... 
    Caused by: /Users/Shared/Workspace/hadoop/hadoop-common/hadoop-common-project/hadoop-common/target/antrun/build-main.xml:23: exec returned: 127
    at org.apache.tools.ant.taskdefs.ExecTask.runExecute(ExecTask.java:650)
    at org.apache.tools.ant.taskdefs.ExecTask.runExec(ExecTask.java:676)
    at org.apache.tools.ant.taskdefs.ExecTask.execute(ExecTask.java:502)
    at org.apache.tools.ant.UnknownElement.execute(UnknownElement.java:291)
    at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)
    ... 21 more
</code></pre>

<p>原因是缺少protocol buffer， 找不到protoc命令。</p>

<h3>安装protocol buffer</h3>

<pre><code>wget https://protobuf.googlecode.com/files/protobuf-2.4.1.tar.bz2
tar -xvf protobuf-2.4.1.tar.bz2
cd protobuf-2.4.1
./configure &amp;&amp; make
make install
</code></pre>

<h3>导入Eclipse</h3>

<pre><code>mvn eclipse:eclipse -DdownloadSources=true -DdownloadJavadocs=true
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/08/31/something-about-memcache-internal/">关于Memcache内存管理模型的理解</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-08-31T07:52:00+08:00" pubdate data-updated="true">Aug 31<span>st</span>, 2012</time>
        
         | <a href="/blog/2012/08/31/something-about-memcache-internal/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><script async class="speakerdeck-embed" data-id="504049be5ec53c000202daa6" data-ratio="1.299492385786802" src="//speakerdeck.com/assets/embed.js"></script>


<h2>说在前面</h2>

<p>本文不包含为什么使用memcache，以及如何使用memcache等基础知识。相关知识请查阅各类手册。
另，为便于理解，最好手头准备一份memcache的源码，本文使用的是目前最新的1.4.4版本源码，可自行到github上clone。</p>

<h2>Item、Chunk、Page、Slab</h2>

<h3>Data Item</h3>

<pre><code>+---------------------------------------+
|  key-value | cas | suffix | item head |  
+---------------------------------------+
</code></pre>

<p>Item指实际存放到memcache中的数据对象结构，除key-value数据外，还包括memcache自身对数据对象的描述信息（Item=key+value+后缀长+32byte结构体）</p>

<h3>Chunk</h3>

<p>Chunk指Memcache用来存放Data Item的最小单元，同一个Slab中的chunk大小是固定的。</p>

<pre><code>+------------------------------+
|   data item    | empty space |
+------------------------------+
</code></pre>

<h2>Page</h2>

<pre><code>+-------------------------------------+
|  chunk1 | chunk2 | chunk3 | chunk4  |
+-------------------------------------+
</code></pre>

<p>每个Slab中按照Page来申请内存，Page的大小默认为1M，可以通过-l参数调整，最小1k，最大128m.</p>

<h3>Slab</h3>

<pre><code>+--------------------------------+
|  Page1 | Page2 | Page3 | Page4 |
+--------------------------------+
</code></pre>

<p>Memcache将分配给它的内存（-m 参数指定，默认64m）按照Chunk大小不同，划分为多个slab。</p>

<p>他们三者的关系如下图所示:</p>

<pre><code>                 Chunk
                   ^                                                         
+------------------|------------------------------------------------------------+
|   Memory         |                                                            | 
|  +---------------|---------------------------------------------------------+  |
|  |      +--------|---------------------+  +------------------------------+ |  |
|  |      |Page1 +-|---+ +-----+ +-----+ |  |Page2 +-----+ +-----+ +-----+ | |  |
|  | Slab |(1M)  | 96B | | 68B | | 72B | |  |(1M)  | 92B | | 76B | | 84B | | |  | 
|  |  1   |      +-----+ +-----+ +-----+ |  |      +-----+ +-----+ +-----+ | |  |
|  |      +------------------------------+  +------------------------------+ |  |
|  +-------------------------------------------------------------------------+  |
|                                                                               |
|  +-------------------------------------------------------------------------+  |
|  |      +------------------------------+  +------------------------------+ |  |
|  |      |Page1 +------+    +------+    |  |Page2 +------+    +-------+   | |  |
|  | Slab | (1M) | 128B |    | 120B |    |  |(1M)  | 128B |    | 97B   |   | |  |
|  |   2  |      +------+    +------+    |  |      +------+    +-------+   | |  |
|  |      +------------------------------+  +------------------------------+ |  |
|  +-------------------------------------------------------------------------+  |
+-------------------------------------------------------------------------------+
</code></pre>

<h2>Slab内存分配</h2>

<h3>slab初始化</h3>

<p>Memcache启动时会进行slab初始化（参见slabs.c中slabs_init()函数），默认最小的chunksize为80（查看源码会发现settings中chunk_size默认为48，但是实际还需要加上一个32bytes的item结构体），可以通过-n参数调整，按照然后按照factor（默认为1.25，可以通过-f参数调整）(<em>关于参数更多的memcache默认参数可以参考memcache.c中settings的设置</em>)比例递增，划分出多个不同chunk大小的slab空间，即slab1的chunk大小=80，slab2的chunk大小为80*1.25=100，slab3的chunk大小为80*1.25*1.25=125，但最大一个一个chunk不会大于一个Page的大小（默认1M）。</p>

<pre><code>一下代码节选自 slabs.c
 95 void slabs_init(const size_t limit, const double factor, const bool prealloc) {
 96     int i = POWER_SMALLEST - 1;
 97     unsigned int size = sizeof(item) + settings.chunk_size;
 98  
 99     mem_limit = limit;
100  
101     if (prealloc) {
102         /* Allocate everything in a big chunk with malloc */
103         mem_base = malloc(mem_limit);
104         if (mem_base != NULL) {
105             mem_current = mem_base;
106             mem_avail = mem_limit;
107         } else {
108             fprintf(stderr, "Warning: Failed to allocate requested memory in"
109                     " one large chunk.\nWill allocate in smaller chunks\n");
110         }
111     }
112  
113     memset(slabclass, 0, sizeof(slabclass));
114  
115     while (++i &lt; POWER_LARGEST &amp;&amp; size &lt;= settings.item_size_max / factor) {
116         /* Make sure items are always n-byte aligned */
117         if (size % CHUNK_ALIGN_BYTES)
118             size += CHUNK_ALIGN_BYTES - (size % CHUNK_ALIGN_BYTES);
119  
120         slabclass[i].size = size;
121         slabclass[i].perslab = settings.item_size_max / slabclass[i].size;
122         size *= factor;
123         if (settings.verbose &gt; 1) {
124             fprintf(stderr, "slab class %3d: chunk size %9u perslab %7u\n",
125                     i, slabclass[i].size, slabclass[i].perslab);
126         }
127     }
128  
129     power_largest = i;
130     slabclass[power_largest].size = settings.item_size_max;
131     slabclass[power_largest].perslab = 1;
132     if (settings.verbose &gt; 1) {
133         fprintf(stderr, "slab class %3d: chunk size %9u perslab %7u\n",
134                 i, slabclass[i].size, slabclass[i].perslab);
135     }
136  
137     /* for the test suite:  faking of how much we've already malloc'd */
138     {
139         char *t_initial_malloc = getenv("T_MEMD_INITIAL_MALLOC");
140         if (t_initial_malloc) {
141             mem_malloced = (size_t)atol(t_initial_malloc);
142         }
143  
144     }
145  
146     if (prealloc) {
147         slabs_preallocate(power_largest);
148     }
149 }                             
</code></pre>

<p>PS：prealloc指的是直接申请一个大的chunk存放所有数据，默认是不采用这种方式的。</p>

<h3>数据存储过程</h3>

<p>一个数据项的大致存储量过程可以理解为（完整代码较长，不在粘贴，具体可参见items.c中do_item_alloc()方法）：</p>

<ol>
<li>构造一个数据项结构体，计算数据项的大小，（假设默认配置下，数据项大小为102B）</li>
<li>根据数据项的大小，找到最合适的slab，（100&lt;102&lt;125，所以存储在slab3中）</li>
<li>检查该slab中是否有过期的数据，如有清理掉</li>
<li>如果没有过期的数据项，则从当前slab中申请空间，参见slabs.c中slab_alloc()方法。</li>
<li>如果当前slab中申请失败，则尝试根据LRU算法逐出一个数据项，默认memcache是允许逐出的，如果被设置为禁止逐出，那么这是会反生悲剧的oom了</li>
<li>获取到item空间后将数据存储到改空间中，并追加到该slab的item列表中</li>
</ol>


<p>一个slab的申请一个chunk空间的过程大致如下（以下代码节选自slabs.c）：</p>

<pre><code>195 static int do_slabs_newslab(const unsigned int id) { 
196     slabclass_t *p = &amp;slabclass[id];
197     int len = settings.slab_reassign ? settings.item_size_max
198         : p-&gt;size * p-&gt;perslab;
199     char *ptr;             
200            
201     if ((mem_limit &amp;&amp; mem_malloced + len &gt; mem_limit &amp;&amp; p-&gt;slabs &gt; 0) ||
202         (grow_slab_list(id) == 0) ||    
203         ((ptr = memory_allocate((size_t)len)) == 0)) {
204            
205         MEMCACHED_SLABS_SLABCLASS_ALLOCATE_FAILED(id);
206         return 0;          
207     }      
208            
209     memset(ptr, 0, (size_t)len);    
210     split_slab_page_into_freelist(ptr, id);
211            
212     p-&gt;slab_list[p-&gt;slabs++] = ptr; 
213     mem_malloced += len;   
214     MEMCACHED_SLABS_SLABCLASS_ALLOCATE(id);
215            
216     return 1;              
217 }
218  
219 /*@null@*/ 
220 static void *do_slabs_alloc(const size_t size, unsigned int id) {
221     slabclass_t *p;        
222     void *ret = NULL;      
223     item *it = NULL;       
224  
225     if (id &lt; POWER_SMALLEST || id &gt; power_largest) {
226         MEMCACHED_SLABS_ALLOCATE_FAILED(size, 0);
227         return NULL;
228     }
229  
230     p = &amp;slabclass[id];
231     assert(p-&gt;sl_curr == 0 || ((item *)p-&gt;slots)-&gt;slabs_clsid == 0);
232  
233     /* fail unless we have space at the end of a recently allocated page,
234        we have something on our freelist, or we could allocate a new page */
235     if (! (p-&gt;sl_curr != 0 || do_slabs_newslab(id) != 0)) {
236         /* We don't have more memory available */
237         ret = NULL;
238     } else if (p-&gt;sl_curr != 0) {
239         /* return off our freelist */
240         it = (item *)p-&gt;slots;
241         p-&gt;slots = it-&gt;next;
242         if (it-&gt;next) it-&gt;next-&gt;prev = 0;
243         p-&gt;sl_curr--;
244         ret = (void *)it;
245     }
246  
247     if (ret) {
248         p-&gt;requested += size;
249         MEMCACHED_SLABS_ALLOCATE(size, id, p-&gt;size, ret);
250     } else {
251         MEMCACHED_SLABS_ALLOCATE_FAILED(size, id);
252     }
253  
254     return ret;
255 }
</code></pre>

<p>slab优先从slots（空闲chunk空间列表）中申请空间，如果没有则尝试申请一个Page的新空间（do_slab_newslab()），申请新slab是会先判断是否进行slab_reasgin（重新分配slab空间，默认不开启）。</p>

<h2>内存浪费</h2>

<p>根据上述描述，Memcache使用Slab预分配的方式进行内存管理提升了性能（减少分配内存的消耗），但是带来了内存浪费，主要体现在：</p>

<ol>
<li><p>Data Item Size &lt;= Chunk Size，Chunk是存储数据项的最小单元，数据项的大小必须不大于其所在的Chunk大小。也就是说76B的数据对象存入96B的Chunk中，将带来96B-76B=20B的空间浪费。</p></li>
<li><p>Memcache是按照Page申请和使用内存的，当Page大小不是Chunk的整数倍时，余下的空间将被浪费。即如果PageSize=1M，ChunkSize=1000B,那么将有1024*1024%1000=576B的空间浪费。</p></li>
<li><p>Memcache默认是不开启slab reasign的，也就是说分配已经分配给一个slab的内存空间，即使该slab不用，默认也不会分配给其他slab的</p></li>
</ol>


<h2>案例分析：定长问题导致逐出</h2>

<p>memcache的chunk分布是均匀的，这是为了通用性考虑，但是现实中一些场景chunk的分布是不均运的，例如为了减小对数据库的压力，对数据进行了全量缓存，为标识数据库中不存在的记录，向缓存中放置了一个stupidObject。这个对象大小是固定的，且该数据的量很大，导致该数据类型所在的slab占用了大量缓存空间。再一次调整对象结构时，修改了这个StupidObject大小，使其分布在另一个slab中，但是这个原分配的slab空间不会回收，空闲空间不足，导致大量逐出。</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/5/">&larr; Older</a>
    
    <a href="archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/3/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <ul id="recent_posts">
      <li class="post">
      <a href="http://jiangbo.me" alt="Home"><img src="/images/Home.png"></a>
      <a href="http://jiangbo.me/archives/" alt="Archives"><img src="/images/Calendar.png"></a>
      <a href="mailto:" alt="E-Mail"><img src="/images/Envelope.png"></a>
      <a href="http://jiangbo.me/atom.xml" alt="subscribe feed"><img src="/images/rss.png"></a>
      </li>
  </ul>
</section>
<section>
  <h1>关于我</h1>
  <p>一个非纯种程序员，爱代码爱产品爱旅行爱美女</p>
  <iframe width="100%" height="550" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=550&fansRow=1&ptype=1&speed=0&skin=2&isTitle=0&noborder=1&isWeibo=1&isFans=0&uid=1892066397&verifier=8c17d4b5&dpc=1"></iframe>

</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2012/12/21/hdfs-raid/">HDFS RAID</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/12/10/hdfs-blockreaderlocal/">HDFS-2246:使用BlockReaderLocal优化本地block读取</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/10/23/mount-hdfs-with-fuse-dfs/">使用FUSE-DFS mount HDFS</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/10/18/hdfs-dataxceiver/">HDFS源码学习（15）——DataXceiverServer</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/10/18/hdfs-client-code/">HDFS源码学习（14）——Client代码结构</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/10/18/hdfs-datanode-startup/">HDFS源码学习（13）——DataNode启动过程</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/10/18/hdfs-datanode-structure/">HDFS源码学习（12）——DataNode主要数据结构</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/10/18/hdfs-secondary-namenode/">HDFS源码学习（11）——SecondaryNameNode</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/10/18/hdfs-namenode-and-datanode-communication/">HDFS源码学习（10）——NameNode与DataNode间的通信</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/10/18/hdfs-namenode-safe-mode/">HDFS源码学习（9）——安全模式（SafeMode）</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/jiang-bo">@jiang-bo</a> on GitHub
  
  <script type="text/javascript">
    $.domReady(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'jiang-bo',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>




  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2012 - jiang-bo -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'jiangbo';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>











</body>
</html>
