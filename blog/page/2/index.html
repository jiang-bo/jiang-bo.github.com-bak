
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>非纯种程序猿</title>
  <meta name="author" content="jiang-bo">

  
  <meta name="description" content="NameNode和DataNode间的通信分为四种场景： 初始时DataNode注册：
周期性心跳检测：
周期性blockreport：
完成一个副本的写入： 一、初始时DataNode注册 DataNode在启动时会向NameNode注册， &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://jiangbo.me/blog/page/2">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="非纯种程序猿" type="application/atom+xml">
  <!-- font-family: 'Knewave', cursive; -->
<link href='http://fonts.googleapis.com/css?family=Knewave' rel='stylesheet' type='text/css'>
<!-- font-family: 'Cantata One', serif; -->
<link href='http://fonts.googleapis.com/css?family=Cantata+One' rel='stylesheet' type='text/css'>

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-34477986-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1>
      <a href="/">非纯种程序猿</a>
      
  </h1>
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:jiangbo.me" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Home</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/about-me">About Me</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/10/18/hdfs-namenode-and-datanode-communication/">HDFS源码学习（10）——NameNode与DataNode间的通信</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-10-18T21:54:00+08:00" pubdate data-updated="true">Oct 18<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/10/18/hdfs-namenode-and-datanode-communication/#disqus_thread">Comments</a>
        
        
          | 

<span class="categories">
  
    <a class='category' href='/blog/categories/hdfs/'>HDFS</a>
  
</span>


        
      </p>
    
  </header>


  <div class="entry-content"><p>NameNode和DataNode间的通信分为四种场景：</p>

<ol>
<li>初始时DataNode注册：</li>
<li>周期性心跳检测：</li>
<li>周期性blockreport：</li>
<li>完成一个副本的写入：</li>
</ol>


<h2>一、初始时DataNode注册</h2>

<p>DataNode在启动时会向NameNode注册，注册时需要提交的信息有DatanodeRegistration表示。结构如下：</p>

<p><img src="/images/hdfs/DatanodeRegistration.png" alt="DatanodeRegistration" /></p>

<p>主要包括：</p>

<ol>
<li>name：机器名（主机名+服务端口号）</li>
<li>infoPort: 状态信息服务端口好</li>
<li>ipcPort： 提供ipc服务的端口号</li>
</ol>


<p>此外，该类中的storageID是该datanode在集群中的唯一id，在注册时有NameNode分配</p>

<p>注册的主要流程如下：
<img src="/images/hdfs/register.png" alt="DataNodeRegister" /></p>

<h2>二、心跳检测（heartbeat）</h2>

<p>DataNode通过周期性调用namenode.sendHeartbeat()来完成心跳检测.主要流程如下：</p>

<p><img src="/images/hdfs/sendHeartbeat.png" alt="sendHeartbeat" /></p>

<h2>三、blockReport</h2>

<p>DataNode周期性向NameNode发送blockReport，告知自己最新的block信息：
<img src="/images/hdfs/blockReport.png" alt="blockReport" /></p>

<h2>四、完成副本写入</h2>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/10/18/hdfs-namenode-safe-mode/">HDFS源码学习（9）——安全模式（SafeMode）</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-10-18T21:52:00+08:00" pubdate data-updated="true">Oct 18<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/10/18/hdfs-namenode-safe-mode/#disqus_thread">Comments</a>
        
        
          | 

<span class="categories">
  
    <a class='category' href='/blog/categories/hdfs/'>HDFS</a>
  
</span>


        
      </p>
    
  </header>


  <div class="entry-content"><h2>一、SafeModeInfo</h2>

<p>SafeModeInfo维护了系统安全模式下的状态信息，每当系统进入安全模式时都会创建一个SafeModeInfo实例维护状态信息，离开时会销毁这个实例。
该类结构如下</p>

<p><img src="/images/hdfs/SafeModeInfo.png" alt="SafeModeInfo" /></p>

<p>其中threshold和extension为可配置项：</p>

<ol>
<li>threshold表示离开安全模式时打到最低备份数的block的比例</li>
<li>extension表示进入安全模式的最低时长</li>
</ol>


<h2>二、SafeModeMonitor</h2>

<p>FSNameSystem中SafeModeMonitor代码结构如下：</p>

<pre><code>  class SafeModeMonitor implements Runnable {
    /** interval in msec for checking safe mode: {@value} */
    private static final long recheckInterval = 1000;

    /**
     */
    public void run() {
      while (fsRunning &amp;&amp; (safeMode != null &amp;&amp; !safeMode.canLeave())) {
        try {
          Thread.sleep(recheckInterval);
        } catch (InterruptedException ie) {
        }
      }
      // leave safe mode and stop the monitor
      try {
        leaveSafeMode(true);
      } catch(SafeModeException es) { // should never happen
        String msg = "SafeModeMonitor may not run during distributed upgrade.";
        assert false : msg;
        throw new RuntimeException(msg, es);
      }
      smmthread = null;
    }
  }
</code></pre>

<p>其核心就是每个1秒检测一次是否能够离开模式（safeMode.canLeave()），如果可以，则尝试离开并停止SafeModeMonitor线程（leaveSafeMode(true)）</p>

<h3>1.1. 是否能离开 —— safeMode.canLeave()</h3>

<p>能够离开安全模式的标准是：
1. 已进入安全模式的时长大于等于 extension
2. 安全的block数比例打到门槛值</p>

<pre><code>synchronized boolean canLeave() {
  if (reached == 0)
    return false;
  if (now() - reached &lt; extension) {
    reportStatus("STATE* Safe mode ON.", false);
    return false;
  }
  return !needEnter();
}

/** 
 * There is no need to enter safe mode 
 * if DFS is empty or {@link #threshold} == 0
 */
boolean needEnter() {
  return getSafeBlockRatio() &lt; threshold;
}
</code></pre>

<h3>1.2. 离开安全模式 —— leaveSafeMode(true);</h3>

<pre><code>  public void leaveSafeMode(boolean checkForUpgrades) throws SafeModeException {
    writeLock();
    try {
    if (!isInSafeMode()) {
      NameNode.stateChangeLog.info("STATE* Safe mode is already OFF."); 
      return;
    }
    //获取升级状态，如在升级中，不能离开安全模式
    if(getDistributedUpgradeState())
      throw new SafeModeException("Distributed upgrade is in progress",
                                  safeMode);
    //调用SafeModeInfo.leave()离开安全模式
    safeMode.leave(checkForUpgrades);
    } finally {
      writeUnlock();
    }
  }
</code></pre>

<h3>1.2.1 SafeModeInfo.leave()</h3>

<pre><code>    synchronized void leave(boolean checkForUpgrades) {
      if(checkForUpgrades) {
        // 验证是否需要升级
        boolean needUpgrade = false;
        try {
          needUpgrade = startDistributedUpgradeIfNeeded();
        } catch(IOException e) {
          FSNamesystem.LOG.error(StringUtils.stringifyException(e));
        }
        if(needUpgrade) {
          //如果需要升级，进入手动安全模式
          safeMode = new SafeModeInfo();
          return;
        }
      }
      // 如果备份队列未初始化完，继续初始化该队列
      if (!isPopulatingReplQueues()) {
        initializeReplQueues();
      }
      long timeInSafemode = now() - systemStart;
      NameNode.stateChangeLog.info("STATE* Leaving safe mode after " 
                                    + timeInSafemode/1000 + " secs.");
      NameNode.getNameNodeMetrics().safeModeTime.set((int) timeInSafemode);

      if (reached &gt;= 0) {
        NameNode.stateChangeLog.info("STATE* Safe mode is OFF."); 
      }
      reached = -1;
      safeMode = null;
      NameNode.stateChangeLog.info("STATE* Network topology has "
                                   +clusterMap.getNumOfRacks()+" racks and "
                                   +clusterMap.getNumOfLeaves()+ " datanodes");
      NameNode.stateChangeLog.info("STATE* UnderReplicatedBlocks has "
                                   +neededReplications.size()+" blocks");
    }
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/10/18/hdfs-namenode-backup-mode/">HDFS源码学习（8）——Backup Mode</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-10-18T21:51:00+08:00" pubdate data-updated="true">Oct 18<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/10/18/hdfs-namenode-backup-mode/#disqus_thread">Comments</a>
        
        
          | 

<span class="categories">
  
    <a class='category' href='/blog/categories/hdfs/'>HDFS</a>
  
</span>


        
      </p>
    
  </header>


  <div class="entry-content"><h2>元数据的持久化</h2>

<p>HDFS通过主要通过FSImage和FSEditLog来完成文件元数据的持久化。对文件系统的任何修改，NameNode都会通过Editlog记录下来，持久化到本地。同时整个系统的命名空间，所有的文件元信息均保存在FSImage中，包括block->File的映射，文件的属性等等。NameNode启动时会从本地磁盘加载FSImage和FSEditLog，并将EditLog中的日志信息合并到FSImage中进行之持久化（该合并过程称为一个检查点：checkpoint），并构建文件系统的元信息。</p>

<p>但是持久化的数据中不包括block<->datanode的映射信息，该信息由每个datanode向NameNode发起blockReport()请求时报告其所拥有的block信息。</p>

<h3>Editlog记录修改日志</h3>

<p>EditLog的持久化文件是一个二进制文件，大体结构如下：</p>

<p><img src="/images/hdfs/EditLogFile.png" alt="EditLogFile" /></p>

<p>EditLog文件开始是一个日志版本号，0.19版本的hdfs中该version为-18。
随后是每一条操作的事务日志，每条日志的起始为一个操作类型位，随后是该操作的详细信息，不同的操作类型所带的详细信息也不同。加载EditLog是根据layoutVersion和edit_op位采取不同的方式解析后面的详细信息。
EditLog能够记录如下17中操作：</p>

<p><img src="/images/hdfs/EditLogOp.png" alt="EditLogOp" /></p>

<p>EditLog为每种操作都提供了相应的log方法，当系统中发生文件修改时，会调用相应的log方法记录日志</p>

<h2>元数据加载与恢复</h2>

<p>NameNode启动过程中最终会通过FSImage.loadFSImage()来从fsimage目录中加载最新的fsimage镜像和editslog，并合并构建命名空间。
代码结构如下：</p>

<pre><code>  boolean loadFSImage() throws IOException {
    // 根据checkpointtime查找最新的fsimage
    long latestNameCheckpointTime = Long.MIN_VALUE;
    long latestEditsCheckpointTime = Long.MIN_VALUE;
    StorageDirectory latestNameSD = null;
    StorageDirectory latestEditsSD = null;
    boolean needToSave = false;
    isUpgradeFinalized = true;
    Collection&lt;String&gt; imageDirs = new ArrayList&lt;String&gt;();
    Collection&lt;String&gt; editsDirs = new ArrayList&lt;String&gt;();
    for (Iterator&lt;StorageDirectory&gt; it = dirIterator(); it.hasNext();) {
      StorageDirectory sd = it.next();
      if (!sd.getVersionFile().exists()) {
        needToSave |= true;
        continue; // some of them might have just been formatted
      }
      boolean imageExists = false, editsExists = false;
      if (sd.getStorageDirType().isOfType(NameNodeDirType.IMAGE)) {
        imageExists = getImageFile(sd, NameNodeFile.IMAGE).exists();
        imageDirs.add(sd.getRoot().getCanonicalPath());
      }
      if (sd.getStorageDirType().isOfType(NameNodeDirType.EDITS)) {
        editsExists = getImageFile(sd, NameNodeFile.EDITS).exists();
        editsDirs.add(sd.getRoot().getCanonicalPath());
      }

      checkpointTime = readCheckpointTime(sd);
      if ((checkpointTime != Long.MIN_VALUE) &amp;&amp; 
          ((checkpointTime != latestNameCheckpointTime) || 
           (checkpointTime != latestEditsCheckpointTime))) {
        // Force saving of new image if checkpoint time
        // is not same in all of the storage directories.
        needToSave |= true;
      }
      if (sd.getStorageDirType().isOfType(NameNodeDirType.IMAGE) &amp;&amp; 
         (latestNameCheckpointTime &lt; checkpointTime) &amp;&amp; imageExists) {
        latestNameCheckpointTime = checkpointTime;
        latestNameSD = sd;
      }
      if (sd.getStorageDirType().isOfType(NameNodeDirType.EDITS) &amp;&amp; 
           (latestEditsCheckpointTime &lt; checkpointTime) &amp;&amp; editsExists) {
        latestEditsCheckpointTime = checkpointTime;
        latestEditsSD = sd;
      }
      if (checkpointTime &lt;= 0L)
        needToSave |= true;
      // set finalized flag
      isUpgradeFinalized = isUpgradeFinalized &amp;&amp; !sd.getPreviousDir().exists();
    }

    // 确保至少有一个fsimage和一个edits目录
    if (latestNameSD == null)
      throw new IOException("Image file is not found in " + imageDirs);
    if (latestEditsSD == null)
      throw new IOException("Edits file is not found in " + editsDirs);

    // 确保获得的fsimage和edits是同一个检查点
    if (latestNameCheckpointTime &gt; latestEditsCheckpointTime
        &amp;&amp; latestNameSD != latestEditsSD
        &amp;&amp; latestNameSD.getStorageDirType() == NameNodeDirType.IMAGE
        &amp;&amp; latestEditsSD.getStorageDirType() == NameNodeDirType.EDITS) {
      // This is a rare failure when NN has image-only and edits-only
      // storage directories, and fails right after saving images,
      // in some of the storage directories, but before purging edits.
      // See -NOTE- in saveNamespace().
      LOG.error("This is a rare failure scenario!!!");
      LOG.error("Image checkpoint time " + latestNameCheckpointTime +
          " &gt; edits checkpoint time " + latestEditsCheckpointTime);
      LOG.error("Name-node will treat the image as the latest state of " +
          "the namespace. Old edits will be discarded.");
    } else if (latestNameCheckpointTime != latestEditsCheckpointTime)
      throw new IOException("Inconsitent storage detected, " +
          "image and edits checkpoint times do not match. " +
          "image checkpoint time = " + latestNameCheckpointTime +
          "edits checkpoint time = " + latestEditsCheckpointTime);

    // 如果上次检查点中断了，则恢复该检查点
    needToSave |= recoverInterruptedCheckpoint(latestNameSD, latestEditsSD);

    long startTime = FSNamesystem.now();
    long imageSize = getImageFile(latestNameSD, NameNodeFile.IMAGE).length();

    //
    // 加载fsimage文件
    //
    latestNameSD.read();
    needToSave |= loadFSImage(getImageFile(latestNameSD, NameNodeFile.IMAGE));
    LOG.info("Image file of size " + imageSize + " loaded in " 
        + (FSNamesystem.now() - startTime)/1000 + " seconds.");

    // 加载最新的edits并作用于fsimage上
    if (latestNameCheckpointTime &gt; latestEditsCheckpointTime)
      // the image is already current, discard edits
      needToSave |= true;
    else // latestNameCheckpointTime == latestEditsCheckpointTime
      needToSave |= (loadFSEdits(latestEditsSD) &gt; 0);

    return needToSave;
  }
</code></pre>

<p>其中FSImage.loadFSImage(File curFile) 代码如下：</p>

<pre><code>  boolean loadFSImage(File curFile) throws IOException {
    assert this.getLayoutVersion() &lt; 0 : "Negative layout version is expected.";
    assert curFile != null : "curFile is null";

    FSNamesystem fsNamesys = FSNamesystem.getFSNamesystem();
    FSDirectory fsDir = fsNamesys.dir;

    //
    // Load in bits
    //
    boolean needToSave = true;
    DataInputStream in = new DataInputStream(new BufferedInputStream(
                              new FileInputStream(curFile)));
    try {
      /*
       * Note: Remove any checks for version earlier than 
       * Storage.LAST_UPGRADABLE_LAYOUT_VERSION since we should never get 
       * to here with older images.
       */

      /*
       * TODO we need to change format of the image file
       * it should not contain version and namespace fields
       */
      // 读取imageversion
      int imgVersion = in.readInt();
      // 读取namespaceid
      this.namespaceID = in.readInt();

      // 读取镜像中的文件数
      long numFiles;
      if (imgVersion &lt;= -16) {
        numFiles = in.readLong();
      } else {
        numFiles = in.readInt();
      }

      this.layoutVersion = imgVersion;
      // 读取镜像时间戳
      if (imgVersion &lt;= -12) {
        long genstamp = in.readLong();
        fsNamesys.setGenerationStamp(genstamp); 
      }

      needToSave = (imgVersion != FSConstants.LAYOUT_VERSION);

      // 读取每个文件的信息
      short replication = FSNamesystem.getFSNamesystem().getDefaultReplication();

      LOG.info("Number of files = " + numFiles);

      byte[][] pathComponents;
      byte[][] parentPath = ;
      INodeDirectory parentINode = fsDir.rootDir;
      for (long i = 0; i &lt; numFiles; i++) {
        long modificationTime = 0;
        long atime = 0;
        long blockSize = 0;
        //读取文件名(path)
        pathComponents = readPathComponents(in);
        //读取副本数
        replication = in.readShort();
        //调整副本数，使其不超过系统的最大和最小副本数限制
        replication = FSEditLog.adjustReplication(replication);
        //读取文件修改时间
        modificationTime = in.readLong();
        if (imgVersion &lt;= -17) {
        //读取最近访问时间
          atime = in.readLong();
        }
        if (imgVersion &lt;= -8) {
        //读取block块大小
          blockSize = in.readLong();
        }
        //读取block数
        int numBlocks = in.readInt();
        //构建blocks
        Block blocks[] = null;

        // 老版本hdfs中，numBlocks=0表示目录，新版本中numBlocks=-1表示目录
        if ((-9 &lt;= imgVersion &amp;&amp; numBlocks &gt; 0) ||
            (imgVersion &lt; -9 &amp;&amp; numBlocks &gt;= 0)) {
           //构建文件block信息
          blocks = new Block[numBlocks];
          for (int j = 0; j &lt; numBlocks; j++) {
            blocks[j] = new Block();
            if (-14 &lt; imgVersion) {
              blocks[j].set(in.readLong(), in.readLong(), 
                            Block.GRANDFATHER_GENERATION_STAMP);
            } else {
              // 读取block信息
              blocks[j].readFields(in);
            }
          }
        }
        // 老版本inode中不维护blocksize，如果存在多个block，blocksize选取第一个block的大小，如果只有一个block，则选该block大小和默认大小中较大的，如果没有block，则选用默认大小
        if (-8 &lt;= imgVersion &amp;&amp; blockSize == 0) {
          if (numBlocks &gt; 1) {
            blockSize = blocks[0].getNumBytes();
          } else {
            long first = ((numBlocks == 1) ? blocks[0].getNumBytes(): 0);
            blockSize = Math.max(fsNamesys.getDefaultBlockSize(), first);
          }
        }

        // 如果是目录（blocks=null），读取该目录的配额
        long nsQuota = -1L;
        if (imgVersion &lt;= -16 &amp;&amp; blocks == null) {
          nsQuota = in.readLong();
        }
        long dsQuota = -1L;
        if (imgVersion &lt;= -18 &amp;&amp; blocks == null) {
          dsQuota = in.readLong();
        }

        //获取权限信息
        PermissionStatus permissions = fsNamesys.getUpgradePermission();
        if (imgVersion &lt;= -11) {
          permissions = PermissionStatus.read(in);
        }

        //如果该path为root，且设置了配额信息，则更新根目录的配额
        if (isRoot(pathComponents)) { // it is the root
          // update the root's attributes
          if (nsQuota != -1 || dsQuota != -1) {
            fsDir.rootDir.setQuota(nsQuota, dsQuota);
          }
          fsDir.rootDir.setModificationTime(modificationTime);
          fsDir.rootDir.setPermissionStatus(permissions);
          continue;
        }
        //如果该inode的parent与当前路径不一至，获取新的parentPaht
        if(!isParent(pathComponents, parentPath)) {
          parentINode = null;
          parentPath = getParent(pathComponents);
        }
        // 将该inode添加到inode树中
        parentINode = fsDir.addToParent(pathComponents, parentINode, permissions,
                                        blocks, replication, modificationTime, 
                                        atime, nsQuota, dsQuota, blockSize);
      }

      // 加载datanode信息，imgVersion&lt;-12的版本事实上啥都不做，datanode信息已经不保存在fsimage中
      this.loadDatanodes(imgVersion, in);

      // 加载正在构建中的文件
      this.loadFilesUnderConstruction(imgVersion, in, fsNamesys);

    } finally {
      in.close();
    }

    return needToSave;
  }
</code></pre>

<p>其核心就是加载并解析fsimage文件，构建命名空间，fsimage文件的结构参见《NameNode中主要数据结构》</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/10/18/hdfs-namenode-block-management/">HDFS源码学习（7）——Block管理</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-10-18T21:46:00+08:00" pubdate data-updated="true">Oct 18<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/10/18/hdfs-namenode-block-management/#disqus_thread">Comments</a>
        
        
          | 

<span class="categories">
  
    <a class='category' href='/blog/categories/hdfs/'>HDFS</a>
  
</span>


        
      </p>
    
  </header>


  <div class="entry-content"><p>HDFS通过一个BlockManager管理集群中所有的block信息</p>

<h2>主要数据结构</h2>

<h3>Block</h3>

<p>Block是HDFS读写的基本单元，集群中每个block通过一个long id来唯一标示。</p>

<h3>BlockInfo</h3>

<p>维护一个block的元信息，主要通过</p>

<h3>BlockMap</h3>

<p>通过一个GSet&lt;Block, BlockInfo>维护一个block与其元数据信息的映射关系，元信息包括其所属的BlockCollection和存储该block的datanode节点，每个BlockMap有个初始容量capacity</p>

<h3>BlockCollection</h3>

<h2>Block和副本管理</h2>

<h3>Block和副本状态</h3>

<p>Block有如下状态：</p>

<ol>
<li>committed：所有的副本已经被创建且更新至最新</li>
<li>Under construction: 需要创建一个或多个副本</li>
<li>To be deleted: 所有副本需要被删除。发生在文件被删除或者block被重写</li>
<li>Over-replicated: 过多的副本存在。此时副本中的一个需要设置为无效并删除。</li>
</ol>


<p>副本有如下状态：</p>

<ol>
<li>Current: 正常状态，该副本正确反应block内容</li>
<li>Conrrupt: 某个副本损坏。副本损坏是由client报告给namenode的。client通过checksum检查副本是否损坏，如果损坏了，通过BlockManager.invalidateBlock()处理</li>
<li>On a faild DataNode: DataNode Heartbeat发现有DataNode失效时，即将在改datanode上创建的副本将被删除</li>
<li>Out of Date: 当Datanode失效，且副本所属的block发生更新后，Datanode恢复正常。过期的block将通过blockreport报告给namenode，并将其删除</li>
<li>Under construction: 副本尚未被写入并在Datanode上被验证。在NameNode看来，只有当收到blockReport并且报告中timestamp正确时，猜人物副本写入正常。</li>
</ol>


<h2>Block分配</h2>

<h2>Block查询</h2>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/10/18/hdfs-namenode-lease-management/">HDFS源码学习（6）——租约管理（lease Management)</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-10-18T21:44:00+08:00" pubdate data-updated="true">Oct 18<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/10/18/hdfs-namenode-lease-management/#disqus_thread">Comments</a>
        
        
          | 

<span class="categories">
  
    <a class='category' href='/blog/categories/hdfs/'>HDFS</a>
  
</span>


        
      </p>
    
  </header>


  <div class="entry-content"><p>LeaseManagement是HDFS中的一个同步机制，用于保证同一时刻只有一个client对一个文件进行写或创建操作。如当新建一个文件f时，client向NameNode发起一个create请求，那么leaseManager会想该client分配一个f文件的lease。client凭借该lease完成文件的创建操作。此时其他client无法获得f的当client长时间（默认为超过1min）不进行操作时，发放的lease将被收回。</p>

<p>LeaseManager主要完成两部分工作：</p>

<ol>
<li>文件create，write，complete操作时，创建lease、更新时间戳、回收lease</li>
<li>一个后台线程定期检查是否有过期的lease</li>
</ol>


<p>LeaseManager的代码结构如下</p>

<p><img src="/images/hdfs/LeaseManager.png" alt="LeaseManager" /></p>

<p>其中Lease表示一个租约，包括一个client(holder)所拥有的所有文件锁(paths)。</p>

<p>Monitor是检查是否有过期租约的线程。</p>

<p>LeaseManager中有几个主要数据结构：</p>

<ol>
<li>leases（TreeMap&lt;String, Lease>）：维护holder -> leased的映射集合</li>
<li>sortedLeases (TreeSet<Lease>): lease集合</li>
<li>sortedLeaseByPath(TreeMap&lt;String, Lease>): 维护paths->lease的映射集合</li>
</ol>


<h2>一、创建lease</h2>

<p>当client向NameNode发起create操作时，NameNode.create()调用FSNameSystem.startFile()->FSNameSystem.startFileInternal()，该方法最终会调用leaseManager.addLease(cons.clientName, src)来创建lease。</p>

<p>LeaseManager.addLease()方法如下：</p>

<pre><code>  synchronized Lease addLease(String holder, String src
      ) throws IOException {
    Lease lease = getLease(holder);
    if (lease == null) {
      lease = new Lease(holder);
      leases.put(holder, lease);
      sortedLeases.add(lease);
    } else {
      renewLease(lease);
    }
    sortedLeasesByPath.put(src, lease);
    lease.paths.add(src);
    return lease;
  }
</code></pre>

<p>代码结构简单：判断该client是否有lease，没有则新建一个lease，并将起加到leases集合中。否则更新lease。更新sortedLeasesByPath，将filepath加入到该lease的paths集合中</p>

<h2>二、更新时间戳</h2>

<p>针对已经存在的lease，通过LeasemManager.renewLease()来更新该lease的时间戳。代码如下：</p>

<pre><code>  synchronized void renewLease(Lease lease) {
    if (lease != null) {
      sortedLeases.remove(lease);
      lease.renew();
      sortedLeases.add(lease);
    }
  }
</code></pre>

<p>lease.renew()代码如下：</p>

<pre><code>/** Only LeaseManager object can renew a lease */
private void renew() {
  this.lastUpdate = FSNamesystem.now();
}
</code></pre>

<h2>三、compelete时回收lease</h2>

<p>当client调用NameNode.complete()方法时，最终会调用FSNameSystem.completeFileInternal()方法。其中执行finalizeINodeFileUnderConstruction()是调用leaseManager.removeLease()释放lease。</p>

<p>代码结构如下：</p>

<pre><code>  synchronized void removeLease(String holder, String src) {
    Lease lease = getLease(holder);
    if (lease != null) {
      removeLease(lease, src);
    }
  }
</code></pre>

<p> removeLease(lease, src);代码如下：</p>

<pre><code>  /**
   * Remove the specified lease and src.
   */
  synchronized void removeLease(Lease lease, String src) {
    sortedLeasesByPath.remove(src);
    if (!lease.removePath(src)) {
      LOG.error(src + " not found in lease.paths (=" + lease.paths + ")");
    }

    if (!lease.hasPath()) {
      leases.remove(lease.holder);
      if (!sortedLeases.remove(lease)) {
        LOG.error(lease + " not found in sortedLeases");
      }
    }
  }
</code></pre>

<h2>四、后台线程回收过期lease</h2>

<p>Monitor回收lease线程代码结构如下：</p>

<pre><code> class Monitor implements Runnable {
    final String name = getClass().getSimpleName();

    /** Check leases periodically. */
    public void run() {
      for(; fsnamesystem.isRunning(); ) {
        fsnamesystem.writeLock();
        try {
          checkLeases();
        } finally {
          fsnamesystem.writeUnlock();
        }

        try {
          Thread.sleep(2000);
        } catch(InterruptedException ie) {
          if (LOG.isDebugEnabled()) {
            LOG.debug(name + " is interrupted", ie);
          }
        }
      }
    }
  }
</code></pre>

<p>代码结构简单，每个2s周期性执行checkLeases()。</p>

<h3>4.1 checkLeases()</h3>

<pre><code>  /** Check the leases beginning from the oldest. */
  synchronized void checkLeases() {
    for(; sortedLeases.size() &gt; 0; ) {
      final Lease oldest = sortedLeases.first();
      if (!oldest.expiredHardLimit()) {
        return;
      }

      LOG.info("Lease " + oldest + " has expired hard limit");

      final List&lt;String&gt; removing = new ArrayList&lt;String&gt;();
      // need to create a copy of the oldest lease paths, becuase 
      // internalReleaseLease() removes paths corresponding to empty files,
      // i.e. it needs to modify the collection being iterated over
      // causing ConcurrentModificationException
      String[] leasePaths = new String[oldest.getPaths().size()];
      oldest.getPaths().toArray(leasePaths);
      for(String p : leasePaths) {
        try {
          fsnamesystem.internalReleaseLeaseOne(oldest, p);
        } catch (IOException e) {
          LOG.error("Cannot release the path "+p+" in the lease "+oldest, e);
          removing.add(p);
        }
      }

      for(String p : removing) {
        removeLease(oldest, p);
      }
    }
  }
</code></pre>

<h2>Lease Recovery ——租约回收</h2>

<h3>lease recovery时机</h3>

<p>lease发放之后，在不用时会被回收，回收的产经除上述Monitor线程检测lease过期是回收外，还有：</p>

<ol>
<li>NameNode收到DataNode的Sync block command时</li>
<li>DFSClient主动关闭一个流时</li>
<li>创建文件时，如果该DFSClient的lease超过soft limit时</li>
</ol>


<h3>lease recovery 算法</h3>

<p>1) NameNode查找lease信息</p>

<p>2) 对于lease中的每个文件f，令b为f的最后一个block，作如下操作：</p>

<p>2.1) 获取b所在的datanode列表</p>

<p>2.2) 令其中一个datanode作为primary datanode p</p>

<p>2.3) p 从NameNode获取最新的时间戳</p>

<p>2.4) p 从每个DataNode获取block信息</p>

<p>2.5) p 计算最小的block长度</p>

<p>2.6) p 用最小的block长度和最新的时间戳来更新具有有效时间戳的datanode</p>

<p>2.7) p 通知NameNode更新结果</p>

<p>2.8) NameNode更新BlockInfo</p>

<p>2.9) NameNode从lease中删除f，如果此时该lease中所有文件都已被删除，将删除该lease</p>

<p>2.10) Name提交修改的EditLog</p>

<h2>Client续约 —— DFSClient.LeaseChecker</h2>

<p>在NameNode上的LeaseManager.Monitor线程负责检查过期的lease，那么client为了防止尚在使用的lease过期，需要定期想NameNode发起续约请求。该任务有DFSClient中的LeaseChecker完成。</p>

<p>LeaseChecker结构如下：</p>

<p><img src="/images/hdfs/LeaseChecker.png" alt="LeaseChecker" /></p>

<p>其中pendingCreates是一个TreeMap&lt;String, OutputStream>用来维护src->当前正在写入的文件的DFSOutputStream的映射。</p>

<p>其核心是周期性（每个1s）调用run()方法来对租约过半的lease进行续约</p>

<pre><code>public void run() {
  long lastRenewed = 0;
  while (clientRunning &amp;&amp; !Thread.interrupted()) {
    //当租约周期过半时需要进行续约
    if (System.currentTimeMillis() - lastRenewed &gt; (LEASE_SOFTLIMIT_PERIOD / 2)) {
      try {
        renew();
        lastRenewed = System.currentTimeMillis();
      } catch (IOException ie) {
        LOG.warn("Problem renewing lease for " + clientName, ie);
      }
    }

    try {
      Thread.sleep(1000);
    } catch (InterruptedException ie) {
      if (LOG.isDebugEnabled()) {
        LOG.debug(this + " is interrupted.", ie);
      }
      return;
    }
  }
}
</code></pre>

<p>其中renew()方法如下：</p>

<pre><code>    private void renew() throws IOException {
      synchronized(this) {
        //如果当前创建中的文件列表为空，则不需要续约
        if (pendingCreates.isEmpty()) {
          return;
        }
      }
      //向NameNode发起续约请求
      namenode.renewLease(clientName);
    }
</code></pre>

<p>NameNode接收到renewLease请求后，调用FSNameSystem.renewLease()并最终调用LeaseManager.renewLease()完成续约。</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/3/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section class="first odd">
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2012/10/18/hdfs-dataxceiver/">HDFS源码学习（15）——DataXceiverServer</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/10/18/hdfs-client-code/">HDFS源码学习（14）——Client代码结构</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/10/18/hdfs-datanode-startup/">HDFS源码学习（13）——DataNode启动过程</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/10/18/hdfs-datanode-structure/">HDFS源码学习（12）——DataNode主要数据结构</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/10/18/hdfs-secondary-namenode/">HDFS源码学习（11）——SecondaryNameNode</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/10/18/hdfs-namenode-and-datanode-communication/">HDFS源码学习（10）——NameNode与DataNode间的通信</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/10/18/hdfs-namenode-safe-mode/">HDFS源码学习（9）——安全模式（SafeMode）</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/10/18/hdfs-namenode-backup-mode/">HDFS源码学习（8）——Backup Mode</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/10/18/hdfs-namenode-block-management/">HDFS源码学习（7）——Block管理</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/10/18/hdfs-namenode-lease-management/">HDFS源码学习（6）——租约管理（lease management)</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/jiang-bo">@jiang-bo</a> on GitHub
  
  <script type="text/javascript">
    $.domReady(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'jiang-bo',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2012 - jiang-bo -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a> and <a href="https://github.com/gluttony/object-octopress-theme">Object</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'jiangbo';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>











</body>
</html>
