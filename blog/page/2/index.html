
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>非纯种程序猿</title>
  <meta name="author" content="jiang-bo">

  
  <meta name="description" content="一、背景 HDFS中对Block的读取使用DataXceiver通过Socket发送Packet数据进行，client端通过一个BlockReader来接收Socket中的Block数据。详见HDFS数据读取流程。大致流程如下： client端调用FileSystem.open() &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://jiangbo.me/blog/page/2/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="非纯种程序猿" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-34477986-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:jiangbo.me" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
    <li><a href="/">
        <span class="blue_light">
            非纯种程序猿
        </span>
       
    </a></li>
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/algorithm">Algorithm</a><li>
  <li><a href="/about-me">About me</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/12/10/hdfs-blockreaderlocal/">HDFS-2246:使用BlockReaderLocal优化本地block读取</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-12-10T16:09:00+08:00" pubdate data-updated="true">Dec 10<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/12/10/hdfs-blockreaderlocal/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>一、背景</h2>

<p>HDFS中对Block的读取使用DataXceiver通过Socket发送Packet数据进行，client端通过一个BlockReader来接收Socket中的Block数据。详见<a href="">HDFS数据读取流程</a>。大致流程如下：</p>

<ol>
<li>client端调用FileSystem.open()获取一个DFSInputStream</li>
<li>client端调用DFSInputStream.read(byte[] buffer, int off, int len)读取数据</li>
<li>client端通过DFSInputStream.blockSeekTo()向NameNode发起请求，定位到需要读取的block所在的Datanode，构建一个BlockReader用于读去对应DataNode上的block数据，返回该DataNodeInfo</li>
<li>BlockReader主要负责同DataNode间建立一个Socket链接用于读取数据，BlockReader首先向DataNode发送请求头（包括操作类型，blockId，block时间戳，起始偏移量，读取数据的长度，client名）</li>
<li>DataNode接收到DataXceiverServer接收到client端请求后，构建一个DataXceiver处理该请求。</li>
<li>DataXceiver首先解析请求头，获取请求操作类型，当发现是READ_BLOCK操作后，调用相应的readBlock()方法处理</li>
<li>readBlock方法解析请求中需要的blockId，构建一个BlockSender用于读取磁盘上的block文件数据并发送给client</li>
<li>BlockSender读取磁盘上的block文件，将数据按照chunk通过socket发送给client的blockReader，同时，BlockSender在发送chunk后需要从meta文件中读取该chunk的checksum数据，同样发送给client，用于该chunk的checksum校验。</li>
<li>client端通过BlockReader.readChunks()接收BlockSender发送的chunk数据，并进行checksum校验，校验成功后向DataNode发送checksumOk。</li>
<li>循环6-10，直至当前block的数据全部被读取完成。</li>
<li>循环执行3-11, 直至需要读取的文件数据都被读取完。</li>
</ol>


<p>这个过程是在集群环境想，client读取datanode上数据的一个正常流程，但事实上当client和datanode位于同一个物理节点上时（如Hadoop集群中，task运行在datanode上），这个过程显的有些多余，client可以直接通过本地文件系统api读取文件，而不需要走繁杂的socket流程。</p>

<h2>二、设计实现</h2>

<p>HDFS-2246中提供了一个BlockReaderLocal的实现，当client发现从NameNode返回的Block所属的datanode和client位于同一节点上时，构建一个BlockReaderLocal用于读取本地文件。
上述3-10的流程将简化为：</p>

<ol>
<li>client端向NameNode发起请求获取block所属的datanode信息后，判断该datanode是否和client位于同一节点，是且开启了本地读取功能，则构建一个BlockReaderLocal读取本地文件，否则构建一个BlockReader按照原流程进行。</li>
<li>BlockReaderLocal通过DataNode.getBlockLocaPathInfo()从DataNode获取block的本地文件路径信息。</li>
<li>BlockReaderLocal构建InputStream读取block文件和meta文件信息</li>
<li>对于需要checksum的场景（默认），通过blockReaderLocal.readChunks()按chunk读取本地文件，同时读取meta文件中该chunk的checksum数据，进行校验</li>
<li>对于跳过checksum的场景，直接通过InputStream.read()读取block数据。</li>
</ol>


<h3>扩展DataNode协议接口</h3>

<p>client端需要能够从DataNode获取block文件的本地文件路径信息。因此扩展ClientDataNodeProtocol，增加一个</p>

<pre><code>BlockLocalPathInfo getBlockLocalPathInfo(Block block) throws IOException;
</code></pre>

<p>接口用于获取block的本地路径信息</p>

<h3>本地文件读取</h3>

<p>BlockReaderLocal共过BufferedInputStream直接读取本地文件，注意此处HDFS-2246的patch中使用的是FileInputStream，实际测试过程中发现，FileInputStream对本地文件的读取性能较差， 替换为使用BufferedInputStream</p>

<h3>checksum较验</h3>

<p>为了完成checksum校验，BlockReaderLocal同时需要读取block的meta文件，每当block文件读取一个chunk时需要从meta文件读取一个checksum数据，进行checksum校验，通过校验后进行下一个chunk的读取和校验。由于BlockReaderLocal读取的是本地文件，避免的网络传输对数据的影响，因此可以配置跳过checksum检查，以提高读取性能。默认是需要做checksum的。</p>

<h3>本机判断</h3>

<p>当前patch中的实现主要用IP来判断是否block所在的datanode与client是否位于同一节点上。</p>

<h2>测试</h2>

<p>通过TestDFSIO工具测试一个单节点的集群，2个文件，每个文件1000M
./bin/hadoop jar hadoop-0.19.1-dc-test.jar TestDFSIO -read -nrFiles 2 -fileSize 1000
测试结果对比:
socket读取：</p>

<pre><code>---
12/12/07 13:52:57 INFO mapred.FileInputFormat: ----- TestDFSIO ----- : read
12/12/07 13:52:57 INFO mapred.FileInputFormat:            Date &amp; time: Fri Dec 07 13:52:57 CST 2012
12/12/07 13:52:57 INFO mapred.FileInputFormat:        Number of files: 2
12/12/07 13:52:57 INFO mapred.FileInputFormat: Total MBytes processed: 2000
12/12/07 13:52:57 INFO mapred.FileInputFormat:      Throughput mb/sec: 283.5270768358378
12/12/07 13:52:57 INFO mapred.FileInputFormat: Average IO rate mb/sec: 283.5281982421875
12/12/07 13:52:57 INFO mapred.FileInputFormat:  IO rate std deviation: 0.5685961122141402
</code></pre>

<p>本地读取</p>

<pre><code>---
12/12/07 13:48:59 INFO mapred.FileInputFormat: ----- TestDFSIO ----- : read
12/12/07 13:48:59 INFO mapred.FileInputFormat:            Date &amp; time: Fri Dec 07 13:48:59 CST 2012
12/12/07 13:48:59 INFO mapred.FileInputFormat:        Number of files: 2
12/12/07 13:48:59 INFO mapred.FileInputFormat: Total MBytes processed: 2000
12/12/07 13:48:59 INFO mapred.FileInputFormat:      Throughput mb/sec: 369.61744594344856
12/12/07 13:48:59 INFO mapred.FileInputFormat: Average IO rate mb/sec: 369.6180725097656
12/12/07 13:48:59 INFO mapred.FileInputFormat:  IO rate std deviation: 0.4800772
</code></pre>

<p>另外通过Patch中提供的TestShortCircuitLocalRead工具，测试结果如下：</p>

<p>本地读取并进行checksum校验</p>

<pre><code>true no 1 32000000
---
Iteration 20 took 115453
Iteration 20 took 115803
Iteration 20 took 115748
</code></pre>

<p>socket读取并进行checksum校验（默认）</p>

<pre><code>no no 1 32000000
---
Iteration 20 took 128820
Iteration 20 took 135305
Iteration 20 took 129145
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/10/23/mount-hdfs-with-fuse-dfs/">使用FUSE-DFS Mount HDFS</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-10-23T10:24:00+08:00" pubdate data-updated="true">Oct 23<span>rd</span>, 2012</time>
        
         | <a href="/blog/2012/10/23/mount-hdfs-with-fuse-dfs/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>介绍</h2>

<p>Hadooop源码中自带了contrib/fuse-dfs模块，用于实现通过libhdfs和fuse将HDFS mount到*inux的本地。</p>

<h2>编译</h2>

<h3>环境</h3>

<ol>
<li>Linux: 2.6.18-164.el5 x86_64</li>
<li>JDK: 1.6.0_23 64bit</li>
<li>Hadoop: 0.19.1 下面假设源码目录为$HADOOP_SRC_HOME</li>
<li>Ant: 1.8.4</li>
<li>GCC: 4.1.2(系统默认)</li>
</ol>


<h3>编译libhdfs</h3>

<h4>修改configure执行权限</h4>

<pre><code>$chmod +x $HADOOP_SRC_HOME/src/c++/pipes/configure
$chmod +x $HADOOP_SRC_HOME/src/c++/utils/configure
</code></pre>

<h4>修改Makefile，调整编译模式</h4>

<p>64位机中，需要修改libhdfs的Makefile，将GCC编译的输出模式由32(-m32)位改为64(-m64)位</p>

<pre><code>CC = gcc
LD = gcc
CFLAGS =  -g -Wall -O2 -fPIC
LDFLAGS = -L$(JAVA_HOME)/jre/lib/$(OS_ARCH)/server -ljvm -shared -m64(这里) -Wl,-x
PLATFORM = $(shell echo $$OS_NAME | tr [A-Z] [a-z])
CPPFLAGS = -m64(还有这里) -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/$(PLATFORM)
</code></pre>

<h4>编译</h4>

<p>在$HADOOP_HOME目录下执行</p>

<pre><code>$ ant compile -Dcompile.c++=true -Dlibhdfs=true
</code></pre>

<p>编译结果将生成libhdfs库，位于$HADOOP_SRC_HOME/build/libhdfs目录下</p>

<h3>编译fuse-dfs</h3>

<h4>安装fuse库</h4>

<p>fuse-dfs依赖fuse库，可通过</p>

<pre><code>sudo lsmod|grep fuse
</code></pre>

<p>检查是否已经安装，如没有，可通过：</p>

<pre><code>yum -y install fuse fuse-devel fuse-libs
</code></pre>

<p>安装相关依赖库。</p>

<h4>设置编译库路径</h4>

<p>设置编译库路径，将libhdfs的库加入到编译路径中</p>

<pre><code>export LD_LIBRARY_PATH=/usr/lib:/usr/local/lib:$HADOOP_SRC_HOME/build/c++/Linux-amd64-64/lib:$JAVA_HOME/jre/lib/amd64/server
</code></pre>

<h4>编译</h4>

<p>编译contrib/fuse-dfs模块：</p>

<pre><code>ant compile-contrib -Dlibhdfs=1 -Dfusedfs=1
</code></pre>

<p>编译完成将会生成$HADOOP_HOME/build/contrib/fuse-dfs/目录，内有：</p>

<pre><code>fuse-dfs]$ ls
fuse_dfs  fuse_dfs_wrapper.sh  test
</code></pre>

<p>其中fuse_dfs是可执行程序，fuse_dfs_wrapper.sh是包含一些环境变量设置的脚本，不过其中大部分需要修改:(</p>

<h4>修改fuse_dfs_warpper.sh</h4>

<pre><code>#Hadoop安装目录
export HADOOP_HOME=/home/bo.jiangb/yunti-trunk/build/hadoop-0.19.1-dc
#将fuse_dfs加入到PATH
export PATH=$HADOOP_HOME/contrib/fuse_dfs:$PATH
#将hadoop的jar加入到CLASSPATH
for f in ls $HADOOP_HOME/lib/*.jar $HADOOP_HOME/*.jar ; do
export  CLASSPATH=$CLASSPATH:$f
done
#设置机器模式
export OS_ARCH=amd64
#设置JAVA_HOME
export  JAVA_HOME=/home/admin/tools/jdk1.6
#将libhdfs加入到链接库路径中
export LD_LIBRARY_PATH=$JAVA_HOME/jre/lib/$OS_ARCH/server:/home/bo.jiangb/yunti-trunk/build/libhdfs:/usr/local/lib
./fuse_dfs $@
</code></pre>

<h2>使用</h2>

<h3>mount</h3>

<ol>
<li><p>新建一个空目录</p>

<p> $mkdir /tmp/dfs</p></li>
<li><p>挂载dfs
$./fuse_dfs_wrapper.sh dfs://master_node(namenode地址):port /tmp/dfs -d
-d表示debug模式，如果正常，可以将-d参数去掉。</p></li>
</ol>


<h3>unmount</h3>

<p>卸载可通过：</p>

<pre><code>fusermount -u /tmp/dfs
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/10/18/hdfs-dataxceiver/">HDFS源码学习（15）——DataXceiverServer</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-10-18T22:00:00+08:00" pubdate data-updated="true">Oct 18<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/10/18/hdfs-dataxceiver/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>HDFS中有两种类型的通信机制，一种是进行消息传递的Hadoop IPC机制，一种是用于处理数据传输的DataXceiver机制。前者包括client<->namenode之间的通信，以及datanode<->namenode间通信，后者包括client<->datanode, datanode<->datanode间的数据传输。</p>

<h2>DataXceiverServer</h2>

<p>DataNode在启动时会通过DataXceiverServer开启一个Socket端口，负责block数据的读写。DataXceiverServer本身作为一个守护线程，监听dfs.datanode.address配置的数据读写服务端口。当有请求来时，新建一个DataXceiver线程处理请求。</p>

<h2>DataXceiver</h2>

<p>DataXceiver线程用于处理一个读/写数据流请求，其run方法入下主要是根据请求中不同的请求类型，调用响应的处理方法。</p>

<p>请求操作类型定义在DataTransferProtocol中，主要有：</p>

<ol>
<li>OP_WRITE_BLOCK： 写入Block数据，对应writeBlock()方法</li>
<li>OP_READ_BLOCK： 读取Block数据，对应readBlock()方法</li>
<li>OP_READ_METADATA： 读取Block元数据，对应readMetadata()方法</li>
<li>OP_REPLACE_BLOCK： 替换Block，将block发送到目标datanode上，用于IO负载均衡；对应replaceBlock()方法。</li>
<li>OP_COPY_BLOCK：复制Block，将block发送到proxy source上，用于IO负载均衡；对应copyBlock()方法。</li>
<li>OP_BLOCK_CHECKSUM：获取Block的checksum；对应getBlockChecksum()方法。</li>
</ol>


<p>请处理返回的状态也定义在该类中：</p>

<ol>
<li>OP_STATUS_SUCCESS： 成功</li>
<li>OP_STATUS_ERROR： 请求出错</li>
<li>OP_STATUS_ERROR_CHECKSUM： checksum校验出错</li>
<li>OP_STATUS_ERROR_INVALID： 读取无效block</li>
<li>OP_STATUS_ERROR_EXISTS：block不存在</li>
<li>OP_STATUS_CHECKSUM_OK： checksum校验正常</li>
</ol>


<h3>1.读取block——readBlock()</h3>

<p>OP_READ_BLOCK的请求数据格式如下：</p>

<p><img src="/images/hdfs/ReadBlock.png" alt="READ_BLOCK" /></p>

<p>返回数据格式如下：</p>

<p><img src="/images/hdfs/ReadResponse.png" alt="READ_Response" /></p>

<p>readBlock()主要从disk读取block数据，构建一个DataOutputStream数据流，并新建一个BlockSender将这个数据流发送出去（datanode或者client）。</p>

<p>BlockSender.sendBlock()发送的Block的流程大体如下：</p>

<ol>
<li>读取block的meta信息，获得checksum并发送</li>
<li>发送数据读取的偏移量</li>
<li>将block数据切分为packet，发送给client</li>
<li>所有packet发送完之后，关闭checksum文件和block文件</li>
</ol>


<h3>2.写入block——writeBlock()</h3>

<p>OP_WRITE_BLOCK的请求数据格式如下：</p>

<p><img src="/images/hdfs/WriteRequest.png" alt="WRITE_BLOCK" /></p>

<p>writeBlock()解析请求信息，构建一个BlockReceiver处理数据接收和写入，在client（或上一datanode节点）-当前datanode节点-下一datanode节点之间建立一个如下连接。</p>

<p><img src="/images/hdfs/WriteBlock.png" alt="WRITE_BLOCK" /></p>

<ol>
<li>BlockReceiver从上按packet一节点读取数据，写入到本地disk</li>
<li>如有下一备份节点，将该packet转发给下一节点</li>
<li>将该packet加入到ackqueue队列中等待ack消息</li>
<li>当下一节点完成该packet写入后会返回该packet对应的ack信息</li>
<li>PakcetResponder接收到ack信息后，将ackqueue中该packet删除，并向前置节点发送ack信息</li>
</ol>

</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/3/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <ul id="recent_posts">
      <li class="post">
      <a href="http://jiangbo.me" alt="Home"><img src="/images/Home.png"></a>
      <a href="http://jiangbo.me/archives/" alt="Archives"><img src="/images/Calendar.png"></a>
      <a href="mailto:" alt="E-Mail"><img src="/images/Envelope.png"></a>
      <a href="http://jiangbo.me/atom.xml" alt="subscribe feed"><img src="/images/rss.png"></a>
      </li>
  </ul>
</section>
<section>
<a href="/about-me/"><h1>关于我</h1></a>
  <p>一个非纯种程序员，爱代码爱旅行爱美女</p>
  <iframe width="100%" height="480" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=480&fansRow=2&ptype=1&speed=0&skin=1&isTitle=0&noborder=1&isWeibo=1&isFans=0&uid=1892066397&verifier=8c17d4b5&dpc=1"></iframe>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2013/01/28/my2012/">我的2012&2013</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/01/16/hadoop-reconfigurable/">HADOOP动态加载配置</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/12/21/hdfs-raid/">HDFS RAID</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/12/10/hdfs-blockreaderlocal/">HDFS-2246:使用BlockReaderLocal优化本地block读取</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/10/23/mount-hdfs-with-fuse-dfs/">使用FUSE-DFS mount HDFS</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/jiang-bo">@jiang-bo</a> on GitHub
  
  <script type="text/javascript">
    $.domReady(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'jiang-bo',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>



<section>
  <h1>Tag Cloud</h1>
    <span id="tag-cloud"><a href='/blog/categories/android' style='font-size: 115.78947368421052%'>Android</a> <a href='/blog/categories/design' style='font-size: 109.47368421052632%'>Design</a> <a href='/blog/categories/hadoop' style='font-size: 106.3157894736842%'>Hadoop</a> <a href='/blog/categories/hdfs' style='font-size: 160.0%'>HDFS</a> <a href='/blog/categories/java' style='font-size: 103.15789473684211%'>Java</a> <a href='/blog/categories/javaee' style='font-size: 115.78947368421052%'>JavaEE</a> <a href='/blog/categories/jvm' style='font-size: 109.47368421052632%'>JVM</a> <a href='/blog/categories/life' style='font-size: 103.15789473684211%'>Life</a> <a href='/blog/categories/linux' style='font-size: 137.89473684210526%'>Linux</a> <a href='/blog/categories/mac' style='font-size: 112.63157894736842%'>Mac</a> <a href='/blog/categories/pattern' style='font-size: 109.47368421052632%'>Pattern</a> <a href='/blog/categories/python' style='font-size: 103.15789473684211%'>Python</a> <a href='/blog/categories/ruby' style='font-size: 103.15789473684211%'>Ruby</a> <a href='/blog/categories/ruby' style='font-size: 106.3157894736842%'>ruby</a> <a href='/blog/categories/spring' style='font-size: 103.15789473684211%'>Spring</a> <a href='/blog/categories/velocity源码分析' style='font-size: 106.3157894736842%'>Velocity源码分析</a> <a href='/blog/categories/webx' style='font-size: 103.15789473684211%'>webx</a> <a href='/blog/categories/基础巩固' style='font-size: 103.15789473684211%'>基础巩固</a> <a href='/blog/categories/嵌入式开发' style='font-size: 112.63157894736842%'>嵌入式开发</a> <a href='/blog/categories/技术生活' style='font-size: 106.3157894736842%'>技术生活</a> <a href='/blog/categories/未分类' style='font-size: 109.47368421052632%'>未分类</a> <a href='/blog/categories/生活' style='font-size: 103.15789473684211%'>生活</a> <a href='/blog/categories/高性能服务器' style='font-size: 103.15789473684211%'>高性能服务器</a> </span>
</section>

  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2013 - jiang-bo -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'jiangbo';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>











</body>
</html>
